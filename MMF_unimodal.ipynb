{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miayuehan/hm_detection/blob/main/MMF_unimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GrXROb1J9Zx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4NhVqgLx3e_"
      },
      "source": [
        "# **Install MMF**\n",
        "Please enable GPU in this notebook: Runtime > Change runtime type > Hardware Accelerator > Set to GPU\n",
        "(more details in [MMF Colab Demo](https://colab.research.google.com/github/facebookresearch/mmf/blob/notebooks/notebooks/mmf_hm_example.ipynb#scrollTo=1nwebqtdWOfZ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCKaUR4SK5hp"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ftR__RFgITu"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y mmf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkSscOx_L4kx"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://luckyyc12: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@github.com/luckyyc12/mmf.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfDDXEaPpSnj"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NgBl6BR0dm4"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "809U-LbLyZWb"
      },
      "source": [
        "### **Convert dataset zip file into required MMF format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V03M-IRPQSHc"
      },
      "outputs": [],
      "source": [
        "!mmf_convert_hm --zip_file /content/drive/MyDrive/CS7643_final_project/hateful_memes.zip --password ' ' --bypass_checksum=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jfgsHB3yq8_"
      },
      "source": [
        "### **Visualize**\n",
        "\n",
        "Below code block will output some samples of the dataset for visualization. You can adjust number of samples, rows and size among other stuff.\n",
        "\n",
        "**Note 1**: In some particular images, colab version of matplotlib can cause issues, so we will upgrade it and restart the runtime to load new version.\n",
        "\n",
        "**Note 2**: Some of the images in the hateful memes dataset are sensitive and may not be suitable for all audiences. Please run the next code responsibly keeping these conditions in mind."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl14eAgdM7rJ"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade matplotlib==3.3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYTE5Sx7yu6X"
      },
      "outputs": [],
      "source": [
        " !pip install --upgrade Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lmdZUbHM-ZG"
      },
      "outputs": [],
      "source": [
        "from mmf.common.registry import registry\n",
        "from mmf.models.mmbt import MMBT\n",
        "from mmf.utils.build import build_dataset\n",
        "from mmf.utils.env import setup_imports\n",
        "\n",
        "setup_imports()\n",
        "dataset = build_dataset(\"hateful_memes\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
        "dataset.visualize(num_samples=8, size=(512, 512), nrow=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ShqFziVzG7f"
      },
      "source": [
        "# **Test pretrained model**\n",
        "We will now use MMF to load an existing model MMBT to run some tests on random images from the internet. Fill in the image url and the text contained in it to see if the model thinks of it as hateful or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fibGq1zXt05"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from mmf.models.mmbt import MMBT\n",
        "\n",
        "model = MMBT.from_pretrained(\"mmbt.hateful_memes.images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llib5H6LhEHv"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://i.imgur.com/tEcsk5q.jpg\" #@param {type:\"string\"}\n",
        "text = \"look how many people love you\" #@param {type: \"string\"}\n",
        "output = model.classify(image_url, text)\n",
        "plt.imshow(Image.open(requests.get(image_url, stream=True).raw))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "hateful = \"Yes\" if output[\"label\"] == 1 else \"No\"\n",
        "print(\"Hateful as per the model?\", hateful)\n",
        "print(f\"Model's confidence: {output['confidence'] * 100:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6LdVmzgzQ-J"
      },
      "source": [
        "# **Submit a prediction**\n",
        "\n",
        "Now, we will use a pretrained model from MMF to submit a prediction to DrivenData. Run the command in the next block and at the end it will output the path to the csv file generated. Download and upload that file to DrivenData's submission page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFIuQ-_OhJ5b"
      },
      "outputs": [],
      "source": [
        "!mmf_predict config=projects/hateful_memes/configs/mmbt/defaults.yaml model=mmbt dataset=hateful_memes run_type=test checkpoint.resume_zoo=mmbt.hateful_memes.images training.batch_size=16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtQiaeIOzVVF"
      },
      "source": [
        "# **Train an existing model**\n",
        "\n",
        "We will use MMF to train an existing baseline from MMF's model zoo on the Hateful Memes dataset. Run the next code cell to start training MMBT-Grid model on the dataset. You can adjust the batch size, maximum number of updates, log and evaluation interval among other things by using command line overrides. Read more about MMF's configuration system at https://mmf.readthedocs.io/en/latest/notes/configuration.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhkWx-_ChNzC"
      },
      "outputs": [],
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/mmf_bert/defaults.yaml \\\n",
        "  model=mmf_bert \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=300 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqBRonFeHYu_"
      },
      "outputs": [],
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/mmbt/defaults.yaml \\\n",
        "  model=mmbt \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=3000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ZRGSIbzaj1"
      },
      "source": [
        "# **Build your own model**\n",
        "\n",
        "Using MMF's encoders, modules and utilities, we can easily build a custom model. In this example, we are building a fusion model which fuses ResNet pooled grid features with fasttext embedding vectors to classify a meme as hateful or not hateful.\n",
        "\n",
        "Steps involved in building the model are:\n",
        "\n",
        "Create a new processor to get fasttext sentence embeddings. (Read more on processors here)\n",
        "Create new model using encoders from MMF.\n",
        "Move hardcoded stuff from model to configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRyWsdxTzeQV"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "\n",
        "# We will inherit the FastText Processor already present in MMF\n",
        "from mmf.datasets.processors import FastTextProcessor\n",
        "# registry is needed to register processor and model to be MMF discoverable\n",
        "from mmf.common.registry import registry\n",
        "\n",
        "\n",
        "# Register the processor so that MMF can discover it\n",
        "@registry.register_processor(\"fasttext_sentence_vector\")\n",
        "class FastTextSentenceVectorProcessor(FastTextProcessor):\n",
        "    # Override the call method\n",
        "    def __call__(self, item):\n",
        "        # This function is present in FastTextProcessor class and loads\n",
        "        # fasttext bin\n",
        "        self._load_fasttext_model(self.model_file)\n",
        "        if \"text\" in item:\n",
        "            text = item[\"text\"]\n",
        "        elif \"tokens\" in item:\n",
        "            text = \" \".join(item[\"tokens\"])\n",
        "\n",
        "        # Get a sentence vector for sentence and convert it to torch tensor\n",
        "        sentence_vector = torch.tensor(\n",
        "            self.model.get_sentence_vector(text),\n",
        "            dtype=torch.float\n",
        "        )\n",
        "\n",
        "        # Return back a dict\n",
        "        return {\n",
        "            \"text\": sentence_vector\n",
        "        }\n",
        "    \n",
        "    # Make dataset builder happy, return a random number\n",
        "    def get_vocab_size(self):\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6GayvapzhQB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# registry is need to register our new model so as to be MMF discoverable\n",
        "from mmf.common.registry import registry\n",
        "# All model using MMF need to inherit BaseModel\n",
        "from mmf.models.base_model import BaseModel\n",
        "# ProjectionEmbedding will act as proxy encoder for FastText Sentence Vector\n",
        "from mmf.modules.embeddings import ProjectionEmbedding\n",
        "# Builder methods for image encoder and classifier\n",
        "from mmf.utils.build import build_classifier_layer, build_image_encoder\n",
        "\n",
        "# Register the model for MMF, \"concat_vl\" key would be used to find the model\n",
        "@registry.register_model(\"concat_vl\")\n",
        "class LanguageAndVisionConcat(BaseModel):\n",
        "    # All models in MMF get first argument as config which contains all\n",
        "    # of the information you stored in this model's config (hyperparameters)\n",
        "    def __init__(self, config, *args, **kwargs):\n",
        "        # This is not needed in most cases as it just calling parent's init\n",
        "        # with same parameters. But to explain how config is initialized we \n",
        "        # have kept this\n",
        "        super().__init__(config, *args, **kwargs)\n",
        "    \n",
        "    # This classmethod tells MMF where to look for default config of this model\n",
        "    @classmethod\n",
        "    def config_path(cls):\n",
        "        # Relative to user dir root\n",
        "        return \"/content/hm_example_mmf/configs/models/concat_vl.yaml\"\n",
        "    \n",
        "    # Each method need to define a build method where the model's modules\n",
        "    # are actually build and assigned to the model\n",
        "    def build(self):\n",
        "        \"\"\"\n",
        "        Config's image_encoder attribute will used to build an MMF image\n",
        "        encoder. This config in yaml will look like:\n",
        "\n",
        "        # \"type\" parameter specifies the type of encoder we are using here. \n",
        "        # In this particular case, we are using resnet152\n",
        "        type: resnet152\n",
        "      \n",
        "        # Parameters are passed to underlying encoder class by \n",
        "        # build_image_encoder\n",
        "        params:\n",
        "          # Specifies whether to use a pretrained version\n",
        "          pretrained: true \n",
        "          # Pooling type, use max to use AdaptiveMaxPool2D\n",
        "          pool_type: avg \n",
        "      \n",
        "          # Number of output features from the encoder, -1 for original\n",
        "          # otherwise, supports between 1 to 9\n",
        "          num_output_features: 1 \n",
        "        \"\"\"\n",
        "        self.vision_module = build_image_encoder(self.config.image_encoder)\n",
        "\n",
        "        \"\"\"\n",
        "        For classifer, configuration would look like:\n",
        "        # Specifies the type of the classifier, in this case mlp\n",
        "        type: mlp\n",
        "        # Parameter to the classifier passed through build_classifier_layer\n",
        "        params:\n",
        "          # Dimension of the tensor coming into the classifier\n",
        "          in_dim: 512\n",
        "          # Dimension of the tensor going out of the classifier\n",
        "          out_dim: 2\n",
        "          # Number of MLP layers in the classifier\n",
        "          num_layers: 0\n",
        "        \"\"\"\n",
        "        self.classifier = build_classifier_layer(self.config.classifier)\n",
        "        \n",
        "        # ProjectionEmbeddings takes in params directly as it is module\n",
        "        # So, pass in kwargs, which are in_dim, out_dim and module\n",
        "        # whose value would be \"linear\" as we want linear layer\n",
        "        self.language_module = ProjectionEmbedding(\n",
        "            **self.config.text_encoder.params\n",
        "        )\n",
        "        # Dropout value will come from config now\n",
        "        self.dropout = torch.nn.Dropout(self.config.dropout)\n",
        "        # Same as Projection Embedding, fusion's layer params (which are param \n",
        "        # for linear layer) will come from config now\n",
        "        self.fusion = torch.nn.Linear(**self.config.fusion.params)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    # Each model in MMF gets a dict called sample_list which contains\n",
        "    # all of the necessary information returned from the image\n",
        "    def forward(self, sample_list):\n",
        "        # Text input features will be in \"text\" key\n",
        "        text = sample_list[\"text\"]\n",
        "        # Similarly, image input will be in \"image\" key\n",
        "        image = sample_list[\"image\"]\n",
        "\n",
        "        text_features = self.relu(self.language_module(text))\n",
        "        image_features = self.relu(self.vision_module(image))\n",
        "\n",
        "        # Concatenate the features returned from two modality encoders\n",
        "        combined = torch.cat([text_features, image_features.squeeze(dim=1)], dim=1)\n",
        "\n",
        "        # Pass through the fusion layer, relu and dropout\n",
        "        fused = self.dropout(self.relu(self.fusion(combined)))\n",
        "\n",
        "        # Pass final tensor from classifier to get scores\n",
        "        logits = self.classifier(fused)\n",
        "\n",
        "        # For loss calculations (automatically done by MMF based on loss defined\n",
        "        # in the config), we need to return a dict with \"scores\" key as logits\n",
        "        output = {\"scores\": logits}\n",
        "\n",
        "        # MMF will automatically calculate loss\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PAEMSclzmvu"
      },
      "source": [
        "Now, we will install the example repo that we have already created on top of MMF and contains code in this colab. We do this so that we don't have to build configs again from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtYom8_czkq4"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/apsdehal/hm_example_mmf /content/hm_example_mmf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avBt2LXvzqsZ"
      },
      "source": [
        "# **Train your model**\n",
        "\n",
        "In this step, we will train the model we just built. A dot list can be passed as either a dict or a list to the run to override the configuration parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UeOH3qCzyPX"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from mmf_cli.run import run\n",
        "from mmf.common.registry import registry\n",
        "\n",
        "registry.mapping[\"state\"] = {}\n",
        "opts = opts=[\n",
        "    \"config='/content/hm_example_mmf/configs/experiments/defaults.yaml'\", \n",
        "    \"model=concat_vl\", \n",
        "    \"dataset=hateful_memes\", \n",
        "    \"training.num_workers=0\",\n",
        "]\n",
        "run(opts=opts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yri1lv40zy59"
      },
      "source": [
        "# **Using your module**\n",
        "Since, we have cloned the repo that contains the example we built in this colab notebook we can use it also to run the training from command line by using the env.user_dir option or by overriding the environment variable MMF_USER_DIR. Expand the cell below the next code cell to see how it can be done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qzUWd-Jz-UK"
      },
      "outputs": [],
      "source": [
        "!MMF_USER_DIR=\"/content/hm_example_mmf\" mmf_run \\\n",
        "  config=\"configs/experiments/defaults.yaml\" \\\n",
        "  model=concat_vl \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.num_workers=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg6wtkCmz-8Y"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vEKCVptAZxE"
      },
      "source": [
        "# **BERT + Classfier**\n",
        "- Bert only\n",
        "- MLP classifier with configurable #layers and hidden units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-1QAYXjaA6P"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/luckyyc12/mmf.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-udnv_XTzJr"
      },
      "outputs": [],
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/unimodal/with_features.yaml \\\n",
        "  model=unimodal_image \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=100 \\\n",
        "  training.max_updates=1500 \\\n",
        "  training.batch_size=64 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myjJA3T9l1Gd"
      },
      "outputs": [],
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/unimodal/bert.yaml \\\n",
        "  model=unimodal_text \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=1000 \\\n",
        "  # training.max_updates=1500 \\\n",
        "  # training.batch_size=64 \\\n",
        "  training.evaluation_interval=5000 \\\n",
        "  trainer.params.gpus=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EW3Joggob92"
      },
      "outputs": [],
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/vilbert/from_cc.yaml \\\n",
        "  model=vilbert \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=1000 \\\n",
        "  training.max_updates=10000 \\\n",
        "  training.evaluation_interval=2500 \\\n",
        "  trainer.params.gpus=100\n",
        "\n",
        "  #  # training.batch_size=64 \\"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/unimodal/image.yaml \\\n",
        "  model=unimodal_image \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=1000 \\\n",
        "  training.max_updates=10000 \\\n",
        "  training.evaluation_interval=2500 \\\n",
        "  trainer.params.gpus=100\n",
        "\n",
        "  #  # training.batch_size=64 \\"
      ],
      "metadata": {
        "id": "JXuS-HinDXjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
        "  model=visual_bert \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=2000 \\\n",
        "  training.max_updates=10000 \\\n",
        "  # training.batch_size=64 \\\n",
        "  training.evaluation_interval=2000 \\\n",
        "  trainer.params.gpus=100"
      ],
      "metadata": {
        "id": "PCsljKB-hlJX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}