{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miayuehan/hm_detection/blob/main/Train_existing_mmf_multimodal_based_on_pretrained_unimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GrXROb1J9Zx",
        "outputId": "55f06432-39da-4883-a396-593fcb160695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4NhVqgLx3e_"
      },
      "source": [
        "# **Install MMF**\n",
        "Please enable GPU in this notebook: Runtime > Change runtime type > Hardware Accelerator > Set to GPU\n",
        "(more details in [MMF Colab Demo](https://colab.research.google.com/github/facebookresearch/mmf/blob/notebooks/notebooks/mmf_hm_example.ipynb#scrollTo=1nwebqtdWOfZ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ftR__RFgITu",
        "outputId": "74ce4090-9a06-402e-a448-a222be7ce921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping mmf as it is not installed.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y mmf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkSscOx_L4kx",
        "outputId": "5f67e72c-2fb9-4e83-8b94-9f515eb73dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/BotaoAn/mmf.git\n",
            "  Cloning https://github.com/BotaoAn/mmf.git to /tmp/pip-req-build-yc_h3gz6\n",
            "  Running command git clone -q https://github.com/BotaoAn/mmf.git /tmp/pip-req-build-yc_h3gz6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f\n",
            "  Cloning https://github.com/PyTorchLightning/pytorch-lightning (to revision 9b011606f) to /tmp/pip-install-sambu6k3/pytorch-lightning_29418f7548524769a7770c00c41a527d\n",
            "  Running command git clone -q https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-install-sambu6k3/pytorch-lightning_29418f7548524769a7770c00c41a527d\n",
            "\u001b[33m  WARNING: Did not find branch or tag '9b011606f', assuming revision or ref.\u001b[0m\n",
            "  Running command git checkout -q 9b011606f\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  From https://github.com/PyTorchLightning/lightning-tutorials\n",
            "   * branch            290fb466de1fcc2ac6025f74b56906592911e856 -> FETCH_HEAD\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/BotaoAn/mmf.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NgBl6BR0dm4"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "809U-LbLyZWb"
      },
      "source": [
        "### **Convert dataset zip file into required MMF format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V03M-IRPQSHc"
      },
      "outputs": [],
      "source": [
        "!mmf_convert_hm --zip_file /content/drive/MyDrive/final_project/mmf/projects/hateful_memes/hateful_memes.zip --password ' ' --bypass_checksum=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtQiaeIOzVVF"
      },
      "source": [
        "# **Train an existing model**\n",
        "\n",
        "We will use MMF to train an existing baseline from MMF's model zoo on the Hateful Memes dataset. Run the next code cell to start training MMBT-Grid model on the dataset. You can adjust the batch size, maximum number of updates, log and evaluation interval among other things by using command line overrides. Read more about MMF's configuration system at https://mmf.readthedocs.io/en/latest/notes/configuration.html."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcuhKF5cDQyz",
        "outputId": "d34168b9-a7a0-4011-e35e-ff3d35988057"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 92.8 MB/s eta 0:00:14tcmalloc: large alloc 1147494400 bytes == 0x39518000 @  0x7f0fae292615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:14:08tcmalloc: large alloc 1434370048 bytes == 0x7db6e000 @  0x7f0fae292615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 121.2 MB/s eta 0:00:06tcmalloc: large alloc 1792966656 bytes == 0x29a0000 @  0x7f0fae292615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:50tcmalloc: large alloc 2241208320 bytes == 0x6d788000 @  0x7f0fae292615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041339904 bytes == 0xf30ea000 @  0x7f0fae2911e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
            "tcmalloc: large alloc 2551676928 bytes == 0x1e1048000 @  0x7f0fae292615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 4.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp38-cp38-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchaudio==0.9.0 in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0+cu111) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (1.21.4)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (9.0.1)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0\n",
            "    Uninstalling torch-1.9.0:\n",
            "      Successfully uninstalled torch-1.9.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0\n",
            "    Uninstalling torchvision-0.10.0:\n",
            "      Successfully uninstalled torchvision-0.10.0\n",
            "Successfully installed torch-1.9.0+cu111 torchvision-0.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl14eAgdM7rJ",
        "outputId": "3a9c37b9-5a3b-40da-849e-8884351dd84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib==3.3.4 in /usr/local/lib/python3.8/dist-packages (3.3.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (1.21.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (9.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.4) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade matplotlib==3.3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhkWx-_ChNzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e0ecce-c16a-4a3d-e2c9-47a6c196ae01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 07:12:50.755657: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "\u001b[32m2022-12-09T07:12:55 | mmf: \u001b[0mLogging to: /drive/MyDrive/final_project/mmf/projects/hateful_memes/save/train.log\n",
            "\u001b[32m2022-12-09T07:12:55 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/concat_bert/defaults.yaml', 'model=concat_vl', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=6000', 'training.batch_size=16', 'training.evaluation_interval=500', 'trainer.params.gpus=100', 'env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save'])\n",
            "\u001b[32m2022-12-09T07:12:55 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu111\n",
            "\u001b[32m2022-12-09T07:12:55 | mmf.utils.general: \u001b[0mCUDA Device 0 is: A100-SXM4-40GB\n",
            "\u001b[32m2022-12-09T07:12:55 | mmf_cli.run: \u001b[0mUsing seed 56051853\n",
            "\u001b[32m2022-12-09T07:12:56 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:00<00:00, 377kB/s]\n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T07:12:57 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/mmf/datasets/processors/processors.py:450: UserWarning: No model file present at /root/.cache/torch/mmf/wiki.en.bin.\n",
            "  warnings.warn(f\"No model file present at {model_file}.\")\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T07:12:57 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/mmf/datasets/processors/processors.py:450: UserWarning: No model file present at /root/.cache/torch/mmf/wiki.en.bin.\n",
            "  warnings.warn(f\"No model file present at {model_file}.\")\n",
            "\n",
            "\u001b[32m2022-12-09T07:12:57 | mmf.datasets.processors.processors: \u001b[0mDownloading FastText bin\n",
            "169876453it [02:40, 1057897.06it/s]\n",
            "\u001b[32m2022-12-09T07:15:38 | mmf.datasets.processors.processors: \u001b[0mfastText bin downloaded at /root/.cache/torch/mmf/wiki.en.bin.\n",
            "\u001b[32m2022-12-09T07:15:38 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T07:15:38 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T07:15:38 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T07:15:38 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100% 230M/230M [00:01<00:00, 165MB/s]\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.trainers.mmf_trainer: \u001b[0mLanguageAndVisionConcat(\n",
            "  (vision_module): ResNet152ImageEncoder(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (6): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (7): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (6): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (7): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (8): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (9): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (10): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (11): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (12): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (13): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (14): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (15): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (16): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (17): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (18): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (19): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (20): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (21): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (22): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (23): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (24): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (25): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (26): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (27): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (28): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (29): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (30): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (31): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (32): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (33): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (34): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (35): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (classifier): MLPClassifer(\n",
            "    (layers): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.5, inplace=False)\n",
            "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ReLU()\n",
            "      (7): Dropout(p=0.5, inplace=False)\n",
            "      (8): Linear(in_features=512, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (language_module): ProjectionEmbedding(\n",
            "    (layers): Linear(in_features=300, out_features=300, bias=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fusion): Linear(in_features=2348, out_features=512, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.utils.general: \u001b[0mTotal Parameters: 59965182. Trained Parameters: 59965182\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T07:15:47 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3ea8bfc000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4e67 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3ea8bfc000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4e67 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3ea8bfc000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4e67 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3ea8bfc000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4e67 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3df48ca000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4eab 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3df48ca000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4eab 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3df48ca000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4eab 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3df48ca000 @  0x7f4239b29887 0x7f4133db5b73 0x7f4133da4eab 0x7f4133da5981 0x7f4133d74272 0x7f4133d93ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:15:57 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T07:15:58 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T07:15:58 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[32m2022-12-09T07:15:58 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:15:58 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:15:58 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:16:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/6000, train/hateful_memes/cross_entropy: 0.7251, train/hateful_memes/cross_entropy/avg: 0.7251, train/total_loss: 0.7251, train/total_loss/avg: 0.7251, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 6000, lr: 0., ups: 2.38, time: 21s 420ms, time_since_start: 21s 471ms, eta: 45m 22s 381ms\n",
            "\u001b[32m2022-12-09T07:16:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/6000, train/hateful_memes/cross_entropy: 0.6665, train/hateful_memes/cross_entropy/avg: 0.6958, train/total_loss: 0.6665, train/total_loss/avg: 0.6958, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 665ms, time_since_start: 32s 137ms, eta: 22m 24s 061ms\n",
            "\u001b[32m2022-12-09T07:16:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/6000, train/hateful_memes/cross_entropy: 0.6665, train/hateful_memes/cross_entropy/avg: 0.6750, train/total_loss: 0.6665, train/total_loss/avg: 0.6750, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 658ms, time_since_start: 42s 795ms, eta: 22m 11s 856ms\n",
            "\u001b[32m2022-12-09T07:16:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/6000, train/hateful_memes/cross_entropy: 0.6334, train/hateful_memes/cross_entropy/avg: 0.6640, train/total_loss: 0.6334, train/total_loss/avg: 0.6640, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 707ms, time_since_start: 53s 503ms, eta: 22m 06s 584ms\n",
            "\u001b[32m2022-12-09T07:16:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/6000, train/hateful_memes/cross_entropy: 0.6665, train/hateful_memes/cross_entropy/avg: 0.7028, train/total_loss: 0.6665, train/total_loss/avg: 0.7028, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 657ms, time_since_start: 01m 04s 161ms, eta: 21m 48s 990ms\n",
            "\u001b[32m2022-12-09T07:17:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/6000, train/hateful_memes/cross_entropy: 0.6665, train/hateful_memes/cross_entropy/avg: 0.7014, train/total_loss: 0.6665, train/total_loss/avg: 0.7014, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 651ms, time_since_start: 01m 14s 813ms, eta: 21m 36s 879ms\n",
            "\u001b[32m2022-12-09T07:17:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7079, train/total_loss: 0.6942, train/total_loss/avg: 0.7079, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 431ms, time_since_start: 01m 25s 244ms, eta: 20m 58s 935ms\n",
            "\u001b[32m2022-12-09T07:17:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7243, train/total_loss: 0.6942, train/total_loss/avg: 0.7243, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 415ms, time_since_start: 01m 35s 660ms, eta: 20m 45s 820ms\n",
            "\u001b[32m2022-12-09T07:17:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/6000, train/hateful_memes/cross_entropy: 0.7251, train/hateful_memes/cross_entropy/avg: 0.7282, train/total_loss: 0.7251, train/total_loss/avg: 0.7282, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 439ms, time_since_start: 01m 46s 099ms, eta: 20m 37s 542ms\n",
            "\u001b[32m2022-12-09T07:17:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7196, train/total_loss: 0.6942, train/total_loss/avg: 0.7196, max mem: 3688.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 488ms, time_since_start: 01m 56s 587ms, eta: 20m 32s 179ms\n",
            "\u001b[32m2022-12-09T07:17:44 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:17:44 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:17:44 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:17:44 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:17:44 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:17:44 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3daebfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3daebfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3daebfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3daebfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cfa8ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cfa8ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cfa8ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cfa8ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:18:00 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:18:00 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:18:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:18:02 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T07:18:03 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:18:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:18:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, val/hateful_memes/cross_entropy: 0.6680, val/total_loss: 0.6680, val/hateful_memes/accuracy: 0.6130, val/hateful_memes/binary_f1: 0.1469, val/hateful_memes/roc_auc: 0.5110, num_updates: 500, epoch: 1, iterations: 500, max_updates: 6000, val_time: 20s 714ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.510985\n",
            "\u001b[32m2022-12-09T07:18:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/6000, train/hateful_memes/cross_entropy: 0.7251, train/hateful_memes/cross_entropy/avg: 0.7265, train/total_loss: 0.7251, train/total_loss/avg: 0.7265, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 6000, lr: 0.00001, ups: 4.17, time: 12s 435ms, time_since_start: 02m 29s 739ms, eta: 24m 07s 657ms\n",
            "\u001b[32m2022-12-09T07:18:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7198, train/total_loss: 0.6942, train/total_loss/avg: 0.7198, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 543ms, time_since_start: 02m 40s 283ms, eta: 20m 16s 183ms\n",
            "\u001b[32m2022-12-09T07:18:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7101, train/total_loss: 0.6942, train/total_loss/avg: 0.7101, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 575ms, time_since_start: 02m 50s 858ms, eta: 20m 08s 486ms\n",
            "\u001b[32m2022-12-09T07:18:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7151, train/total_loss: 0.6942, train/total_loss/avg: 0.7151, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 566ms, time_since_start: 03m 01s 424ms, eta: 19m 56s 202ms\n",
            "\u001b[32m2022-12-09T07:19:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/6000, train/hateful_memes/cross_entropy: 0.7251, train/hateful_memes/cross_entropy/avg: 0.7253, train/total_loss: 0.7251, train/total_loss/avg: 0.7253, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 968ms, time_since_start: 03m 12s 393ms, eta: 20m 30s 015ms\n",
            "\u001b[32m2022-12-09T07:19:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7176, train/total_loss: 0.6942, train/total_loss/avg: 0.7176, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 568ms, time_since_start: 03m 22s 961ms, eta: 19m 33s 867ms\n",
            "\u001b[32m2022-12-09T07:19:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/6000, train/hateful_memes/cross_entropy: 0.6942, train/hateful_memes/cross_entropy/avg: 0.7046, train/total_loss: 0.6942, train/total_loss/avg: 0.7046, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 664ms, time_since_start: 03m 33s 626ms, eta: 19m 33s 125ms\n",
            "\u001b[32m2022-12-09T07:19:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/6000, train/hateful_memes/cross_entropy: 0.6665, train/hateful_memes/cross_entropy/avg: 0.6983, train/total_loss: 0.6665, train/total_loss/avg: 0.6983, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 900, iterations: 900, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 729ms, time_since_start: 03m 44s 355ms, eta: 19m 28s 778ms\n",
            "\u001b[32m2022-12-09T07:19:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/6000, train/hateful_memes/cross_entropy: 0.6787, train/hateful_memes/cross_entropy/avg: 0.6972, train/total_loss: 0.6787, train/total_loss/avg: 0.6972, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 950, iterations: 950, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 616ms, time_since_start: 03m 54s 971ms, eta: 19m 05s 148ms\n",
            "\u001b[32m2022-12-09T07:19:53 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T07:19:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:19:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:19:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:19:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, train/hateful_memes/cross_entropy: 0.6665, train/hateful_memes/cross_entropy/avg: 0.6870, train/total_loss: 0.6665, train/total_loss/avg: 0.6870, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 1000, iterations: 1000, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 907ms, time_since_start: 04m 08s 878ms, eta: 24m 45s 302ms\n",
            "\u001b[32m2022-12-09T07:19:56 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:19:56 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:20:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:20:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:20:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:20:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:20:41 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:20:41 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:20:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:20:43 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T07:20:45 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:20:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:20:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, val/hateful_memes/cross_entropy: 0.6669, val/total_loss: 0.6669, val/hateful_memes/accuracy: 0.6426, val/hateful_memes/binary_f1: 0.1787, val/hateful_memes/roc_auc: 0.5305, num_updates: 1000, epoch: 2, iterations: 1000, max_updates: 6000, val_time: 52s 576ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:21:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/6000, train/hateful_memes/cross_entropy: 0.6462, train/hateful_memes/cross_entropy/avg: 0.6807, train/total_loss: 0.6462, train/total_loss/avg: 0.6807, max mem: 3688.0, experiment: run, epoch: 2, num_updates: 1050, iterations: 1050, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 794ms, time_since_start: 05m 12s 251ms, eta: 19m 01s 331ms\n",
            "\u001b[32m2022-12-09T07:21:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6790, train/total_loss: 0.6430, train/total_loss/avg: 0.6790, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 955ms, time_since_start: 05m 23s 207ms, eta: 19m 06s 669ms\n",
            "\u001b[32m2022-12-09T07:21:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6752, train/total_loss: 0.6430, train/total_loss/avg: 0.6752, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 717ms, time_since_start: 05m 33s 925ms, eta: 18m 30s 322ms\n",
            "\u001b[32m2022-12-09T07:21:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/6000, train/hateful_memes/cross_entropy: 0.6462, train/hateful_memes/cross_entropy/avg: 0.6786, train/total_loss: 0.6462, train/total_loss/avg: 0.6786, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 693ms, time_since_start: 05m 44s 618ms, eta: 18m 16s 365ms\n",
            "\u001b[32m2022-12-09T07:21:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6756, train/total_loss: 0.6430, train/total_loss/avg: 0.6756, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 591ms, time_since_start: 05m 55s 210ms, eta: 17m 54s 631ms\n",
            "\u001b[32m2022-12-09T07:21:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6797, train/total_loss: 0.6430, train/total_loss/avg: 0.6797, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 657ms, time_since_start: 06m 05s 868ms, eta: 17m 49s 977ms\n",
            "\u001b[32m2022-12-09T07:22:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6899, train/total_loss: 0.6430, train/total_loss/avg: 0.6899, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 593ms, time_since_start: 06m 16s 462ms, eta: 17m 32s 233ms\n",
            "\u001b[32m2022-12-09T07:22:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6921, train/total_loss: 0.6430, train/total_loss/avg: 0.6921, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 533ms, time_since_start: 06m 26s 995ms, eta: 17m 14s 965ms\n",
            "\u001b[32m2022-12-09T07:22:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/6000, train/hateful_memes/cross_entropy: 0.6422, train/hateful_memes/cross_entropy/avg: 0.6876, train/total_loss: 0.6422, train/total_loss/avg: 0.6876, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 677ms, time_since_start: 06m 37s 672ms, eta: 17m 17s 685ms\n",
            "\u001b[32m2022-12-09T07:22:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6935, train/total_loss: 0.6430, train/total_loss/avg: 0.6935, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 631ms, time_since_start: 06m 48s 303ms, eta: 17m 01s 860ms\n",
            "\u001b[32m2022-12-09T07:22:36 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:22:36 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:22:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:22:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T07:22:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:22:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:23:03 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:23:03 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:23:03 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:23:03 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:23:06 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:23:06 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:23:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:23:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:23:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:23:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, val/hateful_memes/cross_entropy: 0.6793, val/total_loss: 0.6793, val/hateful_memes/accuracy: 0.6037, val/hateful_memes/binary_f1: 0.2302, val/hateful_memes/roc_auc: 0.5238, num_updates: 1500, epoch: 3, iterations: 1500, max_updates: 6000, val_time: 34s 331ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:23:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6954, train/total_loss: 0.6430, train/total_loss/avg: 0.6954, max mem: 3688.0, experiment: run, epoch: 3, num_updates: 1550, iterations: 1550, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 919ms, time_since_start: 07m 33s 556ms, eta: 17m 17s 940ms\n",
            "\u001b[32m2022-12-09T07:23:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6970, train/total_loss: 0.6430, train/total_loss/avg: 0.6970, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1600, iterations: 1600, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 849ms, time_since_start: 07m 44s 406ms, eta: 16m 59s 712ms\n",
            "\u001b[32m2022-12-09T07:23:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/6000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6922, train/total_loss: 0.6430, train/total_loss/avg: 0.6922, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1650, iterations: 1650, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 663ms, time_since_start: 07m 55s 069ms, eta: 16m 30s 796ms\n",
            "\u001b[32m2022-12-09T07:23:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6852, train/total_loss: 0.6039, train/total_loss/avg: 0.6852, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1700, iterations: 1700, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 744ms, time_since_start: 08m 05s 813ms, eta: 16m 26s 837ms\n",
            "\u001b[32m2022-12-09T07:24:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6984, train/total_loss: 0.6039, train/total_loss/avg: 0.6984, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 034ms, time_since_start: 08m 16s 848ms, eta: 16m 41s 717ms\n",
            "\u001b[32m2022-12-09T07:24:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6896, train/total_loss: 0.6039, train/total_loss/avg: 0.6896, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 586ms, time_since_start: 08m 27s 435ms, eta: 15m 49s 777ms\n",
            "\u001b[32m2022-12-09T07:24:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6862, train/total_loss: 0.6039, train/total_loss/avg: 0.6862, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 490ms, time_since_start: 08m 37s 925ms, eta: 15m 29s 878ms\n",
            "\u001b[32m2022-12-09T07:24:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6814, train/total_loss: 0.6039, train/total_loss/avg: 0.6814, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 703ms, time_since_start: 08m 48s 628ms, eta: 15m 37s 357ms\n",
            "\u001b[32m2022-12-09T07:24:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/6000, train/hateful_memes/cross_entropy: 0.5927, train/hateful_memes/cross_entropy/avg: 0.6766, train/total_loss: 0.5927, train/total_loss/avg: 0.6766, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 602ms, time_since_start: 08m 59s 231ms, eta: 15m 17s 245ms\n",
            "\u001b[32m2022-12-09T07:24:57 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T07:24:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:24:58 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:25:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:25:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6772, train/total_loss: 0.6039, train/total_loss/avg: 0.6772, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 882ms, time_since_start: 09m 13s 113ms, eta: 19m 46s 084ms\n",
            "\u001b[32m2022-12-09T07:25:00 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:25:00 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:25:01 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:25:01 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:25:01 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:25:01 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:25:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:25:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:25:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:25:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:25:26 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:25:26 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:25:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:25:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:25:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:25:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, val/hateful_memes/cross_entropy: 0.7236, val/total_loss: 0.7236, val/hateful_memes/accuracy: 0.5759, val/hateful_memes/binary_f1: 0.2954, val/hateful_memes/roc_auc: 0.5107, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 6000, val_time: 29s 555ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:25:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6737, train/total_loss: 0.6039, train/total_loss/avg: 0.6737, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 6000, lr: 0.00005, ups: 4.55, time: 11s 125ms, time_since_start: 09m 53s 796ms, eta: 15m 38s 720ms\n",
            "\u001b[32m2022-12-09T07:25:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6746, train/total_loss: 0.6039, train/total_loss/avg: 0.6746, max mem: 3688.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 942ms, time_since_start: 10m 04s 739ms, eta: 15m 11s 543ms\n",
            "\u001b[32m2022-12-09T07:26:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6710, train/total_loss: 0.6039, train/total_loss/avg: 0.6710, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 6000, lr: 0.00005, ups: 4.55, time: 11s 058ms, time_since_start: 10m 15s 797ms, eta: 15m 09s 401ms\n",
            "\u001b[32m2022-12-09T07:26:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/6000, train/hateful_memes/cross_entropy: 0.6039, train/hateful_memes/cross_entropy/avg: 0.6696, train/total_loss: 0.6039, train/total_loss/avg: 0.6696, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 861ms, time_since_start: 10m 26s 659ms, eta: 14m 41s 621ms\n",
            "\u001b[32m2022-12-09T07:26:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/6000, train/hateful_memes/cross_entropy: 0.6083, train/hateful_memes/cross_entropy/avg: 0.6714, train/total_loss: 0.6083, train/total_loss/avg: 0.6714, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 714ms, time_since_start: 10m 37s 373ms, eta: 14m 18s 222ms\n",
            "\u001b[32m2022-12-09T07:26:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/6000, train/hateful_memes/cross_entropy: 0.5649, train/hateful_memes/cross_entropy/avg: 0.6656, train/total_loss: 0.5649, train/total_loss/avg: 0.6656, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 557ms, time_since_start: 10m 47s 931ms, eta: 13m 54s 394ms\n",
            "\u001b[32m2022-12-09T07:26:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/6000, train/hateful_memes/cross_entropy: 0.5649, train/hateful_memes/cross_entropy/avg: 0.6660, train/total_loss: 0.5649, train/total_loss/avg: 0.6660, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 538ms, time_since_start: 10m 58s 470ms, eta: 13m 41s 655ms\n",
            "\u001b[32m2022-12-09T07:26:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/6000, train/hateful_memes/cross_entropy: 0.5649, train/hateful_memes/cross_entropy/avg: 0.6699, train/total_loss: 0.5649, train/total_loss/avg: 0.6699, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 575ms, time_since_start: 11m 09s 045ms, eta: 13m 33s 204ms\n",
            "\u001b[32m2022-12-09T07:27:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/6000, train/hateful_memes/cross_entropy: 0.6083, train/hateful_memes/cross_entropy/avg: 0.6691, train/total_loss: 0.6083, train/total_loss/avg: 0.6691, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 559ms, time_since_start: 11m 19s 605ms, eta: 13m 20s 742ms\n",
            "\u001b[32m2022-12-09T07:27:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, train/hateful_memes/cross_entropy: 0.6083, train/hateful_memes/cross_entropy/avg: 0.6696, train/total_loss: 0.6083, train/total_loss/avg: 0.6696, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 775ms, time_since_start: 11m 30s 381ms, eta: 13m 25s 577ms\n",
            "\u001b[32m2022-12-09T07:27:18 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:27:18 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:27:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:27:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:27:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:27:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:27:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:27:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:27:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:27:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:27:39 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:27:39 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:27:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:27:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:27:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:27:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, val/hateful_memes/cross_entropy: 0.7826, val/total_loss: 0.7826, val/hateful_memes/accuracy: 0.5630, val/hateful_memes/binary_f1: 0.3587, val/hateful_memes/roc_auc: 0.5216, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 6000, val_time: 25s 525ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:27:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/6000, train/hateful_memes/cross_entropy: 0.5649, train/hateful_memes/cross_entropy/avg: 0.6634, train/total_loss: 0.5649, train/total_loss/avg: 0.6634, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 908ms, time_since_start: 12m 06s 817ms, eta: 13m 23s 891ms\n",
            "\u001b[32m2022-12-09T07:28:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/6000, train/hateful_memes/cross_entropy: 0.5395, train/hateful_memes/cross_entropy/avg: 0.6596, train/total_loss: 0.5395, train/total_loss/avg: 0.6596, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 622ms, time_since_start: 12m 17s 439ms, eta: 12m 51s 462ms\n",
            "\u001b[32m2022-12-09T07:28:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/6000, train/hateful_memes/cross_entropy: 0.5649, train/hateful_memes/cross_entropy/avg: 0.6621, train/total_loss: 0.5649, train/total_loss/avg: 0.6621, max mem: 3688.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 588ms, time_since_start: 12m 28s 028ms, eta: 12m 37s 668ms\n",
            "\u001b[32m2022-12-09T07:28:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/6000, train/hateful_memes/cross_entropy: 0.5649, train/hateful_memes/cross_entropy/avg: 0.6553, train/total_loss: 0.5649, train/total_loss/avg: 0.6553, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 875ms, time_since_start: 12m 38s 904ms, eta: 12m 46s 606ms\n",
            "\u001b[32m2022-12-09T07:28:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/6000, train/hateful_memes/cross_entropy: 0.5335, train/hateful_memes/cross_entropy/avg: 0.6521, train/total_loss: 0.5335, train/total_loss/avg: 0.6521, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 721ms, time_since_start: 12m 49s 625ms, eta: 12m 24s 302ms\n",
            "\u001b[32m2022-12-09T07:28:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/6000, train/hateful_memes/cross_entropy: 0.5335, train/hateful_memes/cross_entropy/avg: 0.6488, train/total_loss: 0.5335, train/total_loss/avg: 0.6488, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 633ms, time_since_start: 13m 259ms, eta: 12m 06s 814ms\n",
            "\u001b[32m2022-12-09T07:28:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/6000, train/hateful_memes/cross_entropy: 0.5210, train/hateful_memes/cross_entropy/avg: 0.6437, train/total_loss: 0.5210, train/total_loss/avg: 0.6437, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 814ms, time_since_start: 13m 11s 073ms, eta: 12m 07s 654ms\n",
            "\u001b[32m2022-12-09T07:29:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/6000, train/hateful_memes/cross_entropy: 0.5210, train/hateful_memes/cross_entropy/avg: 0.6389, train/total_loss: 0.5210, train/total_loss/avg: 0.6389, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 828ms, time_since_start: 13m 21s 902ms, eta: 11m 57s 053ms\n",
            "\u001b[32m2022-12-09T07:29:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/6000, train/hateful_memes/cross_entropy: 0.5210, train/hateful_memes/cross_entropy/avg: 0.6341, train/total_loss: 0.5210, train/total_loss/avg: 0.6341, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 647ms, time_since_start: 13m 32s 550ms, eta: 11m 33s 651ms\n",
            "\u001b[32m2022-12-09T07:29:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T07:29:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:29:32 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:29:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:29:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, train/hateful_memes/cross_entropy: 0.5210, train/hateful_memes/cross_entropy/avg: 0.6332, train/total_loss: 0.5210, train/total_loss/avg: 0.6332, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 6000, lr: 0.00004, ups: 3.33, time: 15s 587ms, time_since_start: 13m 48s 138ms, eta: 16m 38s 859ms\n",
            "\u001b[32m2022-12-09T07:29:35 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:29:35 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:29:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:29:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:29:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:29:36 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:30:05 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:30:05 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:30:05 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:30:05 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:30:08 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:30:08 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:30:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:30:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:30:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:30:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, val/hateful_memes/cross_entropy: 0.8858, val/total_loss: 0.8858, val/hateful_memes/accuracy: 0.5796, val/hateful_memes/binary_f1: 0.2458, val/hateful_memes/roc_auc: 0.4737, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 6000, val_time: 37s 596ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:30:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3050/6000, train/hateful_memes/cross_entropy: 0.4777, train/hateful_memes/cross_entropy/avg: 0.6277, train/total_loss: 0.4777, train/total_loss/avg: 0.6277, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 3050, iterations: 3050, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 892ms, time_since_start: 14m 36s 629ms, eta: 11m 26s 383ms\n",
            "\u001b[32m2022-12-09T07:30:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/6000, train/hateful_memes/cross_entropy: 0.4777, train/hateful_memes/cross_entropy/avg: 0.6254, train/total_loss: 0.4777, train/total_loss/avg: 0.6254, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 3100, iterations: 3100, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 796ms, time_since_start: 14m 47s 425ms, eta: 11m 08s 775ms\n",
            "\u001b[32m2022-12-09T07:30:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3150/6000, train/hateful_memes/cross_entropy: 0.4777, train/hateful_memes/cross_entropy/avg: 0.6234, train/total_loss: 0.4777, train/total_loss/avg: 0.6234, max mem: 3688.0, experiment: run, epoch: 6, num_updates: 3150, iterations: 3150, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 628ms, time_since_start: 14m 58s 053ms, eta: 10m 47s 006ms\n",
            "\u001b[32m2022-12-09T07:30:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/6000, train/hateful_memes/cross_entropy: 0.4686, train/hateful_memes/cross_entropy/avg: 0.6192, train/total_loss: 0.4686, train/total_loss/avg: 0.6192, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3200, iterations: 3200, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 875ms, time_since_start: 15m 08s 929ms, eta: 10m 50s 424ms\n",
            "\u001b[32m2022-12-09T07:31:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3250/6000, train/hateful_memes/cross_entropy: 0.4684, train/hateful_memes/cross_entropy/avg: 0.6167, train/total_loss: 0.4684, train/total_loss/avg: 0.6167, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3250, iterations: 3250, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 513ms, time_since_start: 15m 19s 442ms, eta: 10m 17s 573ms\n",
            "\u001b[32m2022-12-09T07:31:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/6000, train/hateful_memes/cross_entropy: 0.4684, train/hateful_memes/cross_entropy/avg: 0.6097, train/total_loss: 0.4684, train/total_loss/avg: 0.6097, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3300, iterations: 3300, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 594ms, time_since_start: 15m 30s 037ms, eta: 10m 11s 029ms\n",
            "\u001b[32m2022-12-09T07:31:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3350/6000, train/hateful_memes/cross_entropy: 0.4630, train/hateful_memes/cross_entropy/avg: 0.6046, train/total_loss: 0.4630, train/total_loss/avg: 0.6046, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3350, iterations: 3350, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 616ms, time_since_start: 15m 40s 654ms, eta: 10m 949ms\n",
            "\u001b[32m2022-12-09T07:31:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/6000, train/hateful_memes/cross_entropy: 0.3661, train/hateful_memes/cross_entropy/avg: 0.5974, train/total_loss: 0.3661, train/total_loss/avg: 0.5974, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3400, iterations: 3400, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 564ms, time_since_start: 15m 51s 219ms, eta: 09m 46s 729ms\n",
            "\u001b[32m2022-12-09T07:31:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3450/6000, train/hateful_memes/cross_entropy: 0.3599, train/hateful_memes/cross_entropy/avg: 0.5900, train/total_loss: 0.3599, train/total_loss/avg: 0.5900, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3450, iterations: 3450, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 711ms, time_since_start: 16m 01s 931ms, eta: 09m 43s 453ms\n",
            "\u001b[32m2022-12-09T07:32:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, train/hateful_memes/cross_entropy: 0.3523, train/hateful_memes/cross_entropy/avg: 0.5848, train/total_loss: 0.3523, train/total_loss/avg: 0.5848, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3500, iterations: 3500, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 633ms, time_since_start: 16m 12s 564ms, eta: 09m 27s 825ms\n",
            "\u001b[32m2022-12-09T07:32:00 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:32:00 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:32:00 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:32:00 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:32:00 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:32:00 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:32:20 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:32:20 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:32:21 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:32:21 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:32:24 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:32:24 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:32:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:32:26 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:32:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:32:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, val/hateful_memes/cross_entropy: 1.0594, val/total_loss: 1.0594, val/hateful_memes/accuracy: 0.5593, val/hateful_memes/binary_f1: 0.2917, val/hateful_memes/roc_auc: 0.4822, num_updates: 3500, epoch: 7, iterations: 3500, max_updates: 6000, val_time: 27s 828ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:32:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3550/6000, train/hateful_memes/cross_entropy: 0.3523, train/hateful_memes/cross_entropy/avg: 0.5801, train/total_loss: 0.3523, train/total_loss/avg: 0.5801, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3550, iterations: 3550, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 970ms, time_since_start: 16m 51s 365ms, eta: 09m 34s 118ms\n",
            "\u001b[32m2022-12-09T07:32:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/6000, train/hateful_memes/cross_entropy: 0.3518, train/hateful_memes/cross_entropy/avg: 0.5761, train/total_loss: 0.3518, train/total_loss/avg: 0.5761, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3600, iterations: 3600, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 687ms, time_since_start: 17m 02s 052ms, eta: 09m 07s 860ms\n",
            "\u001b[32m2022-12-09T07:33:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3650/6000, train/hateful_memes/cross_entropy: 0.3518, train/hateful_memes/cross_entropy/avg: 0.5751, train/total_loss: 0.3518, train/total_loss/avg: 0.5751, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3650, iterations: 3650, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 720ms, time_since_start: 17m 12s 773ms, eta: 08m 58s 151ms\n",
            "\u001b[32m2022-12-09T07:33:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/6000, train/hateful_memes/cross_entropy: 0.3518, train/hateful_memes/cross_entropy/avg: 0.5700, train/total_loss: 0.3518, train/total_loss/avg: 0.5700, max mem: 3688.0, experiment: run, epoch: 7, num_updates: 3700, iterations: 3700, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 526ms, time_since_start: 17m 23s 300ms, eta: 08m 37s 168ms\n",
            "\u001b[32m2022-12-09T07:33:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3750/6000, train/hateful_memes/cross_entropy: 0.2997, train/hateful_memes/cross_entropy/avg: 0.5655, train/total_loss: 0.2997, train/total_loss/avg: 0.5655, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 3750, iterations: 3750, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 862ms, time_since_start: 17m 34s 162ms, eta: 08m 42s 035ms\n",
            "\u001b[32m2022-12-09T07:33:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/6000, train/hateful_memes/cross_entropy: 0.2910, train/hateful_memes/cross_entropy/avg: 0.5596, train/total_loss: 0.2910, train/total_loss/avg: 0.5596, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 3800, iterations: 3800, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 513ms, time_since_start: 17m 44s 675ms, eta: 08m 14s 032ms\n",
            "\u001b[32m2022-12-09T07:33:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3850/6000, train/hateful_memes/cross_entropy: 0.2652, train/hateful_memes/cross_entropy/avg: 0.5546, train/total_loss: 0.2652, train/total_loss/avg: 0.5546, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 3850, iterations: 3850, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 670ms, time_since_start: 17m 55s 346ms, eta: 08m 10s 027ms\n",
            "\u001b[32m2022-12-09T07:33:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/6000, train/hateful_memes/cross_entropy: 0.2512, train/hateful_memes/cross_entropy/avg: 0.5496, train/total_loss: 0.2512, train/total_loss/avg: 0.5496, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 3900, iterations: 3900, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 124ms, time_since_start: 18m 06s 471ms, eta: 08m 19s 019ms\n",
            "\u001b[32m2022-12-09T07:34:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3950/6000, train/hateful_memes/cross_entropy: 0.2382, train/hateful_memes/cross_entropy/avg: 0.5442, train/total_loss: 0.2382, train/total_loss/avg: 0.5442, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 3950, iterations: 3950, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 569ms, time_since_start: 18m 17s 040ms, eta: 07m 42s 806ms\n",
            "\u001b[32m2022-12-09T07:34:15 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T07:34:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:34:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, train/hateful_memes/cross_entropy: 0.2312, train/hateful_memes/cross_entropy/avg: 0.5383, train/total_loss: 0.2312, train/total_loss/avg: 0.5383, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 4000, iterations: 4000, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 559ms, time_since_start: 18m 30s 599ms, eta: 09m 39s 257ms\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:34:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:34:45 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:34:45 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:34:45 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:34:45 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:34:48 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:34:48 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:34:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:34:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:34:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:34:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, val/hateful_memes/cross_entropy: 1.1229, val/total_loss: 1.1229, val/hateful_memes/accuracy: 0.5537, val/hateful_memes/binary_f1: 0.3095, val/hateful_memes/roc_auc: 0.4634, num_updates: 4000, epoch: 8, iterations: 4000, max_updates: 6000, val_time: 33s 921ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:35:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4050/6000, train/hateful_memes/cross_entropy: 0.2312, train/hateful_memes/cross_entropy/avg: 0.5345, train/total_loss: 0.2312, train/total_loss/avg: 0.5345, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 4050, iterations: 4050, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 869ms, time_since_start: 19m 15s 392ms, eta: 07m 32s 722ms\n",
            "\u001b[32m2022-12-09T07:35:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/6000, train/hateful_memes/cross_entropy: 0.1921, train/hateful_memes/cross_entropy/avg: 0.5296, train/total_loss: 0.1921, train/total_loss/avg: 0.5296, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 4100, iterations: 4100, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 698ms, time_since_start: 19m 26s 090ms, eta: 07m 14s 201ms\n",
            "\u001b[32m2022-12-09T07:35:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4150/6000, train/hateful_memes/cross_entropy: 0.1921, train/hateful_memes/cross_entropy/avg: 0.5266, train/total_loss: 0.1921, train/total_loss/avg: 0.5266, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 4150, iterations: 4150, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 561ms, time_since_start: 19m 36s 652ms, eta: 06m 57s 356ms\n",
            "\u001b[32m2022-12-09T07:35:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/6000, train/hateful_memes/cross_entropy: 0.1738, train/hateful_memes/cross_entropy/avg: 0.5211, train/total_loss: 0.1738, train/total_loss/avg: 0.5211, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 4200, iterations: 4200, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 721ms, time_since_start: 19m 47s 373ms, eta: 06m 52s 215ms\n",
            "\u001b[32m2022-12-09T07:35:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4250/6000, train/hateful_memes/cross_entropy: 0.1738, train/hateful_memes/cross_entropy/avg: 0.5197, train/total_loss: 0.1738, train/total_loss/avg: 0.5197, max mem: 3688.0, experiment: run, epoch: 8, num_updates: 4250, iterations: 4250, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 619ms, time_since_start: 19m 57s 993ms, eta: 06m 36s 956ms\n",
            "\u001b[32m2022-12-09T07:35:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/6000, train/hateful_memes/cross_entropy: 0.1738, train/hateful_memes/cross_entropy/avg: 0.5146, train/total_loss: 0.1738, train/total_loss/avg: 0.5146, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4300, iterations: 4300, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 843ms, time_since_start: 20m 08s 837ms, eta: 06m 33s 763ms\n",
            "\u001b[32m2022-12-09T07:36:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4350/6000, train/hateful_memes/cross_entropy: 0.1602, train/hateful_memes/cross_entropy/avg: 0.5095, train/total_loss: 0.1602, train/total_loss/avg: 0.5095, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4350, iterations: 4350, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 679ms, time_since_start: 20m 19s 516ms, eta: 06m 16s 376ms\n",
            "\u001b[32m2022-12-09T07:36:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/6000, train/hateful_memes/cross_entropy: 0.1602, train/hateful_memes/cross_entropy/avg: 0.5041, train/total_loss: 0.1602, train/total_loss/avg: 0.5041, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4400, iterations: 4400, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 584ms, time_since_start: 20m 30s 101ms, eta: 06m 01s 738ms\n",
            "\u001b[32m2022-12-09T07:36:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4450/6000, train/hateful_memes/cross_entropy: 0.1602, train/hateful_memes/cross_entropy/avg: 0.5001, train/total_loss: 0.1602, train/total_loss/avg: 0.5001, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4450, iterations: 4450, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 620ms, time_since_start: 20m 40s 721ms, eta: 05m 51s 608ms\n",
            "\u001b[32m2022-12-09T07:36:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, train/hateful_memes/cross_entropy: 0.1558, train/hateful_memes/cross_entropy/avg: 0.4954, train/total_loss: 0.1558, train/total_loss/avg: 0.4954, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4500, iterations: 4500, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 505ms, time_since_start: 20m 51s 227ms, eta: 05m 36s 606ms\n",
            "\u001b[32m2022-12-09T07:36:38 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:36:38 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:36:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:36:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:36:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T07:36:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:37:11 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:37:11 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:37:11 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:37:11 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:37:14 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:37:14 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:37:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:37:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:37:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:37:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, val/hateful_memes/cross_entropy: 1.1768, val/total_loss: 1.1768, val/hateful_memes/accuracy: 0.5944, val/hateful_memes/binary_f1: 0.3091, val/hateful_memes/roc_auc: 0.4810, num_updates: 4500, epoch: 9, iterations: 4500, max_updates: 6000, val_time: 40s 619ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:37:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4550/6000, train/hateful_memes/cross_entropy: 0.1300, train/hateful_memes/cross_entropy/avg: 0.4905, train/total_loss: 0.1300, train/total_loss/avg: 0.4905, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4550, iterations: 4550, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 955ms, time_since_start: 21m 42s 811ms, eta: 05m 39s 317ms\n",
            "\u001b[32m2022-12-09T07:37:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/6000, train/hateful_memes/cross_entropy: 0.1271, train/hateful_memes/cross_entropy/avg: 0.4862, train/total_loss: 0.1271, train/total_loss/avg: 0.4862, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4600, iterations: 4600, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 830ms, time_since_start: 21m 53s 641ms, eta: 05m 23s 869ms\n",
            "\u001b[32m2022-12-09T07:37:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4650/6000, train/hateful_memes/cross_entropy: 0.1161, train/hateful_memes/cross_entropy/avg: 0.4814, train/total_loss: 0.1161, train/total_loss/avg: 0.4814, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4650, iterations: 4650, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 657ms, time_since_start: 22m 04s 298ms, eta: 05m 07s 308ms\n",
            "\u001b[32m2022-12-09T07:38:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/6000, train/hateful_memes/cross_entropy: 0.0968, train/hateful_memes/cross_entropy/avg: 0.4767, train/total_loss: 0.0968, train/total_loss/avg: 0.4767, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4700, iterations: 4700, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 736ms, time_since_start: 22m 15s 035ms, eta: 04m 58s 135ms\n",
            "\u001b[32m2022-12-09T07:38:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4750/6000, train/hateful_memes/cross_entropy: 0.0821, train/hateful_memes/cross_entropy/avg: 0.4721, train/total_loss: 0.0821, train/total_loss/avg: 0.4721, max mem: 3688.0, experiment: run, epoch: 9, num_updates: 4750, iterations: 4750, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 786ms, time_since_start: 22m 25s 822ms, eta: 04m 47s 997ms\n",
            "\u001b[32m2022-12-09T07:38:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/6000, train/hateful_memes/cross_entropy: 0.0751, train/hateful_memes/cross_entropy/avg: 0.4677, train/total_loss: 0.0751, train/total_loss/avg: 0.4677, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 4800, iterations: 4800, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 832ms, time_since_start: 22m 36s 654ms, eta: 04m 37s 660ms\n",
            "\u001b[32m2022-12-09T07:38:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4850/6000, train/hateful_memes/cross_entropy: 0.0751, train/hateful_memes/cross_entropy/avg: 0.4637, train/total_loss: 0.0751, train/total_loss/avg: 0.4637, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 4850, iterations: 4850, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 632ms, time_since_start: 22m 47s 287ms, eta: 04m 21s 180ms\n",
            "\u001b[32m2022-12-09T07:38:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/6000, train/hateful_memes/cross_entropy: 0.0684, train/hateful_memes/cross_entropy/avg: 0.4596, train/total_loss: 0.0684, train/total_loss/avg: 0.4596, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 4900, iterations: 4900, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 689ms, time_since_start: 22m 57s 976ms, eta: 04m 11s 157ms\n",
            "\u001b[32m2022-12-09T07:38:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4950/6000, train/hateful_memes/cross_entropy: 0.0658, train/hateful_memes/cross_entropy/avg: 0.4553, train/total_loss: 0.0658, train/total_loss/avg: 0.4553, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 4950, iterations: 4950, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 111ms, time_since_start: 23m 09s 088ms, eta: 04m 09s 212ms\n",
            "\u001b[32m2022-12-09T07:39:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T07:39:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:39:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, train/hateful_memes/cross_entropy: 0.0638, train/hateful_memes/cross_entropy/avg: 0.4512, train/total_loss: 0.0638, train/total_loss/avg: 0.4512, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 5000, iterations: 5000, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 677ms, time_since_start: 23m 22s 766ms, eta: 04m 52s 159ms\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:39:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:39:57 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:39:57 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:39:57 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:39:57 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:40:01 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:40:01 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:40:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:40:03 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:40:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:40:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, val/hateful_memes/cross_entropy: 1.1616, val/total_loss: 1.1616, val/hateful_memes/accuracy: 0.5815, val/hateful_memes/binary_f1: 0.3543, val/hateful_memes/roc_auc: 0.4993, num_updates: 5000, epoch: 10, iterations: 5000, max_updates: 6000, val_time: 54s 356ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:40:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5050/6000, train/hateful_memes/cross_entropy: 0.0557, train/hateful_memes/cross_entropy/avg: 0.4470, train/total_loss: 0.0557, train/total_loss/avg: 0.4470, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 5050, iterations: 5050, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 984ms, time_since_start: 24m 28s 108ms, eta: 03m 42s 903ms\n",
            "\u001b[32m2022-12-09T07:40:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/6000, train/hateful_memes/cross_entropy: 0.0550, train/hateful_memes/cross_entropy/avg: 0.4429, train/total_loss: 0.0550, train/total_loss/avg: 0.4429, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 5100, iterations: 5100, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 553ms, time_since_start: 24m 38s 662ms, eta: 03m 22s 878ms\n",
            "\u001b[32m2022-12-09T07:40:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5150/6000, train/hateful_memes/cross_entropy: 0.0550, train/hateful_memes/cross_entropy/avg: 0.4392, train/total_loss: 0.0550, train/total_loss/avg: 0.4392, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 5150, iterations: 5150, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 718ms, time_since_start: 24m 49s 380ms, eta: 03m 14s 608ms\n",
            "\u001b[32m2022-12-09T07:40:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/6000, train/hateful_memes/cross_entropy: 0.0481, train/hateful_memes/cross_entropy/avg: 0.4354, train/total_loss: 0.0481, train/total_loss/avg: 0.4354, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 5200, iterations: 5200, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 692ms, time_since_start: 25m 073ms, eta: 03m 02s 713ms\n",
            "\u001b[32m2022-12-09T07:40:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5250/6000, train/hateful_memes/cross_entropy: 0.0481, train/hateful_memes/cross_entropy/avg: 0.4332, train/total_loss: 0.0481, train/total_loss/avg: 0.4332, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 5250, iterations: 5250, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 718ms, time_since_start: 25m 10s 791ms, eta: 02m 51s 711ms\n",
            "\u001b[32m2022-12-09T07:41:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/6000, train/hateful_memes/cross_entropy: 0.0481, train/hateful_memes/cross_entropy/avg: 0.4341, train/total_loss: 0.0481, train/total_loss/avg: 0.4341, max mem: 3688.0, experiment: run, epoch: 10, num_updates: 5300, iterations: 5300, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 662ms, time_since_start: 25m 21s 454ms, eta: 02m 39s 420ms\n",
            "\u001b[32m2022-12-09T07:41:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5350/6000, train/hateful_memes/cross_entropy: 0.0481, train/hateful_memes/cross_entropy/avg: 0.4308, train/total_loss: 0.0481, train/total_loss/avg: 0.4308, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5350, iterations: 5350, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 923ms, time_since_start: 25m 32s 377ms, eta: 02m 31s 656ms\n",
            "\u001b[32m2022-12-09T07:41:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/6000, train/hateful_memes/cross_entropy: 0.0550, train/hateful_memes/cross_entropy/avg: 0.4278, train/total_loss: 0.0550, train/total_loss/avg: 0.4278, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5400, iterations: 5400, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 631ms, time_since_start: 25m 43s 008ms, eta: 02m 16s 251ms\n",
            "\u001b[32m2022-12-09T07:41:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5450/6000, train/hateful_memes/cross_entropy: 0.0481, train/hateful_memes/cross_entropy/avg: 0.4241, train/total_loss: 0.0481, train/total_loss/avg: 0.4241, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5450, iterations: 5450, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 751ms, time_since_start: 25m 53s 759ms, eta: 02m 06s 304ms\n",
            "\u001b[32m2022-12-09T07:41:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, train/hateful_memes/cross_entropy: 0.0469, train/hateful_memes/cross_entropy/avg: 0.4204, train/total_loss: 0.0469, train/total_loss/avg: 0.4204, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5500, iterations: 5500, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 795ms, time_since_start: 26m 04s 555ms, eta: 01m 55s 298ms\n",
            "\u001b[32m2022-12-09T07:41:52 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:41:52 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:41:52 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:41:52 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:41:52 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:41:52 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:42:12 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:42:12 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:42:12 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:42:12 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:42:15 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:42:15 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:42:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, val/hateful_memes/cross_entropy: 1.2507, val/total_loss: 1.2507, val/hateful_memes/accuracy: 0.5537, val/hateful_memes/binary_f1: 0.3173, val/hateful_memes/roc_auc: 0.4744, num_updates: 5500, epoch: 11, iterations: 5500, max_updates: 6000, val_time: 24s 200ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:42:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5550/6000, train/hateful_memes/cross_entropy: 0.0451, train/hateful_memes/cross_entropy/avg: 0.4167, train/total_loss: 0.0451, train/total_loss/avg: 0.4167, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5550, iterations: 5550, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 947ms, time_since_start: 26m 39s 704ms, eta: 01m 45s 227ms\n",
            "\u001b[32m2022-12-09T07:42:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/6000, train/hateful_memes/cross_entropy: 0.0397, train/hateful_memes/cross_entropy/avg: 0.4131, train/total_loss: 0.0397, train/total_loss/avg: 0.4131, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5600, iterations: 5600, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 669ms, time_since_start: 26m 50s 374ms, eta: 01m 31s 161ms\n",
            "\u001b[32m2022-12-09T07:42:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5650/6000, train/hateful_memes/cross_entropy: 0.0446, train/hateful_memes/cross_entropy/avg: 0.4099, train/total_loss: 0.0446, train/total_loss/avg: 0.4099, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5650, iterations: 5650, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 787ms, time_since_start: 27m 01s 161ms, eta: 01m 20s 645ms\n",
            "\u001b[32m2022-12-09T07:42:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/6000, train/hateful_memes/cross_entropy: 0.0397, train/hateful_memes/cross_entropy/avg: 0.4064, train/total_loss: 0.0397, train/total_loss/avg: 0.4064, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5700, iterations: 5700, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 852ms, time_since_start: 27m 12s 014ms, eta: 01m 09s 545ms\n",
            "\u001b[32m2022-12-09T07:43:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5750/6000, train/hateful_memes/cross_entropy: 0.0397, train/hateful_memes/cross_entropy/avg: 0.4031, train/total_loss: 0.0397, train/total_loss/avg: 0.4031, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5750, iterations: 5750, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 754ms, time_since_start: 27m 22s 769ms, eta: 57s 428ms\n",
            "\u001b[32m2022-12-09T07:43:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/6000, train/hateful_memes/cross_entropy: 0.0369, train/hateful_memes/cross_entropy/avg: 0.3998, train/total_loss: 0.0369, train/total_loss/avg: 0.3998, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5800, iterations: 5800, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 649ms, time_since_start: 27m 33s 419ms, eta: 45s 496ms\n",
            "\u001b[32m2022-12-09T07:43:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5850/6000, train/hateful_memes/cross_entropy: 0.0369, train/hateful_memes/cross_entropy/avg: 0.3970, train/total_loss: 0.0369, train/total_loss/avg: 0.3970, max mem: 3688.0, experiment: run, epoch: 11, num_updates: 5850, iterations: 5850, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 605ms, time_since_start: 27m 44s 024ms, eta: 33s 980ms\n",
            "\u001b[32m2022-12-09T07:43:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/6000, train/hateful_memes/cross_entropy: 0.0367, train/hateful_memes/cross_entropy/avg: 0.3938, train/total_loss: 0.0367, train/total_loss/avg: 0.3938, max mem: 3688.0, experiment: run, epoch: 12, num_updates: 5900, iterations: 5900, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 926ms, time_since_start: 27m 54s 951ms, eta: 23s 339ms\n",
            "\u001b[32m2022-12-09T07:43:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5950/6000, train/hateful_memes/cross_entropy: 0.0369, train/hateful_memes/cross_entropy/avg: 0.3912, train/total_loss: 0.0369, train/total_loss/avg: 0.3912, max mem: 3688.0, experiment: run, epoch: 12, num_updates: 5950, iterations: 5950, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 947ms, time_since_start: 28m 05s 898ms, eta: 11s 691ms\n",
            "\u001b[32m2022-12-09T07:44:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T07:44:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:44:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, train/hateful_memes/cross_entropy: 0.0322, train/hateful_memes/cross_entropy/avg: 0.3882, train/total_loss: 0.0322, train/total_loss/avg: 0.3882, max mem: 3688.0, experiment: run, epoch: 12, num_updates: 6000, iterations: 6000, max_updates: 6000, lr: 0., ups: 3.33, time: 15s 625ms, time_since_start: 28m 21s 523ms, eta: 0ms\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:44:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3d94bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3ce08ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:44:31 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:44:31 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:44:31 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:44:31 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:44:35 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:44:35 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:44:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, val/hateful_memes/cross_entropy: 1.2544, val/total_loss: 1.2544, val/hateful_memes/accuracy: 0.5796, val/hateful_memes/binary_f1: 0.3224, val/hateful_memes/roc_auc: 0.4710, num_updates: 6000, epoch: 12, iterations: 6000, max_updates: 6000, val_time: 26s 497ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.530544\n",
            "\u001b[32m2022-12-09T07:44:35 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2022-12-09T07:44:35 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2022-12-09T07:44:35 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2022-12-09T07:44:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-12-09T07:44:39 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 1000\n",
            "\u001b[32m2022-12-09T07:44:39 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 1000\n",
            "\u001b[32m2022-12-09T07:44:39 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 2\n",
            "\u001b[32m2022-12-09T07:44:40 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-12-09T07:44:40 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[32m2022-12-09T07:44:40 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:44:40 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:44:40 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:44:40 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3da6bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3da6bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3da6bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f3da6bfc000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2e67 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cf28ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cf28ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cf28ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f3cf28ca000 @  0x7f4239b29887 0x7f412edb3b73 0x7f412eda2eab 0x7f412eda3981 0x7f412ed72272 0x7f412ed91ef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:44:59 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:44:59 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:44:59 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:44:59 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "100% 125/125 [00:31<00:00,  4.03it/s]\n",
            "\u001b[32m2022-12-09T07:45:11 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 125\n",
            "\u001b[32m2022-12-09T07:45:11 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:45:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, test/hateful_memes/cross_entropy: 0.6657, test/total_loss: 0.6657, test/hateful_memes/accuracy: 0.6200, test/hateful_memes/binary_f1: 0.1324, test/hateful_memes/roc_auc: 0.5525\n",
            "\u001b[32m2022-12-09T07:45:12 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 29m 24s 302ms\n"
          ]
        }
      ],
      "source": [
        "!mmf_run config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/concat_bert/defaults.yaml \\\n",
        "  model=concat_vl \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=6000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100 \\\n",
        "  env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## new config with 3 layer and converge mlp\n",
        "!mmf_run config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/concat_bert/defaults.yaml \\\n",
        "  model=concat_vl \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=6000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100 \\\n",
        "  env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V_a58413DgF",
        "outputId": "302af2e6-e85a-464b-dc05-3433c21dc34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 07:49:49.070683: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf: \u001b[0mLogging to: /drive/MyDrive/final_project/mmf/projects/hateful_memes/save/train.log\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/concat_bert/defaults.yaml', 'model=concat_vl', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=6000', 'training.batch_size=16', 'training.evaluation_interval=500', 'trainer.params.gpus=100', 'env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save'])\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu111\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf.utils.general: \u001b[0mCUDA Device 0 is: A100-SXM4-40GB\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf_cli.run: \u001b[0mUsing seed 58060130\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T07:49:58 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "\u001b[32m2022-12-09T07:50:14 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-12-09T07:50:14 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-12-09T07:50:14 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-12-09T07:50:14 | mmf.trainers.mmf_trainer: \u001b[0mLanguageAndVisionConcat(\n",
            "  (vision_module): ResNet152ImageEncoder(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (6): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (7): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (6): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (7): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (8): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (9): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (10): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (11): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (12): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (13): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (14): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (15): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (16): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (17): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (18): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (19): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (20): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (21): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (22): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (23): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (24): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (25): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (26): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (27): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (28): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (29): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (30): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (31): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (32): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (33): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (34): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (35): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (classifier): MLPClassifer(\n",
            "    (layers): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.5, inplace=False)\n",
            "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ReLU()\n",
            "      (7): Dropout(p=0.5, inplace=False)\n",
            "      (8): Linear(in_features=128, out_features=64, bias=True)\n",
            "      (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (10): ReLU()\n",
            "      (11): Dropout(p=0.5, inplace=False)\n",
            "      (12): Linear(in_features=64, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (language_module): ProjectionEmbedding(\n",
            "    (layers): Linear(in_features=300, out_features=300, bias=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fusion): Linear(in_features=2348, out_features=512, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-12-09T07:50:15 | mmf.utils.general: \u001b[0mTotal Parameters: 59610302. Trained Parameters: 59610302\n",
            "\u001b[32m2022-12-09T07:50:15 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2022-12-09T07:50:15 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:50:15 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T07:50:15 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:50:15 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f97e0bfc000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6fe67 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f97e0bfc000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6fe67 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f97e0bfc000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6fe67 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f97e0bfc000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6fe67 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f972c8ca000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6feab 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f972c8ca000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6feab 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f972c8ca000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6feab 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f972c8ca000 @  0x7f9b71af4887 0x7f9a69d80b73 0x7f9a69d6feab 0x7f9a69d70981 0x7f9a69d3f272 0x7f9a69d5eef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:50:30 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:50:30 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:50:30 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:50:30 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T07:50:30 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T07:50:30 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[32m2022-12-09T07:50:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/6000, train/hateful_memes/cross_entropy: 0.7243, train/hateful_memes/cross_entropy/avg: 0.7243, train/total_loss: 0.7243, train/total_loss/avg: 0.7243, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 6000, lr: 0., ups: 1.92, time: 26s 521ms, time_since_start: 26s 631ms, eta: 56m 10s 716ms\n",
            "\u001b[32m2022-12-09T07:50:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/6000, train/hateful_memes/cross_entropy: 0.7243, train/hateful_memes/cross_entropy/avg: 0.8288, train/total_loss: 0.7243, train/total_loss/avg: 0.8288, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 669ms, time_since_start: 37s 300ms, eta: 22m 24s 604ms\n",
            "\u001b[32m2022-12-09T07:51:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/6000, train/hateful_memes/cross_entropy: 0.7365, train/hateful_memes/cross_entropy/avg: 0.7980, train/total_loss: 0.7365, train/total_loss/avg: 0.7980, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 615ms, time_since_start: 47s 916ms, eta: 22m 06s 488ms\n",
            "\u001b[32m2022-12-09T07:51:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/6000, train/hateful_memes/cross_entropy: 0.7365, train/hateful_memes/cross_entropy/avg: 0.8158, train/total_loss: 0.7365, train/total_loss/avg: 0.8158, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 729ms, time_since_start: 58s 645ms, eta: 22m 09s 206ms\n",
            "\u001b[32m2022-12-09T07:51:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/6000, train/hateful_memes/cross_entropy: 0.7365, train/hateful_memes/cross_entropy/avg: 0.7987, train/total_loss: 0.7365, train/total_loss/avg: 0.7987, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 772ms, time_since_start: 01m 09s 417ms, eta: 22m 03s 091ms\n",
            "\u001b[32m2022-12-09T07:51:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/6000, train/hateful_memes/cross_entropy: 0.7306, train/hateful_memes/cross_entropy/avg: 0.7810, train/total_loss: 0.7306, train/total_loss/avg: 0.7810, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 667ms, time_since_start: 01m 20s 085ms, eta: 21m 38s 848ms\n",
            "\u001b[32m2022-12-09T07:51:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/6000, train/hateful_memes/cross_entropy: 0.7306, train/hateful_memes/cross_entropy/avg: 0.7561, train/total_loss: 0.7306, train/total_loss/avg: 0.7561, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 720ms, time_since_start: 01m 30s 806ms, eta: 21m 33s 755ms\n",
            "\u001b[32m2022-12-09T07:51:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/6000, train/hateful_memes/cross_entropy: 0.7306, train/hateful_memes/cross_entropy/avg: 0.7671, train/total_loss: 0.7306, train/total_loss/avg: 0.7671, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 734ms, time_since_start: 01m 41s 540ms, eta: 21m 23s 993ms\n",
            "\u001b[32m2022-12-09T07:52:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/6000, train/hateful_memes/cross_entropy: 0.7365, train/hateful_memes/cross_entropy/avg: 0.7705, train/total_loss: 0.7365, train/total_loss/avg: 0.7705, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 720ms, time_since_start: 01m 52s 260ms, eta: 21m 10s 847ms\n",
            "\u001b[32m2022-12-09T07:52:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, train/hateful_memes/cross_entropy: 0.7365, train/hateful_memes/cross_entropy/avg: 0.7691, train/total_loss: 0.7365, train/total_loss/avg: 0.7691, max mem: 3683.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 794ms, time_since_start: 02m 03s 055ms, eta: 21m 08s 146ms\n",
            "\u001b[32m2022-12-09T07:52:18 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:52:18 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:52:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:52:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:52:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:52:18 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96e8bfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96e8bfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96e8bfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96e8bfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96348ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96348ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96348ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96348ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:52:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:52:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:52:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:52:35 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:52:38 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:52:38 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:52:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:52:41 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T07:52:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:52:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:52:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, val/hateful_memes/cross_entropy: 0.6970, val/total_loss: 0.6970, val/hateful_memes/accuracy: 0.4815, val/hateful_memes/binary_f1: 0.4656, val/hateful_memes/roc_auc: 0.5305, num_updates: 500, epoch: 1, iterations: 500, max_updates: 6000, val_time: 28s 372ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.530471\n",
            "\u001b[32m2022-12-09T07:52:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7732, train/total_loss: 0.7563, train/total_loss/avg: 0.7732, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 319ms, time_since_start: 02m 42s 748ms, eta: 21m 57s 674ms\n",
            "\u001b[32m2022-12-09T07:53:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7774, train/total_loss: 0.7563, train/total_loss/avg: 0.7774, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 745ms, time_since_start: 02m 53s 493ms, eta: 20m 39s 449ms\n",
            "\u001b[32m2022-12-09T07:53:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7743, train/total_loss: 0.7563, train/total_loss/avg: 0.7743, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 739ms, time_since_start: 03m 04s 232ms, eta: 20m 27s 232ms\n",
            "\u001b[32m2022-12-09T07:53:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7743, train/total_loss: 0.7563, train/total_loss/avg: 0.7743, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 716ms, time_since_start: 03m 14s 949ms, eta: 20m 13s 175ms\n",
            "\u001b[32m2022-12-09T07:53:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/6000, train/hateful_memes/cross_entropy: 0.7745, train/hateful_memes/cross_entropy/avg: 0.7765, train/total_loss: 0.7745, train/total_loss/avg: 0.7765, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 957ms, time_since_start: 03m 25s 906ms, eta: 20m 28s 725ms\n",
            "\u001b[32m2022-12-09T07:53:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/6000, train/hateful_memes/cross_entropy: 0.7745, train/hateful_memes/cross_entropy/avg: 0.7791, train/total_loss: 0.7745, train/total_loss/avg: 0.7791, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 890ms, time_since_start: 03m 36s 797ms, eta: 20m 09s 677ms\n",
            "\u001b[32m2022-12-09T07:54:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/6000, train/hateful_memes/cross_entropy: 0.7745, train/hateful_memes/cross_entropy/avg: 0.7781, train/total_loss: 0.7745, train/total_loss/avg: 0.7781, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 710ms, time_since_start: 03m 47s 507ms, eta: 19m 38s 187ms\n",
            "\u001b[32m2022-12-09T07:54:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/6000, train/hateful_memes/cross_entropy: 0.7745, train/hateful_memes/cross_entropy/avg: 0.7849, train/total_loss: 0.7745, train/total_loss/avg: 0.7849, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 900, iterations: 900, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 828ms, time_since_start: 03m 58s 335ms, eta: 19m 39s 589ms\n",
            "\u001b[32m2022-12-09T07:54:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/6000, train/hateful_memes/cross_entropy: 0.7745, train/hateful_memes/cross_entropy/avg: 0.7771, train/total_loss: 0.7745, train/total_loss/avg: 0.7771, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 950, iterations: 950, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 655ms, time_since_start: 04m 08s 991ms, eta: 19m 09s 379ms\n",
            "\u001b[32m2022-12-09T07:54:34 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T07:54:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:54:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:54:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:54:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, train/hateful_memes/cross_entropy: 0.7745, train/hateful_memes/cross_entropy/avg: 0.7780, train/total_loss: 0.7745, train/total_loss/avg: 0.7780, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 1000, iterations: 1000, max_updates: 6000, lr: 0.00003, ups: 3.57, time: 14s 907ms, time_since_start: 04m 23s 898ms, eta: 26m 32s 089ms\n",
            "\u001b[32m2022-12-09T07:54:38 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:54:38 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:54:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:54:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T07:54:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:54:39 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:55:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:55:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:55:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:55:23 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:55:27 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:55:27 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:55:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:55:29 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T07:55:31 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:55:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:55:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, val/hateful_memes/cross_entropy: 0.6770, val/total_loss: 0.6770, val/hateful_memes/accuracy: 0.5907, val/hateful_memes/binary_f1: 0.3442, val/hateful_memes/roc_auc: 0.5420, num_updates: 1000, epoch: 2, iterations: 1000, max_updates: 6000, val_time: 54s 523ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.541971\n",
            "\u001b[32m2022-12-09T07:55:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/6000, train/hateful_memes/cross_entropy: 0.7745, train/hateful_memes/cross_entropy/avg: 0.7724, train/total_loss: 0.7745, train/total_loss/avg: 0.7724, max mem: 3683.0, experiment: run, epoch: 2, num_updates: 1050, iterations: 1050, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 995ms, time_since_start: 05m 29s 418ms, eta: 19m 22s 545ms\n",
            "\u001b[32m2022-12-09T07:55:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/6000, train/hateful_memes/cross_entropy: 0.7629, train/hateful_memes/cross_entropy/avg: 0.7678, train/total_loss: 0.7629, train/total_loss/avg: 0.7678, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 125ms, time_since_start: 05m 40s 543ms, eta: 19m 24s 407ms\n",
            "\u001b[32m2022-12-09T07:56:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/6000, train/hateful_memes/cross_entropy: 0.7629, train/hateful_memes/cross_entropy/avg: 0.7655, train/total_loss: 0.7629, train/total_loss/avg: 0.7655, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 825ms, time_since_start: 05m 51s 369ms, eta: 18m 41s 483ms\n",
            "\u001b[32m2022-12-09T07:56:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7603, train/total_loss: 0.7563, train/total_loss/avg: 0.7603, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 665ms, time_since_start: 06m 02s 035ms, eta: 18m 13s 523ms\n",
            "\u001b[32m2022-12-09T07:56:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7528, train/total_loss: 0.7563, train/total_loss/avg: 0.7528, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 903ms, time_since_start: 06m 12s 938ms, eta: 18m 26s 267ms\n",
            "\u001b[32m2022-12-09T07:56:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7463, train/total_loss: 0.7563, train/total_loss/avg: 0.7463, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 770ms, time_since_start: 06m 23s 709ms, eta: 18m 01s 324ms\n",
            "\u001b[32m2022-12-09T07:56:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/6000, train/hateful_memes/cross_entropy: 0.7629, train/hateful_memes/cross_entropy/avg: 0.7473, train/total_loss: 0.7629, train/total_loss/avg: 0.7473, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 720ms, time_since_start: 06m 34s 429ms, eta: 17m 44s 786ms\n",
            "\u001b[32m2022-12-09T07:57:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/6000, train/hateful_memes/cross_entropy: 0.7629, train/hateful_memes/cross_entropy/avg: 0.7495, train/total_loss: 0.7629, train/total_loss/avg: 0.7495, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 730ms, time_since_start: 06m 45s 159ms, eta: 17m 34s 290ms\n",
            "\u001b[32m2022-12-09T07:57:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/6000, train/hateful_memes/cross_entropy: 0.7563, train/hateful_memes/cross_entropy/avg: 0.7456, train/total_loss: 0.7563, train/total_loss/avg: 0.7456, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 899ms, time_since_start: 06m 56s 059ms, eta: 17m 39s 324ms\n",
            "\u001b[32m2022-12-09T07:57:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, train/hateful_memes/cross_entropy: 0.7629, train/hateful_memes/cross_entropy/avg: 0.7472, train/total_loss: 0.7629, train/total_loss/avg: 0.7472, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 785ms, time_since_start: 07m 06s 845ms, eta: 17m 16s 740ms\n",
            "\u001b[32m2022-12-09T07:57:21 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T07:57:21 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T07:57:22 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T07:57:22 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T07:57:22 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T07:57:22 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T07:58:08 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:58:08 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:58:08 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:58:08 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T07:58:11 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T07:58:11 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T07:58:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T07:58:13 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T07:58:15 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T07:58:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T07:58:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, val/hateful_memes/cross_entropy: 0.6638, val/total_loss: 0.6638, val/hateful_memes/accuracy: 0.6000, val/hateful_memes/binary_f1: 0.2174, val/hateful_memes/roc_auc: 0.5469, num_updates: 1500, epoch: 3, iterations: 1500, max_updates: 6000, val_time: 55s 867ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T07:58:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/6000, train/hateful_memes/cross_entropy: 0.7374, train/hateful_memes/cross_entropy/avg: 0.7420, train/total_loss: 0.7374, train/total_loss/avg: 0.7420, max mem: 3683.0, experiment: run, epoch: 3, num_updates: 1550, iterations: 1550, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 110ms, time_since_start: 08m 13s 825ms, eta: 17m 36s 099ms\n",
            "\u001b[32m2022-12-09T07:58:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/6000, train/hateful_memes/cross_entropy: 0.7150, train/hateful_memes/cross_entropy/avg: 0.7374, train/total_loss: 0.7150, train/total_loss/avg: 0.7374, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1600, iterations: 1600, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 243ms, time_since_start: 08m 25s 069ms, eta: 17m 36s 703ms\n",
            "\u001b[32m2022-12-09T07:58:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/6000, train/hateful_memes/cross_entropy: 0.6720, train/hateful_memes/cross_entropy/avg: 0.7340, train/total_loss: 0.6720, train/total_loss/avg: 0.7340, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1650, iterations: 1650, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 043ms, time_since_start: 08m 36s 112ms, eta: 17m 06s 089ms\n",
            "\u001b[32m2022-12-09T07:59:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/6000, train/hateful_memes/cross_entropy: 0.6612, train/hateful_memes/cross_entropy/avg: 0.7311, train/total_loss: 0.6612, train/total_loss/avg: 0.7311, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1700, iterations: 1700, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 684ms, time_since_start: 08m 46s 796ms, eta: 16m 21s 306ms\n",
            "\u001b[32m2022-12-09T07:59:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/6000, train/hateful_memes/cross_entropy: 0.6612, train/hateful_memes/cross_entropy/avg: 0.7318, train/total_loss: 0.6612, train/total_loss/avg: 0.7318, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 737ms, time_since_start: 08m 57s 533ms, eta: 16m 14s 736ms\n",
            "\u001b[32m2022-12-09T07:59:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/6000, train/hateful_memes/cross_entropy: 0.6400, train/hateful_memes/cross_entropy/avg: 0.7270, train/total_loss: 0.6400, train/total_loss/avg: 0.7270, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 740ms, time_since_start: 09m 08s 274ms, eta: 16m 03s 585ms\n",
            "\u001b[32m2022-12-09T07:59:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/6000, train/hateful_memes/cross_entropy: 0.6400, train/hateful_memes/cross_entropy/avg: 0.7331, train/total_loss: 0.6400, train/total_loss/avg: 0.7331, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 926ms, time_since_start: 09m 19s 200ms, eta: 16m 08s 552ms\n",
            "\u001b[32m2022-12-09T07:59:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/6000, train/hateful_memes/cross_entropy: 0.6400, train/hateful_memes/cross_entropy/avg: 0.7317, train/total_loss: 0.6400, train/total_loss/avg: 0.7317, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 784ms, time_since_start: 09m 29s 984ms, eta: 15m 44s 424ms\n",
            "\u001b[32m2022-12-09T07:59:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/6000, train/hateful_memes/cross_entropy: 0.6400, train/hateful_memes/cross_entropy/avg: 0.7284, train/total_loss: 0.6400, train/total_loss/avg: 0.7284, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 667ms, time_since_start: 09m 40s 652ms, eta: 15m 22s 813ms\n",
            "\u001b[32m2022-12-09T08:00:06 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:00:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:00:07 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, train/hateful_memes/cross_entropy: 0.6400, train/hateful_memes/cross_entropy/avg: 0.7295, train/total_loss: 0.6400, train/total_loss/avg: 0.7295, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 762ms, time_since_start: 09m 54s 415ms, eta: 19m 35s 893ms\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:00:09 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:00:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:00:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:00:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:00:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:00:56 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:00:56 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:00:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:00:59 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:01:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:01:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, val/hateful_memes/cross_entropy: 0.6682, val/total_loss: 0.6682, val/hateful_memes/accuracy: 0.6130, val/hateful_memes/binary_f1: 0.2867, val/hateful_memes/roc_auc: 0.5384, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 6000, val_time: 51s 208ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:01:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/6000, train/hateful_memes/cross_entropy: 0.6400, train/hateful_memes/cross_entropy/avg: 0.7277, train/total_loss: 0.6400, train/total_loss/avg: 0.7277, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 6000, lr: 0.00005, ups: 4.55, time: 11s 766ms, time_since_start: 10m 57s 391ms, eta: 16m 32s 785ms\n",
            "\u001b[32m2022-12-09T08:01:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/6000, train/hateful_memes/cross_entropy: 0.6359, train/hateful_memes/cross_entropy/avg: 0.7253, train/total_loss: 0.6359, train/total_loss/avg: 0.7253, max mem: 3683.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 849ms, time_since_start: 11m 08s 240ms, eta: 15m 03s 806ms\n",
            "\u001b[32m2022-12-09T08:01:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/6000, train/hateful_memes/cross_entropy: 0.6359, train/hateful_memes/cross_entropy/avg: 0.7250, train/total_loss: 0.6359, train/total_loss/avg: 0.7250, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 6000, lr: 0.00005, ups: 4.55, time: 11s 192ms, time_since_start: 11m 19s 432ms, eta: 15m 20s 390ms\n",
            "\u001b[32m2022-12-09T08:01:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.7203, train/total_loss: 0.6355, train/total_loss/avg: 0.7203, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 921ms, time_since_start: 11m 30s 354ms, eta: 14m 46s 493ms\n",
            "\u001b[32m2022-12-09T08:01:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/6000, train/hateful_memes/cross_entropy: 0.6359, train/hateful_memes/cross_entropy/avg: 0.7196, train/total_loss: 0.6359, train/total_loss/avg: 0.7196, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 963ms, time_since_start: 11m 41s 317ms, eta: 14m 38s 147ms\n",
            "\u001b[32m2022-12-09T08:02:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/6000, train/hateful_memes/cross_entropy: 0.6550, train/hateful_memes/cross_entropy/avg: 0.7236, train/total_loss: 0.6550, train/total_loss/avg: 0.7236, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 905ms, time_since_start: 11m 52s 223ms, eta: 14m 21s 884ms\n",
            "\u001b[32m2022-12-09T08:02:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/6000, train/hateful_memes/cross_entropy: 0.6550, train/hateful_memes/cross_entropy/avg: 0.7259, train/total_loss: 0.6550, train/total_loss/avg: 0.7259, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 848ms, time_since_start: 12m 03s 071ms, eta: 14m 05s 796ms\n",
            "\u001b[32m2022-12-09T08:02:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/6000, train/hateful_memes/cross_entropy: 0.6359, train/hateful_memes/cross_entropy/avg: 0.7227, train/total_loss: 0.6359, train/total_loss/avg: 0.7227, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 6000, lr: 0.00005, ups: 5.00, time: 10s 838ms, time_since_start: 12m 13s 910ms, eta: 13m 53s 461ms\n",
            "\u001b[32m2022-12-09T08:02:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/6000, train/hateful_memes/cross_entropy: 0.6403, train/hateful_memes/cross_entropy/avg: 0.7210, train/total_loss: 0.6403, train/total_loss/avg: 0.7210, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 855ms, time_since_start: 12m 24s 766ms, eta: 13m 43s 174ms\n",
            "\u001b[32m2022-12-09T08:02:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.7169, train/total_loss: 0.6355, train/total_loss/avg: 0.7169, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 840ms, time_since_start: 12m 35s 606ms, eta: 13m 30s 425ms\n",
            "\u001b[32m2022-12-09T08:02:50 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:02:50 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:02:50 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:02:50 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:02:50 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:02:50 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:03:09 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:03:09 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:03:09 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:03:09 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:03:13 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:03:13 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:03:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:03:15 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:03:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:03:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, val/hateful_memes/cross_entropy: 0.6653, val/total_loss: 0.6653, val/hateful_memes/accuracy: 0.6352, val/hateful_memes/binary_f1: 0.2024, val/hateful_memes/roc_auc: 0.5462, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 6000, val_time: 26s 423ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:03:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.7129, train/total_loss: 0.6355, train/total_loss/avg: 0.7129, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 324ms, time_since_start: 13m 13s 355ms, eta: 13m 54s 528ms\n",
            "\u001b[32m2022-12-09T08:03:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/6000, train/hateful_memes/cross_entropy: 0.6403, train/hateful_memes/cross_entropy/avg: 0.7150, train/total_loss: 0.6403, train/total_loss/avg: 0.7150, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 053ms, time_since_start: 13m 24s 409ms, eta: 13m 22s 749ms\n",
            "\u001b[32m2022-12-09T08:03:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/6000, train/hateful_memes/cross_entropy: 0.6403, train/hateful_memes/cross_entropy/avg: 0.7109, train/total_loss: 0.6403, train/total_loss/avg: 0.7109, max mem: 3683.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 306ms, time_since_start: 13m 35s 716ms, eta: 13m 29s 054ms\n",
            "\u001b[32m2022-12-09T08:04:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/6000, train/hateful_memes/cross_entropy: 0.6403, train/hateful_memes/cross_entropy/avg: 0.7067, train/total_loss: 0.6403, train/total_loss/avg: 0.7067, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 222ms, time_since_start: 13m 46s 938ms, eta: 13m 11s 062ms\n",
            "\u001b[32m2022-12-09T08:04:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/6000, train/hateful_memes/cross_entropy: 0.6285, train/hateful_memes/cross_entropy/avg: 0.7048, train/total_loss: 0.6285, train/total_loss/avg: 0.7048, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 955ms, time_since_start: 13m 57s 893ms, eta: 12m 40s 498ms\n",
            "\u001b[32m2022-12-09T08:04:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/6000, train/hateful_memes/cross_entropy: 0.6285, train/hateful_memes/cross_entropy/avg: 0.7014, train/total_loss: 0.6285, train/total_loss/avg: 0.7014, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 885ms, time_since_start: 14m 08s 779ms, eta: 12m 24s 045ms\n",
            "\u001b[32m2022-12-09T08:04:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/6000, train/hateful_memes/cross_entropy: 0.6058, train/hateful_memes/cross_entropy/avg: 0.6997, train/total_loss: 0.6058, train/total_loss/avg: 0.6997, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 856ms, time_since_start: 14m 19s 635ms, eta: 12m 10s 481ms\n",
            "\u001b[32m2022-12-09T08:04:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/6000, train/hateful_memes/cross_entropy: 0.6015, train/hateful_memes/cross_entropy/avg: 0.6966, train/total_loss: 0.6015, train/total_loss/avg: 0.6966, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 816ms, time_since_start: 14m 30s 452ms, eta: 11m 56s 249ms\n",
            "\u001b[32m2022-12-09T08:04:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/6000, train/hateful_memes/cross_entropy: 0.6058, train/hateful_memes/cross_entropy/avg: 0.6965, train/total_loss: 0.6058, train/total_loss/avg: 0.6965, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 787ms, time_since_start: 14m 41s 240ms, eta: 11m 42s 786ms\n",
            "\u001b[32m2022-12-09T08:05:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:05:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:05:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, train/hateful_memes/cross_entropy: 0.6058, train/hateful_memes/cross_entropy/avg: 0.6953, train/total_loss: 0.6058, train/total_loss/avg: 0.6953, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 6000, lr: 0.00004, ups: 3.57, time: 14s 057ms, time_since_start: 14m 55s 297ms, eta: 15m 795ms\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:05:10 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:05:34 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:05:34 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:05:34 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:05:34 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:05:37 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:05:37 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:05:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:05:40 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:05:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:05:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, val/hateful_memes/cross_entropy: 0.7049, val/total_loss: 0.7049, val/hateful_memes/accuracy: 0.5759, val/hateful_memes/binary_f1: 0.2637, val/hateful_memes/roc_auc: 0.5018, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 6000, val_time: 33s 017ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:05:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3050/6000, train/hateful_memes/cross_entropy: 0.5991, train/hateful_memes/cross_entropy/avg: 0.6927, train/total_loss: 0.5991, train/total_loss/avg: 0.6927, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 3050, iterations: 3050, max_updates: 6000, lr: 0.00004, ups: 4.55, time: 11s 298ms, time_since_start: 15m 39s 615ms, eta: 11m 51s 964ms\n",
            "\u001b[32m2022-12-09T08:06:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/6000, train/hateful_memes/cross_entropy: 0.5991, train/hateful_memes/cross_entropy/avg: 0.6929, train/total_loss: 0.5991, train/total_loss/avg: 0.6929, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 3100, iterations: 3100, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 947ms, time_since_start: 15m 50s 562ms, eta: 11m 18s 115ms\n",
            "\u001b[32m2022-12-09T08:06:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3150/6000, train/hateful_memes/cross_entropy: 0.5741, train/hateful_memes/cross_entropy/avg: 0.6903, train/total_loss: 0.5741, train/total_loss/avg: 0.6903, max mem: 3683.0, experiment: run, epoch: 6, num_updates: 3150, iterations: 3150, max_updates: 6000, lr: 0.00004, ups: 5.00, time: 10s 835ms, time_since_start: 16m 01s 398ms, eta: 10m 59s 621ms\n",
            "\u001b[32m2022-12-09T08:06:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/6000, train/hateful_memes/cross_entropy: 0.5741, train/hateful_memes/cross_entropy/avg: 0.6884, train/total_loss: 0.5741, train/total_loss/avg: 0.6884, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3200, iterations: 3200, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 323ms, time_since_start: 16m 12s 721ms, eta: 11m 17s 225ms\n",
            "\u001b[32m2022-12-09T08:06:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3250/6000, train/hateful_memes/cross_entropy: 0.5714, train/hateful_memes/cross_entropy/avg: 0.6864, train/total_loss: 0.5714, train/total_loss/avg: 0.6864, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3250, iterations: 3250, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 036ms, time_since_start: 16m 23s 758ms, eta: 10m 48s 305ms\n",
            "\u001b[32m2022-12-09T08:06:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/6000, train/hateful_memes/cross_entropy: 0.5714, train/hateful_memes/cross_entropy/avg: 0.6849, train/total_loss: 0.5714, train/total_loss/avg: 0.6849, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3300, iterations: 3300, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 095ms, time_since_start: 16m 34s 854ms, eta: 10m 39s 897ms\n",
            "\u001b[32m2022-12-09T08:07:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3350/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6824, train/total_loss: 0.5592, train/total_loss/avg: 0.6824, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3350, iterations: 3350, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 061ms, time_since_start: 16m 45s 915ms, eta: 10m 26s 118ms\n",
            "\u001b[32m2022-12-09T08:07:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6808, train/total_loss: 0.5592, train/total_loss/avg: 0.6808, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3400, iterations: 3400, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 914ms, time_since_start: 16m 56s 830ms, eta: 10m 06s 166ms\n",
            "\u001b[32m2022-12-09T08:07:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3450/6000, train/hateful_memes/cross_entropy: 0.5589, train/hateful_memes/cross_entropy/avg: 0.6790, train/total_loss: 0.5589, train/total_loss/avg: 0.6790, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3450, iterations: 3450, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 110ms, time_since_start: 17m 07s 940ms, eta: 10m 05s 151ms\n",
            "\u001b[32m2022-12-09T08:07:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6802, train/total_loss: 0.5592, train/total_loss/avg: 0.6802, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3500, iterations: 3500, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 974ms, time_since_start: 17m 18s 915ms, eta: 09m 46s 042ms\n",
            "\u001b[32m2022-12-09T08:07:33 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:07:33 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:07:34 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:07:34 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:07:34 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:07:34 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:07:51 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:07:51 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:07:51 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:07:51 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:07:54 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:07:54 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:07:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:07:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:07:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:07:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, val/hateful_memes/cross_entropy: 0.7105, val/total_loss: 0.7105, val/hateful_memes/accuracy: 0.5963, val/hateful_memes/binary_f1: 0.2635, val/hateful_memes/roc_auc: 0.5218, num_updates: 3500, epoch: 7, iterations: 3500, max_updates: 6000, val_time: 24s 621ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:08:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3550/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6766, train/total_loss: 0.5592, train/total_loss/avg: 0.6766, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3550, iterations: 3550, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 286ms, time_since_start: 17m 54s 824ms, eta: 09m 50s 648ms\n",
            "\u001b[32m2022-12-09T08:08:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6754, train/total_loss: 0.5592, train/total_loss/avg: 0.6754, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3600, iterations: 3600, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 950ms, time_since_start: 18m 05s 775ms, eta: 09m 21s 384ms\n",
            "\u001b[32m2022-12-09T08:08:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3650/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6714, train/total_loss: 0.5592, train/total_loss/avg: 0.6714, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3650, iterations: 3650, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 873ms, time_since_start: 18m 16s 649ms, eta: 09m 05s 820ms\n",
            "\u001b[32m2022-12-09T08:08:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/6000, train/hateful_memes/cross_entropy: 0.5714, train/hateful_memes/cross_entropy/avg: 0.6705, train/total_loss: 0.5714, train/total_loss/avg: 0.6705, max mem: 3683.0, experiment: run, epoch: 7, num_updates: 3700, iterations: 3700, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 128ms, time_since_start: 18m 27s 777ms, eta: 09m 06s 697ms\n",
            "\u001b[32m2022-12-09T08:08:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3750/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6663, train/total_loss: 0.5592, train/total_loss/avg: 0.6663, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 3750, iterations: 3750, max_updates: 6000, lr: 0.00003, ups: 4.55, time: 11s 273ms, time_since_start: 18m 39s 050ms, eta: 09m 01s 786ms\n",
            "\u001b[32m2022-12-09T08:09:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/6000, train/hateful_memes/cross_entropy: 0.5592, train/hateful_memes/cross_entropy/avg: 0.6628, train/total_loss: 0.5592, train/total_loss/avg: 0.6628, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 3800, iterations: 3800, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 824ms, time_since_start: 18m 49s 875ms, eta: 08m 28s 672ms\n",
            "\u001b[32m2022-12-09T08:09:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3850/6000, train/hateful_memes/cross_entropy: 0.5589, train/hateful_memes/cross_entropy/avg: 0.6596, train/total_loss: 0.5589, train/total_loss/avg: 0.6596, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 3850, iterations: 3850, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 821ms, time_since_start: 19m 697ms, eta: 08m 16s 979ms\n",
            "\u001b[32m2022-12-09T08:09:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/6000, train/hateful_memes/cross_entropy: 0.5589, train/hateful_memes/cross_entropy/avg: 0.6558, train/total_loss: 0.5589, train/total_loss/avg: 0.6558, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 3900, iterations: 3900, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 946ms, time_since_start: 19m 11s 643ms, eta: 08m 11s 011ms\n",
            "\u001b[32m2022-12-09T08:09:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3950/6000, train/hateful_memes/cross_entropy: 0.5348, train/hateful_memes/cross_entropy/avg: 0.6539, train/total_loss: 0.5348, train/total_loss/avg: 0.6539, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 3950, iterations: 3950, max_updates: 6000, lr: 0.00003, ups: 5.00, time: 10s 894ms, time_since_start: 19m 22s 537ms, eta: 07m 57s 039ms\n",
            "\u001b[32m2022-12-09T08:09:48 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:09:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:09:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, train/hateful_memes/cross_entropy: 0.5250, train/hateful_memes/cross_entropy/avg: 0.6499, train/total_loss: 0.5250, train/total_loss/avg: 0.6499, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 4000, iterations: 4000, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 724ms, time_since_start: 19m 36s 262ms, eta: 09m 46s 305ms\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:09:51 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:10:18 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:10:18 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:10:18 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:10:18 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:10:22 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:10:22 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:10:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:10:26 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:10:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:10:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, val/hateful_memes/cross_entropy: 0.7161, val/total_loss: 0.7161, val/hateful_memes/accuracy: 0.5889, val/hateful_memes/binary_f1: 0.3019, val/hateful_memes/roc_auc: 0.5313, num_updates: 4000, epoch: 8, iterations: 4000, max_updates: 6000, val_time: 36s 114ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:10:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4050/6000, train/hateful_memes/cross_entropy: 0.5156, train/hateful_memes/cross_entropy/avg: 0.6457, train/total_loss: 0.5156, train/total_loss/avg: 0.6457, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 4050, iterations: 4050, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 109ms, time_since_start: 20m 23s 487ms, eta: 07m 42s 720ms\n",
            "\u001b[32m2022-12-09T08:10:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/6000, train/hateful_memes/cross_entropy: 0.5060, train/hateful_memes/cross_entropy/avg: 0.6427, train/total_loss: 0.5060, train/total_loss/avg: 0.6427, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 4100, iterations: 4100, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 900ms, time_since_start: 20m 34s 387ms, eta: 07m 22s 366ms\n",
            "\u001b[32m2022-12-09T08:11:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4150/6000, train/hateful_memes/cross_entropy: 0.5060, train/hateful_memes/cross_entropy/avg: 0.6418, train/total_loss: 0.5060, train/total_loss/avg: 0.6418, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 4150, iterations: 4150, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 017ms, time_since_start: 20m 45s 404ms, eta: 07m 15s 371ms\n",
            "\u001b[32m2022-12-09T08:11:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/6000, train/hateful_memes/cross_entropy: 0.5060, train/hateful_memes/cross_entropy/avg: 0.6406, train/total_loss: 0.5060, train/total_loss/avg: 0.6406, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 4200, iterations: 4200, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 927ms, time_since_start: 20m 56s 332ms, eta: 07m 136ms\n",
            "\u001b[32m2022-12-09T08:11:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4250/6000, train/hateful_memes/cross_entropy: 0.5060, train/hateful_memes/cross_entropy/avg: 0.6401, train/total_loss: 0.5060, train/total_loss/avg: 0.6401, max mem: 3683.0, experiment: run, epoch: 8, num_updates: 4250, iterations: 4250, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 875ms, time_since_start: 21m 07s 208ms, eta: 06m 46s 541ms\n",
            "\u001b[32m2022-12-09T08:11:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/6000, train/hateful_memes/cross_entropy: 0.4251, train/hateful_memes/cross_entropy/avg: 0.6363, train/total_loss: 0.4251, train/total_loss/avg: 0.6363, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4300, iterations: 4300, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 275ms, time_since_start: 21m 18s 483ms, eta: 06m 49s 436ms\n",
            "\u001b[32m2022-12-09T08:11:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4350/6000, train/hateful_memes/cross_entropy: 0.4226, train/hateful_memes/cross_entropy/avg: 0.6334, train/total_loss: 0.4226, train/total_loss/avg: 0.6334, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4350, iterations: 4350, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 009ms, time_since_start: 21m 29s 492ms, eta: 06m 28s 008ms\n",
            "\u001b[32m2022-12-09T08:11:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/6000, train/hateful_memes/cross_entropy: 0.3968, train/hateful_memes/cross_entropy/avg: 0.6300, train/total_loss: 0.3968, train/total_loss/avg: 0.6300, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4400, iterations: 4400, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 862ms, time_since_start: 21m 40s 355ms, eta: 06m 11s 231ms\n",
            "\u001b[32m2022-12-09T08:12:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4450/6000, train/hateful_memes/cross_entropy: 0.3946, train/hateful_memes/cross_entropy/avg: 0.6262, train/total_loss: 0.3946, train/total_loss/avg: 0.6262, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4450, iterations: 4450, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 860ms, time_since_start: 21m 51s 216ms, eta: 05m 59s 584ms\n",
            "\u001b[32m2022-12-09T08:12:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, train/hateful_memes/cross_entropy: 0.3835, train/hateful_memes/cross_entropy/avg: 0.6235, train/total_loss: 0.3835, train/total_loss/avg: 0.6235, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4500, iterations: 4500, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 747ms, time_since_start: 22m 01s 964ms, eta: 05m 44s 356ms\n",
            "\u001b[32m2022-12-09T08:12:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:12:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:12:17 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:12:17 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:12:17 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:12:17 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:12:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:12:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:12:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:12:52 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:12:55 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:12:55 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:12:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:12:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:12:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:12:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, val/hateful_memes/cross_entropy: 0.7476, val/total_loss: 0.7476, val/hateful_memes/accuracy: 0.6074, val/hateful_memes/binary_f1: 0.2587, val/hateful_memes/roc_auc: 0.5213, num_updates: 4500, epoch: 9, iterations: 4500, max_updates: 6000, val_time: 42s 536ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:13:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4550/6000, train/hateful_memes/cross_entropy: 0.3835, train/hateful_memes/cross_entropy/avg: 0.6218, train/total_loss: 0.3835, train/total_loss/avg: 0.6218, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4550, iterations: 4550, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 275ms, time_since_start: 22m 55s 776ms, eta: 05m 49s 212ms\n",
            "\u001b[32m2022-12-09T08:13:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/6000, train/hateful_memes/cross_entropy: 0.3823, train/hateful_memes/cross_entropy/avg: 0.6181, train/total_loss: 0.3823, train/total_loss/avg: 0.6181, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4600, iterations: 4600, max_updates: 6000, lr: 0.00002, ups: 5.00, time: 10s 782ms, time_since_start: 23m 06s 559ms, eta: 05m 22s 451ms\n",
            "\u001b[32m2022-12-09T08:13:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4650/6000, train/hateful_memes/cross_entropy: 0.3786, train/hateful_memes/cross_entropy/avg: 0.6146, train/total_loss: 0.3786, train/total_loss/avg: 0.6146, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4650, iterations: 4650, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 058ms, time_since_start: 23m 17s 617ms, eta: 05m 18s 870ms\n",
            "\u001b[32m2022-12-09T08:13:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/6000, train/hateful_memes/cross_entropy: 0.3607, train/hateful_memes/cross_entropy/avg: 0.6109, train/total_loss: 0.3607, train/total_loss/avg: 0.6109, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4700, iterations: 4700, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 395ms, time_since_start: 23m 29s 013ms, eta: 05m 16s 440ms\n",
            "\u001b[32m2022-12-09T08:13:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4750/6000, train/hateful_memes/cross_entropy: 0.3607, train/hateful_memes/cross_entropy/avg: 0.6073, train/total_loss: 0.3607, train/total_loss/avg: 0.6073, max mem: 3683.0, experiment: run, epoch: 9, num_updates: 4750, iterations: 4750, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 014ms, time_since_start: 23m 40s 028ms, eta: 04m 54s 097ms\n",
            "\u001b[32m2022-12-09T08:14:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/6000, train/hateful_memes/cross_entropy: 0.3348, train/hateful_memes/cross_entropy/avg: 0.6035, train/total_loss: 0.3348, train/total_loss/avg: 0.6035, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 4800, iterations: 4800, max_updates: 6000, lr: 0.00002, ups: 4.55, time: 11s 164ms, time_since_start: 23m 51s 193ms, eta: 04m 46s 170ms\n",
            "\u001b[32m2022-12-09T08:14:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4850/6000, train/hateful_memes/cross_entropy: 0.3339, train/hateful_memes/cross_entropy/avg: 0.5992, train/total_loss: 0.3339, train/total_loss/avg: 0.5992, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 4850, iterations: 4850, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 849ms, time_since_start: 24m 02s 042ms, eta: 04m 26s 508ms\n",
            "\u001b[32m2022-12-09T08:14:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/6000, train/hateful_memes/cross_entropy: 0.3135, train/hateful_memes/cross_entropy/avg: 0.5953, train/total_loss: 0.3135, train/total_loss/avg: 0.5953, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 4900, iterations: 4900, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 834ms, time_since_start: 24m 12s 877ms, eta: 04m 14s 573ms\n",
            "\u001b[32m2022-12-09T08:14:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4950/6000, train/hateful_memes/cross_entropy: 0.3107, train/hateful_memes/cross_entropy/avg: 0.5922, train/total_loss: 0.3107, train/total_loss/avg: 0.5922, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 4950, iterations: 4950, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 034ms, time_since_start: 24m 23s 912ms, eta: 04m 07s 489ms\n",
            "\u001b[32m2022-12-09T08:14:49 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:14:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:14:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:14:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:14:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, train/hateful_memes/cross_entropy: 0.2935, train/hateful_memes/cross_entropy/avg: 0.5890, train/total_loss: 0.2935, train/total_loss/avg: 0.5890, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 5000, iterations: 5000, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 765ms, time_since_start: 24m 37s 677ms, eta: 04m 54s 021ms\n",
            "\u001b[32m2022-12-09T08:14:52 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:14:52 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:14:53 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:14:53 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:14:53 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:14:53 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:15:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:15:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:15:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:15:38 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:15:41 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:15:41 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:15:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:15:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:15:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:15:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, val/hateful_memes/cross_entropy: 0.7787, val/total_loss: 0.7787, val/hateful_memes/accuracy: 0.6185, val/hateful_memes/binary_f1: 0.2370, val/hateful_memes/roc_auc: 0.4828, num_updates: 5000, epoch: 10, iterations: 5000, max_updates: 6000, val_time: 52s 768ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:15:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5050/6000, train/hateful_memes/cross_entropy: 0.2911, train/hateful_memes/cross_entropy/avg: 0.5858, train/total_loss: 0.2911, train/total_loss/avg: 0.5858, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 5050, iterations: 5050, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 221ms, time_since_start: 25m 41s 667ms, eta: 03m 47s 697ms\n",
            "\u001b[32m2022-12-09T08:16:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/6000, train/hateful_memes/cross_entropy: 0.2905, train/hateful_memes/cross_entropy/avg: 0.5829, train/total_loss: 0.2905, train/total_loss/avg: 0.5829, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 5100, iterations: 5100, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 993ms, time_since_start: 25m 52s 661ms, eta: 03m 31s 341ms\n",
            "\u001b[32m2022-12-09T08:16:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5150/6000, train/hateful_memes/cross_entropy: 0.2878, train/hateful_memes/cross_entropy/avg: 0.5791, train/total_loss: 0.2878, train/total_loss/avg: 0.5791, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 5150, iterations: 5150, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 872ms, time_since_start: 26m 03s 533ms, eta: 03m 17s 396ms\n",
            "\u001b[32m2022-12-09T08:16:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/6000, train/hateful_memes/cross_entropy: 0.2878, train/hateful_memes/cross_entropy/avg: 0.5780, train/total_loss: 0.2878, train/total_loss/avg: 0.5780, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 5200, iterations: 5200, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 067ms, time_since_start: 26m 14s 601ms, eta: 03m 09s 119ms\n",
            "\u001b[32m2022-12-09T08:16:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5250/6000, train/hateful_memes/cross_entropy: 0.2807, train/hateful_memes/cross_entropy/avg: 0.5744, train/total_loss: 0.2807, train/total_loss/avg: 0.5744, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 5250, iterations: 5250, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 061ms, time_since_start: 26m 25s 662ms, eta: 02m 57s 202ms\n",
            "\u001b[32m2022-12-09T08:16:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/6000, train/hateful_memes/cross_entropy: 0.2737, train/hateful_memes/cross_entropy/avg: 0.5714, train/total_loss: 0.2737, train/total_loss/avg: 0.5714, max mem: 3683.0, experiment: run, epoch: 10, num_updates: 5300, iterations: 5300, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 063ms, time_since_start: 26m 36s 726ms, eta: 02m 45s 423ms\n",
            "\u001b[32m2022-12-09T08:17:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5350/6000, train/hateful_memes/cross_entropy: 0.2688, train/hateful_memes/cross_entropy/avg: 0.5676, train/total_loss: 0.2688, train/total_loss/avg: 0.5676, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5350, iterations: 5350, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 302ms, time_since_start: 26m 48s 029ms, eta: 02m 36s 928ms\n",
            "\u001b[32m2022-12-09T08:17:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/6000, train/hateful_memes/cross_entropy: 0.2635, train/hateful_memes/cross_entropy/avg: 0.5640, train/total_loss: 0.2635, train/total_loss/avg: 0.5640, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5400, iterations: 5400, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 006ms, time_since_start: 26m 59s 035ms, eta: 02m 21s 054ms\n",
            "\u001b[32m2022-12-09T08:17:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5450/6000, train/hateful_memes/cross_entropy: 0.2624, train/hateful_memes/cross_entropy/avg: 0.5604, train/total_loss: 0.2624, train/total_loss/avg: 0.5604, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5450, iterations: 5450, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 741ms, time_since_start: 27m 09s 776ms, eta: 02m 06s 186ms\n",
            "\u001b[32m2022-12-09T08:17:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, train/hateful_memes/cross_entropy: 0.2551, train/hateful_memes/cross_entropy/avg: 0.5573, train/total_loss: 0.2551, train/total_loss/avg: 0.5573, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5500, iterations: 5500, max_updates: 6000, lr: 0.00001, ups: 5.00, time: 10s 875ms, time_since_start: 27m 20s 652ms, eta: 01m 56s 154ms\n",
            "\u001b[32m2022-12-09T08:17:35 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:17:35 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:17:35 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:17:35 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:17:35 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:17:35 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:17:56 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:17:59 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:17:59 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:17:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:18:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:18:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:18:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, val/hateful_memes/cross_entropy: 0.7724, val/total_loss: 0.7724, val/hateful_memes/accuracy: 0.5981, val/hateful_memes/binary_f1: 0.2439, val/hateful_memes/roc_auc: 0.5022, num_updates: 5500, epoch: 11, iterations: 5500, max_updates: 6000, val_time: 28s 028ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:18:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5550/6000, train/hateful_memes/cross_entropy: 0.2551, train/hateful_memes/cross_entropy/avg: 0.5547, train/total_loss: 0.2551, train/total_loss/avg: 0.5547, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5550, iterations: 5550, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 228ms, time_since_start: 27m 59s 910ms, eta: 01m 47s 930ms\n",
            "\u001b[32m2022-12-09T08:18:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/6000, train/hateful_memes/cross_entropy: 0.2551, train/hateful_memes/cross_entropy/avg: 0.5520, train/total_loss: 0.2551, train/total_loss/avg: 0.5520, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5600, iterations: 5600, max_updates: 6000, lr: 0.00001, ups: 4.55, time: 11s 118ms, time_since_start: 28m 11s 028ms, eta: 01m 34s 996ms\n",
            "\u001b[32m2022-12-09T08:18:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5650/6000, train/hateful_memes/cross_entropy: 0.2462, train/hateful_memes/cross_entropy/avg: 0.5491, train/total_loss: 0.2462, train/total_loss/avg: 0.5491, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5650, iterations: 5650, max_updates: 6000, lr: 0., ups: 4.55, time: 11s 483ms, time_since_start: 28m 22s 511ms, eta: 01m 25s 848ms\n",
            "\u001b[32m2022-12-09T08:18:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/6000, train/hateful_memes/cross_entropy: 0.2179, train/hateful_memes/cross_entropy/avg: 0.5458, train/total_loss: 0.2179, train/total_loss/avg: 0.5458, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5700, iterations: 5700, max_updates: 6000, lr: 0., ups: 4.55, time: 11s 047ms, time_since_start: 28m 33s 559ms, eta: 01m 10s 790ms\n",
            "\u001b[32m2022-12-09T08:18:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5750/6000, train/hateful_memes/cross_entropy: 0.2173, train/hateful_memes/cross_entropy/avg: 0.5426, train/total_loss: 0.2173, train/total_loss/avg: 0.5426, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5750, iterations: 5750, max_updates: 6000, lr: 0., ups: 4.55, time: 11s 014ms, time_since_start: 28m 44s 573ms, eta: 58s 816ms\n",
            "\u001b[32m2022-12-09T08:19:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/6000, train/hateful_memes/cross_entropy: 0.2138, train/hateful_memes/cross_entropy/avg: 0.5396, train/total_loss: 0.2138, train/total_loss/avg: 0.5396, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5800, iterations: 5800, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 855ms, time_since_start: 28m 55s 429ms, eta: 46s 376ms\n",
            "\u001b[32m2022-12-09T08:19:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5850/6000, train/hateful_memes/cross_entropy: 0.2138, train/hateful_memes/cross_entropy/avg: 0.5367, train/total_loss: 0.2138, train/total_loss/avg: 0.5367, max mem: 3683.0, experiment: run, epoch: 11, num_updates: 5850, iterations: 5850, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 833ms, time_since_start: 29m 06s 263ms, eta: 34s 712ms\n",
            "\u001b[32m2022-12-09T08:19:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/6000, train/hateful_memes/cross_entropy: 0.2034, train/hateful_memes/cross_entropy/avg: 0.5332, train/total_loss: 0.2034, train/total_loss/avg: 0.5332, max mem: 3683.0, experiment: run, epoch: 12, num_updates: 5900, iterations: 5900, max_updates: 6000, lr: 0., ups: 4.55, time: 11s 254ms, time_since_start: 29m 17s 518ms, eta: 24s 040ms\n",
            "\u001b[32m2022-12-09T08:19:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5950/6000, train/hateful_memes/cross_entropy: 0.1992, train/hateful_memes/cross_entropy/avg: 0.5300, train/total_loss: 0.1992, train/total_loss/avg: 0.5300, max mem: 3683.0, experiment: run, epoch: 12, num_updates: 5950, iterations: 5950, max_updates: 6000, lr: 0., ups: 5.00, time: 10s 970ms, time_since_start: 29m 28s 488ms, eta: 11s 716ms\n",
            "\u001b[32m2022-12-09T08:19:54 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:19:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:19:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, train/hateful_memes/cross_entropy: 0.1972, train/hateful_memes/cross_entropy/avg: 0.5273, train/total_loss: 0.1972, train/total_loss/avg: 0.5273, max mem: 3683.0, experiment: run, epoch: 12, num_updates: 6000, iterations: 6000, max_updates: 6000, lr: 0., ups: 3.57, time: 14s 020ms, time_since_start: 29m 42s 509ms, eta: 0ms\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:19:57 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96cabfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96168ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:20:19 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:20:19 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:20:19 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:20:19 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:20:23 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:20:23 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:20:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, val/hateful_memes/cross_entropy: 0.7733, val/total_loss: 0.7733, val/hateful_memes/accuracy: 0.6019, val/hateful_memes/binary_f1: 0.2612, val/hateful_memes/roc_auc: 0.4999, num_updates: 6000, epoch: 12, iterations: 6000, max_updates: 6000, val_time: 26s 446ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.546941\n",
            "\u001b[32m2022-12-09T08:20:24 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2022-12-09T08:20:24 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2022-12-09T08:20:24 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2022-12-09T08:20:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-12-09T08:20:27 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 1500\n",
            "\u001b[32m2022-12-09T08:20:27 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 1500\n",
            "\u001b[32m2022-12-09T08:20:27 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 3\n",
            "\u001b[32m2022-12-09T08:20:28 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-12-09T08:20:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[32m2022-12-09T08:20:28 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\u001b[32m2022-12-09T08:20:28 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\n",
            "\u001b[32m2022-12-09T08:20:28 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "\u001b[32m2022-12-09T08:20:28 | mmf.datasets.processors.processors: \u001b[0mLoading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin\n",
            "\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96dcbfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96dcbfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96dcbfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 5423251456 bytes == 0x7f96dcbfc000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6de67 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96288ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96288ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96288ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "tcmalloc: large alloc 3023249408 bytes == 0x7f96288ca000 @  0x7f9b71af4887 0x7f9a66d7eb73 0x7f9a66d6deab 0x7f9a66d6e981 0x7f9a66d3d272 0x7f9a66d5cef4 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55cd91 0x5d8941 0x5da107 0x586de6 0x5d8cdf 0x55ea20 0x5d8868 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x5da107 0x587116 0x5d85e3 0x55f797 0x55cd91 0x5d8941 0x5da092 0x587116 0x5d8d8c 0x561f80\n",
            "\u001b[32m2022-12-09T08:20:40 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:20:40 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:20:40 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "\u001b[32m2022-12-09T08:20:40 | mmf.datasets.processors.processors: \u001b[0mFinished loading fasttext model\n",
            "100% 125/125 [00:24<00:00,  5.18it/s]\n",
            "\u001b[32m2022-12-09T08:20:52 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 125\n",
            "\u001b[32m2022-12-09T08:20:52 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:20:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, test/hateful_memes/cross_entropy: 0.6693, test/total_loss: 0.6693, test/hateful_memes/accuracy: 0.5995, test/hateful_memes/binary_f1: 0.2408, test/hateful_memes/roc_auc: 0.5378\n",
            "\u001b[32m2022-12-09T08:20:53 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 30m 38s 402ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/late_fusion/defaults.yaml \\\n",
        "  model=late_fusion \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=6000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100 \\\n",
        "  env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUq7brQO_Dnd",
        "outputId": "6bf028f4-b7b3-405d-8308-c1d1e12ba2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 08:25:53.476300: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "\u001b[32m2022-12-09T08:26:03 | mmf: \u001b[0mLogging to: /drive/MyDrive/final_project/mmf/projects/hateful_memes/save/train.log\n",
            "\u001b[32m2022-12-09T08:26:03 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/late_fusion/defaults.yaml', 'model=late_fusion', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=6000', 'training.batch_size=16', 'training.evaluation_interval=500', 'trainer.params.gpus=100', 'env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save'])\n",
            "\u001b[32m2022-12-09T08:26:03 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu111\n",
            "\u001b[32m2022-12-09T08:26:03 | mmf.utils.general: \u001b[0mCUDA Device 0 is: A100-SXM4-40GB\n",
            "\u001b[32m2022-12-09T08:26:03 | mmf_cli.run: \u001b[0mUsing seed 3049255\n",
            "\u001b[32m2022-12-09T08:26:03 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpl0qirwq8\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 30.1kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpi2z__4wy\n",
            "Downloading: 100% 570/570 [00:00<00:00, 584kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfrr2_557\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 2.00MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzy99p2wb\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 3.15MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "\u001b[32m2022-12-09T08:26:05 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T08:26:05 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T08:26:05 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T08:26:05 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3i4uujuy\n",
            "Downloading: 100% 440M/440M [00:04<00:00, 100MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelJit: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModelJit from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModelJit from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModelJit were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModelJit for predictions without further training.\n",
            "\u001b[32m2022-12-09T08:26:30 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-12-09T08:26:30 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-12-09T08:26:30 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-12-09T08:26:30 | mmf.trainers.mmf_trainer: \u001b[0mLateFusion(\n",
            "  (base): FusionBase(\n",
            "    (text): BertModelJit(\n",
            "      (embeddings): BertEmbeddingsJit(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (modal): ResNet152ImageEncoder(\n",
            "      (model): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (4): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (6): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (7): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (6): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (7): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (8): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (9): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (10): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (11): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (12): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (13): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (14): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (15): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (16): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (17): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (18): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (19): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (20): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (21): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (22): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (23): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (24): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (25): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (26): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (27): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (28): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (29): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (30): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (31): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (32): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (33): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (34): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (35): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (modal_classifier): MLPClassifer(\n",
            "    (layers): ModuleList(\n",
            "      (0): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.5, inplace=False)\n",
            "      (4): Linear(in_features=768, out_features=384, bias=True)\n",
            "      (5): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ReLU()\n",
            "      (7): Dropout(p=0.5, inplace=False)\n",
            "      (8): Linear(in_features=384, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (text_classifier): MLPClassifer(\n",
            "    (layers): ModuleList(\n",
            "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.5, inplace=False)\n",
            "      (4): Linear(in_features=768, out_features=384, bias=True)\n",
            "      (5): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ReLU()\n",
            "      (7): Dropout(p=0.5, inplace=False)\n",
            "      (8): Linear(in_features=384, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-12-09T08:26:30 | mmf.utils.general: \u001b[0mTotal Parameters: 170387012. Trained Parameters: 170387012\n",
            "\u001b[32m2022-12-09T08:26:30 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T08:26:31 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T08:26:31 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[32m2022-12-09T08:26:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/6000, train/hateful_memes/cross_entropy: 0.7953, train/hateful_memes/cross_entropy/avg: 0.7953, train/total_loss: 0.7953, train/total_loss/avg: 0.7953, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 6000, lr: 0., ups: 3.57, time: 14s 531ms, time_since_start: 14s 589ms, eta: 30m 46s 888ms\n",
            "\u001b[32m2022-12-09T08:26:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/6000, train/hateful_memes/cross_entropy: 0.7772, train/hateful_memes/cross_entropy/avg: 0.7863, train/total_loss: 0.7772, train/total_loss/avg: 0.7863, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 430ms, time_since_start: 28s 020ms, eta: 28m 12s 585ms\n",
            "\u001b[32m2022-12-09T08:27:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/6000, train/hateful_memes/cross_entropy: 0.7848, train/hateful_memes/cross_entropy/avg: 0.7858, train/total_loss: 0.7848, train/total_loss/avg: 0.7858, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 383ms, time_since_start: 41s 403ms, eta: 27m 52s 323ms\n",
            "\u001b[32m2022-12-09T08:27:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/6000, train/hateful_memes/cross_entropy: 0.7772, train/hateful_memes/cross_entropy/avg: 0.7799, train/total_loss: 0.7772, train/total_loss/avg: 0.7799, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 511ms, time_since_start: 54s 915ms, eta: 27m 53s 935ms\n",
            "\u001b[32m2022-12-09T08:27:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/6000, train/hateful_memes/cross_entropy: 0.7772, train/hateful_memes/cross_entropy/avg: 0.7763, train/total_loss: 0.7772, train/total_loss/avg: 0.7763, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 434ms, time_since_start: 01m 08s 350ms, eta: 27m 30s 083ms\n",
            "\u001b[32m2022-12-09T08:27:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/6000, train/hateful_memes/cross_entropy: 0.7621, train/hateful_memes/cross_entropy/avg: 0.7578, train/total_loss: 0.7621, train/total_loss/avg: 0.7578, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 586ms, time_since_start: 01m 21s 936ms, eta: 27m 34s 156ms\n",
            "\u001b[32m2022-12-09T08:28:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/6000, train/hateful_memes/cross_entropy: 0.7621, train/hateful_memes/cross_entropy/avg: 0.7429, train/total_loss: 0.7621, train/total_loss/avg: 0.7429, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 441ms, time_since_start: 01m 35s 377ms, eta: 27m 02s 137ms\n",
            "\u001b[32m2022-12-09T08:28:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/6000, train/hateful_memes/cross_entropy: 0.7621, train/hateful_memes/cross_entropy/avg: 0.7327, train/total_loss: 0.7621, train/total_loss/avg: 0.7327, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 440ms, time_since_start: 01m 48s 818ms, eta: 26m 47s 727ms\n",
            "\u001b[32m2022-12-09T08:28:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/6000, train/hateful_memes/cross_entropy: 0.7621, train/hateful_memes/cross_entropy/avg: 0.7215, train/total_loss: 0.7621, train/total_loss/avg: 0.7215, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 702ms, time_since_start: 02m 02s 520ms, eta: 27m 04s 377ms\n",
            "\u001b[32m2022-12-09T08:28:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, train/hateful_memes/cross_entropy: 0.6651, train/hateful_memes/cross_entropy/avg: 0.7101, train/total_loss: 0.6651, train/total_loss/avg: 0.7101, max mem: 7111.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 412ms, time_since_start: 02m 15s 933ms, eta: 26m 15s 717ms\n",
            "\u001b[32m2022-12-09T08:28:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:28:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:28:50 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:28:50 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:28:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:28:58 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T08:29:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:29:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:29:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, val/hateful_memes/cross_entropy: 0.6748, val/total_loss: 0.6748, val/hateful_memes/accuracy: 0.5852, val/hateful_memes/binary_f1: 0.4105, val/hateful_memes/roc_auc: 0.5987, num_updates: 500, epoch: 1, iterations: 500, max_updates: 6000, val_time: 23s 069ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.598706\n",
            "\u001b[32m2022-12-09T08:29:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/6000, train/hateful_memes/cross_entropy: 0.6651, train/hateful_memes/cross_entropy/avg: 0.6989, train/total_loss: 0.6651, train/total_loss/avg: 0.6989, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 6000, lr: 0.00001, ups: 3.57, time: 14s 056ms, time_since_start: 02m 53s 060ms, eta: 27m 16s 335ms\n",
            "\u001b[32m2022-12-09T08:29:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/6000, train/hateful_memes/cross_entropy: 0.6615, train/hateful_memes/cross_entropy/avg: 0.6904, train/total_loss: 0.6615, train/total_loss/avg: 0.6904, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 495ms, time_since_start: 03m 06s 555ms, eta: 25m 56s 572ms\n",
            "\u001b[32m2022-12-09T08:29:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/6000, train/hateful_memes/cross_entropy: 0.6615, train/hateful_memes/cross_entropy/avg: 0.6818, train/total_loss: 0.6615, train/total_loss/avg: 0.6818, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 442ms, time_since_start: 03m 19s 997ms, eta: 25m 36s 142ms\n",
            "\u001b[32m2022-12-09T08:30:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/6000, train/hateful_memes/cross_entropy: 0.6536, train/hateful_memes/cross_entropy/avg: 0.6652, train/total_loss: 0.6536, train/total_loss/avg: 0.6652, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 340ms, time_since_start: 03m 33s 338ms, eta: 25m 10s 264ms\n",
            "\u001b[32m2022-12-09T08:30:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/6000, train/hateful_memes/cross_entropy: 0.6536, train/hateful_memes/cross_entropy/avg: 0.6515, train/total_loss: 0.6536, train/total_loss/avg: 0.6515, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 324ms, time_since_start: 03m 46s 662ms, eta: 24m 54s 190ms\n",
            "\u001b[32m2022-12-09T08:30:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/6000, train/hateful_memes/cross_entropy: 0.6319, train/hateful_memes/cross_entropy/avg: 0.6416, train/total_loss: 0.6319, train/total_loss/avg: 0.6416, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 473ms, time_since_start: 04m 136ms, eta: 24m 56s 552ms\n",
            "\u001b[32m2022-12-09T08:30:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/6000, train/hateful_memes/cross_entropy: 0.6536, train/hateful_memes/cross_entropy/avg: 0.6588, train/total_loss: 0.6536, train/total_loss/avg: 0.6588, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 387ms, time_since_start: 04m 13s 524ms, eta: 24m 32s 707ms\n",
            "\u001b[32m2022-12-09T08:30:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/6000, train/hateful_memes/cross_entropy: 0.6319, train/hateful_memes/cross_entropy/avg: 0.6553, train/total_loss: 0.6319, train/total_loss/avg: 0.6553, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 900, iterations: 900, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 482ms, time_since_start: 04m 27s 006ms, eta: 24m 28s 708ms\n",
            "\u001b[32m2022-12-09T08:31:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/6000, train/hateful_memes/cross_entropy: 0.6319, train/hateful_memes/cross_entropy/avg: 0.6425, train/total_loss: 0.6319, train/total_loss/avg: 0.6425, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 950, iterations: 950, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 467ms, time_since_start: 04m 40s 474ms, eta: 24m 12s 752ms\n",
            "\u001b[32m2022-12-09T08:31:24 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:31:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:31:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:31:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:31:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, train/hateful_memes/cross_entropy: 0.6319, train/hateful_memes/cross_entropy/avg: 0.6448, train/total_loss: 0.6319, train/total_loss/avg: 0.6448, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 1000, iterations: 1000, max_updates: 6000, lr: 0.00003, ups: 1.92, time: 26s 336ms, time_since_start: 05m 06s 811ms, eta: 46m 52s 753ms\n",
            "\u001b[32m2022-12-09T08:31:37 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:31:37 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:31:41 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:31:41 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:31:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:31:45 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T08:31:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:32:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:32:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, val/hateful_memes/cross_entropy: 0.6881, val/total_loss: 0.6881, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.2920, val/hateful_memes/roc_auc: 0.6058, num_updates: 1000, epoch: 2, iterations: 1000, max_updates: 6000, val_time: 22s 656ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.605765\n",
            "\u001b[32m2022-12-09T08:32:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/6000, train/hateful_memes/cross_entropy: 0.6319, train/hateful_memes/cross_entropy/avg: 0.6455, train/total_loss: 0.6319, train/total_loss/avg: 0.6455, max mem: 7111.0, experiment: run, epoch: 2, num_updates: 1050, iterations: 1050, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 832ms, time_since_start: 05m 43s 302ms, eta: 24m 22s 521ms\n",
            "\u001b[32m2022-12-09T08:32:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/6000, train/hateful_memes/cross_entropy: 0.6070, train/hateful_memes/cross_entropy/avg: 0.6375, train/total_loss: 0.6070, train/total_loss/avg: 0.6375, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 698ms, time_since_start: 05m 57s 000ms, eta: 23m 53s 725ms\n",
            "\u001b[32m2022-12-09T08:32:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/6000, train/hateful_memes/cross_entropy: 0.5968, train/hateful_memes/cross_entropy/avg: 0.6259, train/total_loss: 0.5968, train/total_loss/avg: 0.6259, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 495ms, time_since_start: 06m 10s 496ms, eta: 23m 18s 110ms\n",
            "\u001b[32m2022-12-09T08:32:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6190, train/total_loss: 0.5956, train/total_loss/avg: 0.6190, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 435ms, time_since_start: 06m 23s 931ms, eta: 22m 57s 475ms\n",
            "\u001b[32m2022-12-09T08:33:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6197, train/total_loss: 0.5956, train/total_loss/avg: 0.6197, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 495ms, time_since_start: 06m 37s 427ms, eta: 22m 49s 275ms\n",
            "\u001b[32m2022-12-09T08:33:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6196, train/total_loss: 0.5956, train/total_loss/avg: 0.6196, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 783ms, time_since_start: 06m 51s 210ms, eta: 23m 03s 752ms\n",
            "\u001b[32m2022-12-09T08:33:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6212, train/total_loss: 0.5956, train/total_loss/avg: 0.6212, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 587ms, time_since_start: 07m 04s 798ms, eta: 22m 29s 600ms\n",
            "\u001b[32m2022-12-09T08:33:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6213, train/total_loss: 0.5956, train/total_loss/avg: 0.6213, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 513ms, time_since_start: 07m 18s 311ms, eta: 22m 07s 739ms\n",
            "\u001b[32m2022-12-09T08:34:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/6000, train/hateful_memes/cross_entropy: 0.5877, train/hateful_memes/cross_entropy/avg: 0.6059, train/total_loss: 0.5877, train/total_loss/avg: 0.6059, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 523ms, time_since_start: 07m 31s 835ms, eta: 21m 54s 320ms\n",
            "\u001b[32m2022-12-09T08:34:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, train/hateful_memes/cross_entropy: 0.5877, train/hateful_memes/cross_entropy/avg: 0.6130, train/total_loss: 0.5877, train/total_loss/avg: 0.6130, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 518ms, time_since_start: 07m 45s 353ms, eta: 21m 39s 386ms\n",
            "\u001b[32m2022-12-09T08:34:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:34:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:34:20 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:34:20 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:34:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:34:24 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T08:34:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:34:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:34:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, val/hateful_memes/cross_entropy: 0.7366, val/total_loss: 0.7366, val/hateful_memes/accuracy: 0.6352, val/hateful_memes/binary_f1: 0.2452, val/hateful_memes/roc_auc: 0.6164, num_updates: 1500, epoch: 3, iterations: 1500, max_updates: 6000, val_time: 23s 273ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.616412\n",
            "\u001b[32m2022-12-09T08:34:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6131, train/total_loss: 0.5956, train/total_loss/avg: 0.6131, max mem: 7111.0, experiment: run, epoch: 3, num_updates: 1550, iterations: 1550, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 744ms, time_since_start: 08m 22s 372ms, eta: 21m 46s 440ms\n",
            "\u001b[32m2022-12-09T08:35:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/6000, train/hateful_memes/cross_entropy: 0.5777, train/hateful_memes/cross_entropy/avg: 0.6097, train/total_loss: 0.5777, train/total_loss/avg: 0.6097, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1600, iterations: 1600, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 884ms, time_since_start: 08m 36s 257ms, eta: 21m 44s 921ms\n",
            "\u001b[32m2022-12-09T08:35:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6169, train/total_loss: 0.5956, train/total_loss/avg: 0.6169, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1650, iterations: 1650, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 514ms, time_since_start: 08m 49s 772ms, eta: 20m 55s 751ms\n",
            "\u001b[32m2022-12-09T08:35:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.6041, train/total_loss: 0.5956, train/total_loss/avg: 0.6041, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1700, iterations: 1700, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 487ms, time_since_start: 09m 03s 259ms, eta: 20m 38s 773ms\n",
            "\u001b[32m2022-12-09T08:35:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.5983, train/total_loss: 0.5956, train/total_loss/avg: 0.5983, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 488ms, time_since_start: 09m 16s 748ms, eta: 20m 24s 527ms\n",
            "\u001b[32m2022-12-09T08:36:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/6000, train/hateful_memes/cross_entropy: 0.5956, train/hateful_memes/cross_entropy/avg: 0.5895, train/total_loss: 0.5956, train/total_loss/avg: 0.5895, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 515ms, time_since_start: 09m 30s 264ms, eta: 20m 12s 514ms\n",
            "\u001b[32m2022-12-09T08:36:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/6000, train/hateful_memes/cross_entropy: 0.5062, train/hateful_memes/cross_entropy/avg: 0.5833, train/total_loss: 0.5062, train/total_loss/avg: 0.5833, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 350ms, time_since_start: 09m 43s 614ms, eta: 19m 43s 444ms\n",
            "\u001b[32m2022-12-09T08:36:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/6000, train/hateful_memes/cross_entropy: 0.4686, train/hateful_memes/cross_entropy/avg: 0.5754, train/total_loss: 0.4686, train/total_loss/avg: 0.5754, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 386ms, time_since_start: 09m 57s 001ms, eta: 19m 32s 333ms\n",
            "\u001b[32m2022-12-09T08:36:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/6000, train/hateful_memes/cross_entropy: 0.4686, train/hateful_memes/cross_entropy/avg: 0.5702, train/total_loss: 0.4686, train/total_loss/avg: 0.5702, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 491ms, time_since_start: 10m 10s 492ms, eta: 19m 27s 110ms\n",
            "\u001b[32m2022-12-09T08:36:54 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:36:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:36:58 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:37:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:37:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, train/hateful_memes/cross_entropy: 0.4615, train/hateful_memes/cross_entropy/avg: 0.5670, train/total_loss: 0.4615, train/total_loss/avg: 0.5670, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 6000, lr: 0.00005, ups: 2.00, time: 25s 454ms, time_since_start: 10m 35s 947ms, eta: 36m 14s 856ms\n",
            "\u001b[32m2022-12-09T08:37:06 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:37:06 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:37:10 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:37:10 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:37:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:37:15 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T08:37:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:37:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:37:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, val/hateful_memes/cross_entropy: 0.8235, val/total_loss: 0.8235, val/hateful_memes/accuracy: 0.6481, val/hateful_memes/binary_f1: 0.3581, val/hateful_memes/roc_auc: 0.6219, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 6000, val_time: 21s 841ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:37:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/6000, train/hateful_memes/cross_entropy: 0.4437, train/hateful_memes/cross_entropy/avg: 0.5623, train/total_loss: 0.4437, train/total_loss/avg: 0.5623, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 864ms, time_since_start: 11m 11s 655ms, eta: 19m 29s 810ms\n",
            "\u001b[32m2022-12-09T08:37:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/6000, train/hateful_memes/cross_entropy: 0.4017, train/hateful_memes/cross_entropy/avg: 0.5558, train/total_loss: 0.4017, train/total_loss/avg: 0.5558, max mem: 7111.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 420ms, time_since_start: 11m 25s 075ms, eta: 18m 37s 976ms\n",
            "\u001b[32m2022-12-09T08:38:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/6000, train/hateful_memes/cross_entropy: 0.4017, train/hateful_memes/cross_entropy/avg: 0.5489, train/total_loss: 0.4017, train/total_loss/avg: 0.5489, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 623ms, time_since_start: 11m 38s 698ms, eta: 18m 40s 312ms\n",
            "\u001b[32m2022-12-09T08:38:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/6000, train/hateful_memes/cross_entropy: 0.3758, train/hateful_memes/cross_entropy/avg: 0.5437, train/total_loss: 0.3758, train/total_loss/avg: 0.5437, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 545ms, time_since_start: 11m 52s 244ms, eta: 18m 19s 460ms\n",
            "\u001b[32m2022-12-09T08:38:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/6000, train/hateful_memes/cross_entropy: 0.3730, train/hateful_memes/cross_entropy/avg: 0.5374, train/total_loss: 0.3730, train/total_loss/avg: 0.5374, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 341ms, time_since_start: 12m 05s 585ms, eta: 17m 48s 644ms\n",
            "\u001b[32m2022-12-09T08:38:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/6000, train/hateful_memes/cross_entropy: 0.3630, train/hateful_memes/cross_entropy/avg: 0.5335, train/total_loss: 0.3630, train/total_loss/avg: 0.5335, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 423ms, time_since_start: 12m 19s 009ms, eta: 17m 40s 913ms\n",
            "\u001b[32m2022-12-09T08:39:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/6000, train/hateful_memes/cross_entropy: 0.3605, train/hateful_memes/cross_entropy/avg: 0.5248, train/total_loss: 0.3605, train/total_loss/avg: 0.5248, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 315ms, time_since_start: 12m 32s 325ms, eta: 17m 18s 135ms\n",
            "\u001b[32m2022-12-09T08:39:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/6000, train/hateful_memes/cross_entropy: 0.3605, train/hateful_memes/cross_entropy/avg: 0.5235, train/total_loss: 0.3605, train/total_loss/avg: 0.5235, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 6000, lr: 0.00005, ups: 3.85, time: 13s 558ms, time_since_start: 12m 45s 883ms, eta: 17m 22s 560ms\n",
            "\u001b[32m2022-12-09T08:39:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/6000, train/hateful_memes/cross_entropy: 0.3605, train/hateful_memes/cross_entropy/avg: 0.5162, train/total_loss: 0.3605, train/total_loss/avg: 0.5162, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 305ms, time_since_start: 12m 59s 189ms, eta: 16m 48s 947ms\n",
            "\u001b[32m2022-12-09T08:39:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, train/hateful_memes/cross_entropy: 0.3225, train/hateful_memes/cross_entropy/avg: 0.5087, train/total_loss: 0.3225, train/total_loss/avg: 0.5087, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 328ms, time_since_start: 13m 12s 517ms, eta: 16m 36s 424ms\n",
            "\u001b[32m2022-12-09T08:39:43 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:39:43 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:39:47 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:39:47 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:39:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:39:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:39:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:39:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, val/hateful_memes/cross_entropy: 1.0226, val/total_loss: 1.0226, val/hateful_memes/accuracy: 0.6556, val/hateful_memes/binary_f1: 0.3882, val/hateful_memes/roc_auc: 0.5993, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 6000, val_time: 14s 389ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:40:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/6000, train/hateful_memes/cross_entropy: 0.2863, train/hateful_memes/cross_entropy/avg: 0.5019, train/total_loss: 0.2863, train/total_loss/avg: 0.5019, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 703ms, time_since_start: 13m 40s 611ms, eta: 16m 49s 856ms\n",
            "\u001b[32m2022-12-09T08:40:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/6000, train/hateful_memes/cross_entropy: 0.2826, train/hateful_memes/cross_entropy/avg: 0.4977, train/total_loss: 0.2826, train/total_loss/avg: 0.4977, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 410ms, time_since_start: 13m 54s 022ms, eta: 16m 13s 893ms\n",
            "\u001b[32m2022-12-09T08:40:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/6000, train/hateful_memes/cross_entropy: 0.2800, train/hateful_memes/cross_entropy/avg: 0.4912, train/total_loss: 0.2800, train/total_loss/avg: 0.4912, max mem: 7111.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 439ms, time_since_start: 14m 07s 461ms, eta: 16m 01s 667ms\n",
            "\u001b[32m2022-12-09T08:40:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/6000, train/hateful_memes/cross_entropy: 0.2800, train/hateful_memes/cross_entropy/avg: 0.4852, train/total_loss: 0.2800, train/total_loss/avg: 0.4852, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 993ms, time_since_start: 14m 21s 455ms, eta: 16m 26s 377ms\n",
            "\u001b[32m2022-12-09T08:41:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/6000, train/hateful_memes/cross_entropy: 0.2783, train/hateful_memes/cross_entropy/avg: 0.4778, train/total_loss: 0.2783, train/total_loss/avg: 0.4778, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 697ms, time_since_start: 14m 35s 152ms, eta: 15m 50s 892ms\n",
            "\u001b[32m2022-12-09T08:41:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/6000, train/hateful_memes/cross_entropy: 0.2586, train/hateful_memes/cross_entropy/avg: 0.4706, train/total_loss: 0.2586, train/total_loss/avg: 0.4706, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 554ms, time_since_start: 14m 48s 707ms, eta: 15m 26s 507ms\n",
            "\u001b[32m2022-12-09T08:41:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/6000, train/hateful_memes/cross_entropy: 0.2583, train/hateful_memes/cross_entropy/avg: 0.4645, train/total_loss: 0.2583, train/total_loss/avg: 0.4645, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 551ms, time_since_start: 15m 02s 258ms, eta: 15m 11s 771ms\n",
            "\u001b[32m2022-12-09T08:41:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/6000, train/hateful_memes/cross_entropy: 0.1661, train/hateful_memes/cross_entropy/avg: 0.4578, train/total_loss: 0.1661, train/total_loss/avg: 0.4578, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 676ms, time_since_start: 15m 15s 935ms, eta: 15m 05s 590ms\n",
            "\u001b[32m2022-12-09T08:42:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/6000, train/hateful_memes/cross_entropy: 0.1658, train/hateful_memes/cross_entropy/avg: 0.4515, train/total_loss: 0.1658, train/total_loss/avg: 0.4515, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 533ms, time_since_start: 15m 29s 468ms, eta: 14m 41s 673ms\n",
            "\u001b[32m2022-12-09T08:42:13 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:42:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:42:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:42:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:42:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, train/hateful_memes/cross_entropy: 0.1658, train/hateful_memes/cross_entropy/avg: 0.4503, train/total_loss: 0.1658, train/total_loss/avg: 0.4503, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 6000, lr: 0.00004, ups: 1.92, time: 26s 241ms, time_since_start: 15m 55s 709ms, eta: 28m 01s 541ms\n",
            "\u001b[32m2022-12-09T08:42:26 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:42:26 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:42:30 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:42:30 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:42:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:42:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:42:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:42:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, val/hateful_memes/cross_entropy: 1.0718, val/total_loss: 1.0718, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.4174, val/hateful_memes/roc_auc: 0.5956, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 6000, val_time: 17s 122ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:42:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3050/6000, train/hateful_memes/cross_entropy: 0.1607, train/hateful_memes/cross_entropy/avg: 0.4442, train/total_loss: 0.1607, train/total_loss/avg: 0.4442, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 3050, iterations: 3050, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 760ms, time_since_start: 16m 26s 593ms, eta: 14m 27s 071ms\n",
            "\u001b[32m2022-12-09T08:43:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/6000, train/hateful_memes/cross_entropy: 0.1557, train/hateful_memes/cross_entropy/avg: 0.4387, train/total_loss: 0.1557, train/total_loss/avg: 0.4387, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 3100, iterations: 3100, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 795ms, time_since_start: 16m 40s 389ms, eta: 14m 14s 571ms\n",
            "\u001b[32m2022-12-09T08:43:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3150/6000, train/hateful_memes/cross_entropy: 0.1437, train/hateful_memes/cross_entropy/avg: 0.4337, train/total_loss: 0.1437, train/total_loss/avg: 0.4337, max mem: 7111.0, experiment: run, epoch: 6, num_updates: 3150, iterations: 3150, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 531ms, time_since_start: 16m 53s 921ms, eta: 13m 43s 749ms\n",
            "\u001b[32m2022-12-09T08:43:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/6000, train/hateful_memes/cross_entropy: 0.1252, train/hateful_memes/cross_entropy/avg: 0.4280, train/total_loss: 0.1252, train/total_loss/avg: 0.4280, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3200, iterations: 3200, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 824ms, time_since_start: 17m 07s 745ms, eta: 13m 46s 815ms\n",
            "\u001b[32m2022-12-09T08:43:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3250/6000, train/hateful_memes/cross_entropy: 0.1212, train/hateful_memes/cross_entropy/avg: 0.4219, train/total_loss: 0.1212, train/total_loss/avg: 0.4219, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3250, iterations: 3250, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 490ms, time_since_start: 17m 21s 236ms, eta: 13m 12s 459ms\n",
            "\u001b[32m2022-12-09T08:44:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/6000, train/hateful_memes/cross_entropy: 0.1193, train/hateful_memes/cross_entropy/avg: 0.4160, train/total_loss: 0.1193, train/total_loss/avg: 0.4160, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3300, iterations: 3300, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 415ms, time_since_start: 17m 34s 651ms, eta: 12m 53s 687ms\n",
            "\u001b[32m2022-12-09T08:44:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3350/6000, train/hateful_memes/cross_entropy: 0.1193, train/hateful_memes/cross_entropy/avg: 0.4125, train/total_loss: 0.1193, train/total_loss/avg: 0.4125, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3350, iterations: 3350, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 404ms, time_since_start: 17m 48s 056ms, eta: 12m 38s 734ms\n",
            "\u001b[32m2022-12-09T08:44:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/6000, train/hateful_memes/cross_entropy: 0.1038, train/hateful_memes/cross_entropy/avg: 0.4074, train/total_loss: 0.1038, train/total_loss/avg: 0.4074, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3400, iterations: 3400, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 365ms, time_since_start: 18m 01s 421ms, eta: 12m 22s 244ms\n",
            "\u001b[32m2022-12-09T08:44:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3450/6000, train/hateful_memes/cross_entropy: 0.0890, train/hateful_memes/cross_entropy/avg: 0.4019, train/total_loss: 0.0890, train/total_loss/avg: 0.4019, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3450, iterations: 3450, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 356ms, time_since_start: 18m 14s 778ms, eta: 12m 07s 524ms\n",
            "\u001b[32m2022-12-09T08:44:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, train/hateful_memes/cross_entropy: 0.0810, train/hateful_memes/cross_entropy/avg: 0.3971, train/total_loss: 0.0810, train/total_loss/avg: 0.3971, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3500, iterations: 3500, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 561ms, time_since_start: 18m 28s 339ms, eta: 12m 04s 192ms\n",
            "\u001b[32m2022-12-09T08:44:58 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:44:59 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:45:03 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:45:03 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:45:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:45:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:45:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:45:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, val/hateful_memes/cross_entropy: 1.1594, val/total_loss: 1.1594, val/hateful_memes/accuracy: 0.6537, val/hateful_memes/binary_f1: 0.4548, val/hateful_memes/roc_auc: 0.6215, num_updates: 3500, epoch: 7, iterations: 3500, max_updates: 6000, val_time: 15s 756ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:45:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3550/6000, train/hateful_memes/cross_entropy: 0.0810, train/hateful_memes/cross_entropy/avg: 0.3928, train/total_loss: 0.0810, train/total_loss/avg: 0.3928, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3550, iterations: 3550, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 707ms, time_since_start: 18m 57s 805ms, eta: 11m 57s 338ms\n",
            "\u001b[32m2022-12-09T08:45:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/6000, train/hateful_memes/cross_entropy: 0.0775, train/hateful_memes/cross_entropy/avg: 0.3877, train/total_loss: 0.0775, train/total_loss/avg: 0.3877, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3600, iterations: 3600, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 540ms, time_since_start: 19m 11s 345ms, eta: 11m 34s 133ms\n",
            "\u001b[32m2022-12-09T08:45:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3650/6000, train/hateful_memes/cross_entropy: 0.0775, train/hateful_memes/cross_entropy/avg: 0.3837, train/total_loss: 0.0775, train/total_loss/avg: 0.3837, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3650, iterations: 3650, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 440ms, time_since_start: 19m 24s 786ms, eta: 11m 14s 674ms\n",
            "\u001b[32m2022-12-09T08:46:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/6000, train/hateful_memes/cross_entropy: 0.0775, train/hateful_memes/cross_entropy/avg: 0.3797, train/total_loss: 0.0775, train/total_loss/avg: 0.3797, max mem: 7111.0, experiment: run, epoch: 7, num_updates: 3700, iterations: 3700, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 427ms, time_since_start: 19m 38s 213ms, eta: 10m 59s 660ms\n",
            "\u001b[32m2022-12-09T08:46:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3750/6000, train/hateful_memes/cross_entropy: 0.0738, train/hateful_memes/cross_entropy/avg: 0.3750, train/total_loss: 0.0738, train/total_loss/avg: 0.3750, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 3750, iterations: 3750, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 624ms, time_since_start: 19m 51s 838ms, eta: 10m 54s 790ms\n",
            "\u001b[32m2022-12-09T08:46:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/6000, train/hateful_memes/cross_entropy: 0.0810, train/hateful_memes/cross_entropy/avg: 0.3716, train/total_loss: 0.0810, train/total_loss/avg: 0.3716, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 3800, iterations: 3800, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 357ms, time_since_start: 20m 05s 195ms, eta: 10m 27s 683ms\n",
            "\u001b[32m2022-12-09T08:46:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3850/6000, train/hateful_memes/cross_entropy: 0.0736, train/hateful_memes/cross_entropy/avg: 0.3674, train/total_loss: 0.0736, train/total_loss/avg: 0.3674, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 3850, iterations: 3850, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 531ms, time_since_start: 20m 18s 726ms, eta: 10m 21s 409ms\n",
            "\u001b[32m2022-12-09T08:47:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/6000, train/hateful_memes/cross_entropy: 0.0736, train/hateful_memes/cross_entropy/avg: 0.3631, train/total_loss: 0.0736, train/total_loss/avg: 0.3631, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 3900, iterations: 3900, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 583ms, time_since_start: 20m 32s 310ms, eta: 10m 09s 323ms\n",
            "\u001b[32m2022-12-09T08:47:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3950/6000, train/hateful_memes/cross_entropy: 0.0676, train/hateful_memes/cross_entropy/avg: 0.3586, train/total_loss: 0.0676, train/total_loss/avg: 0.3586, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 3950, iterations: 3950, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 461ms, time_since_start: 20m 45s 772ms, eta: 09m 49s 460ms\n",
            "\u001b[32m2022-12-09T08:47:29 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:47:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:47:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:47:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:47:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, train/hateful_memes/cross_entropy: 0.0676, train/hateful_memes/cross_entropy/avg: 0.3554, train/total_loss: 0.0676, train/total_loss/avg: 0.3554, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 4000, iterations: 4000, max_updates: 6000, lr: 0.00003, ups: 1.92, time: 26s 757ms, time_since_start: 21m 12s 529ms, eta: 19m 03s 067ms\n",
            "\u001b[32m2022-12-09T08:47:43 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:47:43 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:47:47 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:47:47 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:47:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:47:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:48:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:48:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, val/hateful_memes/cross_entropy: 1.2078, val/total_loss: 1.2078, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.4248, val/hateful_memes/roc_auc: 0.6203, num_updates: 4000, epoch: 8, iterations: 4000, max_updates: 6000, val_time: 16s 952ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:48:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4050/6000, train/hateful_memes/cross_entropy: 0.0637, train/hateful_memes/cross_entropy/avg: 0.3511, train/total_loss: 0.0637, train/total_loss/avg: 0.3511, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 4050, iterations: 4050, max_updates: 6000, lr: 0.00002, ups: 3.57, time: 14s 019ms, time_since_start: 21m 43s 504ms, eta: 09m 43s 958ms\n",
            "\u001b[32m2022-12-09T08:48:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/6000, train/hateful_memes/cross_entropy: 0.0454, train/hateful_memes/cross_entropy/avg: 0.3472, train/total_loss: 0.0454, train/total_loss/avg: 0.3472, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 4100, iterations: 4100, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 662ms, time_since_start: 21m 57s 166ms, eta: 09m 14s 484ms\n",
            "\u001b[32m2022-12-09T08:48:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4150/6000, train/hateful_memes/cross_entropy: 0.0454, train/hateful_memes/cross_entropy/avg: 0.3440, train/total_loss: 0.0454, train/total_loss/avg: 0.3440, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 4150, iterations: 4150, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 518ms, time_since_start: 22m 10s 685ms, eta: 08m 54s 215ms\n",
            "\u001b[32m2022-12-09T08:48:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/6000, train/hateful_memes/cross_entropy: 0.0325, train/hateful_memes/cross_entropy/avg: 0.3400, train/total_loss: 0.0325, train/total_loss/avg: 0.3400, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 4200, iterations: 4200, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 738ms, time_since_start: 22m 24s 423ms, eta: 08m 48s 200ms\n",
            "\u001b[32m2022-12-09T08:49:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4250/6000, train/hateful_memes/cross_entropy: 0.0325, train/hateful_memes/cross_entropy/avg: 0.3364, train/total_loss: 0.0325, train/total_loss/avg: 0.3364, max mem: 7111.0, experiment: run, epoch: 8, num_updates: 4250, iterations: 4250, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 570ms, time_since_start: 22m 37s 994ms, eta: 08m 27s 260ms\n",
            "\u001b[32m2022-12-09T08:49:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/6000, train/hateful_memes/cross_entropy: 0.0454, train/hateful_memes/cross_entropy/avg: 0.3335, train/total_loss: 0.0454, train/total_loss/avg: 0.3335, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4300, iterations: 4300, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 881ms, time_since_start: 22m 51s 875ms, eta: 08m 24s 078ms\n",
            "\u001b[32m2022-12-09T08:49:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4350/6000, train/hateful_memes/cross_entropy: 0.0325, train/hateful_memes/cross_entropy/avg: 0.3298, train/total_loss: 0.0325, train/total_loss/avg: 0.3298, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4350, iterations: 4350, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 440ms, time_since_start: 23m 05s 316ms, eta: 07m 53s 703ms\n",
            "\u001b[32m2022-12-09T08:49:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/6000, train/hateful_memes/cross_entropy: 0.0321, train/hateful_memes/cross_entropy/avg: 0.3263, train/total_loss: 0.0321, train/total_loss/avg: 0.3263, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4400, iterations: 4400, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 544ms, time_since_start: 23m 18s 861ms, eta: 07m 42s 906ms\n",
            "\u001b[32m2022-12-09T08:50:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4450/6000, train/hateful_memes/cross_entropy: 0.0321, train/hateful_memes/cross_entropy/avg: 0.3227, train/total_loss: 0.0321, train/total_loss/avg: 0.3227, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4450, iterations: 4450, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 579ms, time_since_start: 23m 32s 440ms, eta: 07m 29s 576ms\n",
            "\u001b[32m2022-12-09T08:50:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, train/hateful_memes/cross_entropy: 0.0296, train/hateful_memes/cross_entropy/avg: 0.3193, train/total_loss: 0.0296, train/total_loss/avg: 0.3193, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4500, iterations: 4500, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 519ms, time_since_start: 23m 45s 959ms, eta: 07m 13s 156ms\n",
            "\u001b[32m2022-12-09T08:50:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:50:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:50:20 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:50:20 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:50:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:50:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:50:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:50:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, val/hateful_memes/cross_entropy: 1.4331, val/total_loss: 1.4331, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.3311, val/hateful_memes/roc_auc: 0.5965, num_updates: 4500, epoch: 9, iterations: 4500, max_updates: 6000, val_time: 15s 406ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:50:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4550/6000, train/hateful_memes/cross_entropy: 0.0289, train/hateful_memes/cross_entropy/avg: 0.3159, train/total_loss: 0.0289, train/total_loss/avg: 0.3159, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4550, iterations: 4550, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 678ms, time_since_start: 24m 15s 046ms, eta: 07m 03s 649ms\n",
            "\u001b[32m2022-12-09T08:50:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/6000, train/hateful_memes/cross_entropy: 0.0289, train/hateful_memes/cross_entropy/avg: 0.3127, train/total_loss: 0.0289, train/total_loss/avg: 0.3127, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4600, iterations: 4600, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 362ms, time_since_start: 24m 28s 408ms, eta: 06m 39s 596ms\n",
            "\u001b[32m2022-12-09T08:51:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4650/6000, train/hateful_memes/cross_entropy: 0.0289, train/hateful_memes/cross_entropy/avg: 0.3103, train/total_loss: 0.0289, train/total_loss/avg: 0.3103, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4650, iterations: 4650, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 426ms, time_since_start: 24m 41s 835ms, eta: 06m 27s 165ms\n",
            "\u001b[32m2022-12-09T08:51:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/6000, train/hateful_memes/cross_entropy: 0.0217, train/hateful_memes/cross_entropy/avg: 0.3072, train/total_loss: 0.0217, train/total_loss/avg: 0.3072, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4700, iterations: 4700, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 444ms, time_since_start: 24m 55s 280ms, eta: 06m 13s 333ms\n",
            "\u001b[32m2022-12-09T08:51:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4750/6000, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.3041, train/total_loss: 0.0209, train/total_loss/avg: 0.3041, max mem: 7111.0, experiment: run, epoch: 9, num_updates: 4750, iterations: 4750, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 499ms, time_since_start: 25m 08s 779ms, eta: 06m 432ms\n",
            "\u001b[32m2022-12-09T08:51:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/6000, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.3015, train/total_loss: 0.0209, train/total_loss/avg: 0.3015, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 4800, iterations: 4800, max_updates: 6000, lr: 0.00002, ups: 3.85, time: 13s 746ms, time_since_start: 25m 22s 526ms, eta: 05m 52s 358ms\n",
            "\u001b[32m2022-12-09T08:52:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4850/6000, train/hateful_memes/cross_entropy: 0.0181, train/hateful_memes/cross_entropy/avg: 0.2986, train/total_loss: 0.0181, train/total_loss/avg: 0.2986, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 4850, iterations: 4850, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 406ms, time_since_start: 25m 35s 932ms, eta: 05m 29s 318ms\n",
            "\u001b[32m2022-12-09T08:52:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/6000, train/hateful_memes/cross_entropy: 0.0159, train/hateful_memes/cross_entropy/avg: 0.2957, train/total_loss: 0.0159, train/total_loss/avg: 0.2957, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 4900, iterations: 4900, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 552ms, time_since_start: 25m 49s 485ms, eta: 05m 18s 429ms\n",
            "\u001b[32m2022-12-09T08:52:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4950/6000, train/hateful_memes/cross_entropy: 0.0159, train/hateful_memes/cross_entropy/avg: 0.2928, train/total_loss: 0.0159, train/total_loss/avg: 0.2928, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 4950, iterations: 4950, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 368ms, time_since_start: 26m 02s 853ms, eta: 04m 59s 825ms\n",
            "\u001b[32m2022-12-09T08:52:46 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:52:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:52:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:52:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:52:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, train/hateful_memes/cross_entropy: 0.0136, train/hateful_memes/cross_entropy/avg: 0.2899, train/total_loss: 0.0136, train/total_loss/avg: 0.2899, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 5000, iterations: 5000, max_updates: 6000, lr: 0.00001, ups: 1.92, time: 26s 334ms, time_since_start: 26m 29s 187ms, eta: 09m 22s 495ms\n",
            "\u001b[32m2022-12-09T08:52:59 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:52:59 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:53:04 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:53:04 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:53:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:53:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:53:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:53:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, val/hateful_memes/cross_entropy: 1.4059, val/total_loss: 1.4059, val/hateful_memes/accuracy: 0.6463, val/hateful_memes/binary_f1: 0.4013, val/hateful_memes/roc_auc: 0.6148, num_updates: 5000, epoch: 10, iterations: 5000, max_updates: 6000, val_time: 15s 982ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:53:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5050/6000, train/hateful_memes/cross_entropy: 0.0136, train/hateful_memes/cross_entropy/avg: 0.2871, train/total_loss: 0.0136, train/total_loss/avg: 0.2871, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 5050, iterations: 5050, max_updates: 6000, lr: 0.00001, ups: 3.57, time: 14s 009ms, time_since_start: 26m 59s 180ms, eta: 04m 44s 277ms\n",
            "\u001b[32m2022-12-09T08:53:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/6000, train/hateful_memes/cross_entropy: 0.0136, train/hateful_memes/cross_entropy/avg: 0.2849, train/total_loss: 0.0136, train/total_loss/avg: 0.2849, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 5100, iterations: 5100, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 558ms, time_since_start: 27m 12s 739ms, eta: 04m 20s 647ms\n",
            "\u001b[32m2022-12-09T08:53:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5150/6000, train/hateful_memes/cross_entropy: 0.0136, train/hateful_memes/cross_entropy/avg: 0.2822, train/total_loss: 0.0136, train/total_loss/avg: 0.2822, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 5150, iterations: 5150, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 498ms, time_since_start: 27m 26s 238ms, eta: 04m 05s 082ms\n",
            "\u001b[32m2022-12-09T08:54:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/6000, train/hateful_memes/cross_entropy: 0.0136, train/hateful_memes/cross_entropy/avg: 0.2796, train/total_loss: 0.0136, train/total_loss/avg: 0.2796, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 5200, iterations: 5200, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 496ms, time_since_start: 27m 39s 734ms, eta: 03m 50s 632ms\n",
            "\u001b[32m2022-12-09T08:54:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5250/6000, train/hateful_memes/cross_entropy: 0.0121, train/hateful_memes/cross_entropy/avg: 0.2771, train/total_loss: 0.0121, train/total_loss/avg: 0.2771, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 5250, iterations: 5250, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 483ms, time_since_start: 27m 53s 218ms, eta: 03m 36s 005ms\n",
            "\u001b[32m2022-12-09T08:54:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/6000, train/hateful_memes/cross_entropy: 0.0121, train/hateful_memes/cross_entropy/avg: 0.2747, train/total_loss: 0.0121, train/total_loss/avg: 0.2747, max mem: 7111.0, experiment: run, epoch: 10, num_updates: 5300, iterations: 5300, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 336ms, time_since_start: 28m 06s 554ms, eta: 03m 19s 410ms\n",
            "\u001b[32m2022-12-09T08:54:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5350/6000, train/hateful_memes/cross_entropy: 0.0121, train/hateful_memes/cross_entropy/avg: 0.2722, train/total_loss: 0.0121, train/total_loss/avg: 0.2722, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5350, iterations: 5350, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 861ms, time_since_start: 28m 20s 416ms, eta: 03m 12s 459ms\n",
            "\u001b[32m2022-12-09T08:55:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/6000, train/hateful_memes/cross_entropy: 0.0119, train/hateful_memes/cross_entropy/avg: 0.2697, train/total_loss: 0.0119, train/total_loss/avg: 0.2697, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5400, iterations: 5400, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 749ms, time_since_start: 28m 34s 166ms, eta: 02m 56s 218ms\n",
            "\u001b[32m2022-12-09T08:55:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5450/6000, train/hateful_memes/cross_entropy: 0.0119, train/hateful_memes/cross_entropy/avg: 0.2673, train/total_loss: 0.0119, train/total_loss/avg: 0.2673, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5450, iterations: 5450, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 515ms, time_since_start: 28m 47s 682ms, eta: 02m 38s 784ms\n",
            "\u001b[32m2022-12-09T08:55:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, train/hateful_memes/cross_entropy: 0.0113, train/hateful_memes/cross_entropy/avg: 0.2649, train/total_loss: 0.0113, train/total_loss/avg: 0.2649, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5500, iterations: 5500, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 625ms, time_since_start: 29m 01s 308ms, eta: 02m 25s 522ms\n",
            "\u001b[32m2022-12-09T08:55:31 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:55:31 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:55:36 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:55:36 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:55:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:55:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:55:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:55:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, val/hateful_memes/cross_entropy: 1.4015, val/total_loss: 1.4015, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.3537, val/hateful_memes/roc_auc: 0.6090, num_updates: 5500, epoch: 11, iterations: 5500, max_updates: 6000, val_time: 15s 659ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:56:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5550/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2626, train/total_loss: 0.0098, train/total_loss/avg: 0.2626, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5550, iterations: 5550, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 612ms, time_since_start: 29m 30s 581ms, eta: 02m 10s 841ms\n",
            "\u001b[32m2022-12-09T08:56:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2607, train/total_loss: 0.0098, train/total_loss/avg: 0.2607, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5600, iterations: 5600, max_updates: 6000, lr: 0.00001, ups: 3.85, time: 13s 434ms, time_since_start: 29m 44s 015ms, eta: 01m 54s 782ms\n",
            "\u001b[32m2022-12-09T08:56:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5650/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2585, train/total_loss: 0.0098, train/total_loss/avg: 0.2585, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5650, iterations: 5650, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 321ms, time_since_start: 29m 57s 336ms, eta: 01m 39s 591ms\n",
            "\u001b[32m2022-12-09T08:56:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2563, train/total_loss: 0.0098, train/total_loss/avg: 0.2563, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5700, iterations: 5700, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 313ms, time_since_start: 30m 10s 650ms, eta: 01m 25s 312ms\n",
            "\u001b[32m2022-12-09T08:56:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5750/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2542, train/total_loss: 0.0098, train/total_loss/avg: 0.2542, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5750, iterations: 5750, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 462ms, time_since_start: 30m 24s 112ms, eta: 01m 11s 887ms\n",
            "\u001b[32m2022-12-09T08:57:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/6000, train/hateful_memes/cross_entropy: 0.0091, train/hateful_memes/cross_entropy/avg: 0.2521, train/total_loss: 0.0091, train/total_loss/avg: 0.2521, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5800, iterations: 5800, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 343ms, time_since_start: 30m 37s 456ms, eta: 57s 005ms\n",
            "\u001b[32m2022-12-09T08:57:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5850/6000, train/hateful_memes/cross_entropy: 0.0091, train/hateful_memes/cross_entropy/avg: 0.2500, train/total_loss: 0.0091, train/total_loss/avg: 0.2500, max mem: 7111.0, experiment: run, epoch: 11, num_updates: 5850, iterations: 5850, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 268ms, time_since_start: 30m 50s 724ms, eta: 42s 512ms\n",
            "\u001b[32m2022-12-09T08:57:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2482, train/total_loss: 0.0098, train/total_loss/avg: 0.2482, max mem: 7111.0, experiment: run, epoch: 12, num_updates: 5900, iterations: 5900, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 846ms, time_since_start: 31m 04s 571ms, eta: 29s 575ms\n",
            "\u001b[32m2022-12-09T08:57:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5950/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2461, train/total_loss: 0.0098, train/total_loss/avg: 0.2461, max mem: 7111.0, experiment: run, epoch: 12, num_updates: 5950, iterations: 5950, max_updates: 6000, lr: 0., ups: 3.85, time: 13s 621ms, time_since_start: 31m 18s 192ms, eta: 14s 547ms\n",
            "\u001b[32m2022-12-09T08:58:02 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T08:58:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:58:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:58:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:58:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, train/hateful_memes/cross_entropy: 0.0098, train/hateful_memes/cross_entropy/avg: 0.2441, train/total_loss: 0.0098, train/total_loss/avg: 0.2441, max mem: 7111.0, experiment: run, epoch: 12, num_updates: 6000, iterations: 6000, max_updates: 6000, lr: 0., ups: 2.00, time: 25s 093ms, time_since_start: 31m 43s 286ms, eta: 0ms\n",
            "\u001b[32m2022-12-09T08:58:13 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T08:58:13 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T08:58:18 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T08:58:18 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:58:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T08:58:24 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T08:58:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T08:58:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, val/hateful_memes/cross_entropy: 1.4919, val/total_loss: 1.4919, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.3571, val/hateful_memes/roc_auc: 0.6076, num_updates: 6000, epoch: 12, iterations: 6000, max_updates: 6000, val_time: 15s 379ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.621853\n",
            "\u001b[32m2022-12-09T08:58:29 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2022-12-09T08:58:29 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2022-12-09T08:58:29 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2022-12-09T08:58:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-12-09T08:58:31 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2000\n",
            "\u001b[32m2022-12-09T08:58:31 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2000\n",
            "\u001b[32m2022-12-09T08:58:31 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 4\n",
            "\u001b[32m2022-12-09T08:58:32 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-12-09T08:58:32 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 125/125 [00:14<00:00,  8.53it/s]\n",
            "\u001b[32m2022-12-09T08:58:47 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 125\n",
            "\u001b[32m2022-12-09T08:58:47 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T08:58:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, test/hateful_memes/cross_entropy: 0.8193, test/total_loss: 0.8193, test/hateful_memes/accuracy: 0.6425, test/hateful_memes/binary_f1: 0.3656, test/hateful_memes/roc_auc: 0.6371\n",
            "\u001b[32m2022-12-09T08:58:47 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 32m 16s 445ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/mmbt/defaults.yaml \\\n",
        "  model=mmbt \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=6000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100 \\\n",
        "  env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2YN4XMD4sGR",
        "outputId": "9f8083a7-77fe-4564-d431-c87c7ab16d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "\u001b[32m2022-12-09T21:58:20 | mmf: \u001b[0mLogging to: /drive/MyDrive/final_project/mmf/projects/hateful_memes/save/train.log\n",
            "\u001b[32m2022-12-09T21:58:20 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=6000', 'training.batch_size=16', 'training.evaluation_interval=500', 'trainer.params.gpus=100', 'env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save'])\n",
            "\u001b[32m2022-12-09T21:58:20 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n",
            "\u001b[32m2022-12-09T21:58:20 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla T4\n",
            "\u001b[32m2022-12-09T21:58:20 | mmf_cli.run: \u001b[0mUsing seed 20721635\n",
            "\u001b[32m2022-12-09T21:58:20 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:01<00:00, 154kB/s] \n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp28vb2apd\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 28.3kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpk6_3716p\n",
            "Downloading: 100% 570/570 [00:00<00:00, 549kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8iilhri9\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 314kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfjiwr3ha\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 509kB/s] \n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "\u001b[32m2022-12-09T21:58:34 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T21:58:34 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T21:58:34 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-09T21:58:34 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpkvk0wbai\n",
            "Downloading: 100% 440M/440M [00:04<00:00, 102MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelJit: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModelJit from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModelJit from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModelJit were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModelJit for predictions without further training.\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100% 230M/230M [00:02<00:00, 108MB/s]\n",
            "\u001b[32m2022-12-09T21:58:55 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-12-09T21:58:55 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-12-09T21:58:55 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-12-09T21:58:55 | mmf.trainers.mmf_trainer: \u001b[0mMMBT(\n",
            "  (model): MMBTForClassification(\n",
            "    (bert): MMBTBase(\n",
            "      (mmbt): MMBTModel(\n",
            "        (transformer): BertModelJit(\n",
            "          (embeddings): BertEmbeddingsJit(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoderJit(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "        (modal_encoder): ModalEmbeddings(\n",
            "          (encoder): ResNet152ImageEncoder(\n",
            "            (model): Sequential(\n",
            "              (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "              (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "              (4): Sequential(\n",
            "                (0): Bottleneck(\n",
            "                  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                  (downsample): Sequential(\n",
            "                    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  )\n",
            "                )\n",
            "                (1): Bottleneck(\n",
            "                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (2): Bottleneck(\n",
            "                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "              (5): Sequential(\n",
            "                (0): Bottleneck(\n",
            "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                  (downsample): Sequential(\n",
            "                    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  )\n",
            "                )\n",
            "                (1): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (2): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (3): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (4): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (5): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (6): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (7): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "              (6): Sequential(\n",
            "                (0): Bottleneck(\n",
            "                  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                  (downsample): Sequential(\n",
            "                    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  )\n",
            "                )\n",
            "                (1): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (2): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (3): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (4): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (5): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (6): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (7): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (8): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (9): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (10): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (11): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (12): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (13): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (14): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (15): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (16): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (17): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (18): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (19): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (20): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (21): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (22): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (23): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (24): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (25): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (26): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (27): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (28): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (29): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (30): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (31): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (32): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (33): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (34): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (35): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "              (7): Sequential(\n",
            "                (0): Bottleneck(\n",
            "                  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                  (downsample): Sequential(\n",
            "                    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  )\n",
            "                )\n",
            "                (1): Bottleneck(\n",
            "                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "                (2): Bottleneck(\n",
            "                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (relu): ReLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          )\n",
            "          (proj_embeddings): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-12-09T21:58:55 | mmf.utils.general: \u001b[0mTotal Parameters: 169793346. Trained Parameters: 169793346\n",
            "\u001b[32m2022-12-09T21:58:55 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T21:58:55 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-12-09T21:58:55 | py.warnings: \u001b[0m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\n",
            "\u001b[32m2022-12-09T21:59:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/6000, train/hateful_memes/cross_entropy: 0.5997, train/hateful_memes/cross_entropy/avg: 0.5997, train/total_loss: 0.5997, train/total_loss/avg: 0.5997, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 6000, lr: 0., ups: 1.19, time: 42s 156ms, time_since_start: 42s 208ms, eta: 01h 29m 17s 764ms\n",
            "\u001b[32m2022-12-09T22:00:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/6000, train/hateful_memes/cross_entropy: 0.5997, train/hateful_memes/cross_entropy/avg: 0.6208, train/total_loss: 0.5997, train/total_loss/avg: 0.6208, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 6000, lr: 0., ups: 1.16, time: 43s 819ms, time_since_start: 01m 26s 028ms, eta: 01h 32m 02s 356ms\n",
            "\u001b[32m2022-12-09T22:01:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6719, train/total_loss: 0.6419, train/total_loss/avg: 0.6719, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 319ms, time_since_start: 02m 11s 347ms, eta: 01h 34m 22s 910ms\n",
            "\u001b[32m2022-12-09T22:01:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/6000, train/hateful_memes/cross_entropy: 0.6312, train/hateful_memes/cross_entropy/avg: 0.6618, train/total_loss: 0.6312, train/total_loss/avg: 0.6618, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 635ms, time_since_start: 02m 55s 983ms, eta: 01h 32m 09s 811ms\n",
            "\u001b[32m2022-12-09T22:02:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6754, train/total_loss: 0.6419, train/total_loss/avg: 0.6754, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 788ms, time_since_start: 03m 40s 771ms, eta: 01h 31m 40s 898ms\n",
            "\u001b[32m2022-12-09T22:03:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/6000, train/hateful_memes/cross_entropy: 0.6312, train/hateful_memes/cross_entropy/avg: 0.6600, train/total_loss: 0.6312, train/total_loss/avg: 0.6600, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 788ms, time_since_start: 04m 25s 559ms, eta: 01h 30m 53s 076ms\n",
            "\u001b[32m2022-12-09T22:04:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6663, train/total_loss: 0.6419, train/total_loss/avg: 0.6663, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 878ms, time_since_start: 05m 10s 438ms, eta: 01h 30m 16s 139ms\n",
            "\u001b[32m2022-12-09T22:04:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/6000, train/hateful_memes/cross_entropy: 0.6312, train/hateful_memes/cross_entropy/avg: 0.6541, train/total_loss: 0.6312, train/total_loss/avg: 0.6541, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 838ms, time_since_start: 05m 55s 276ms, eta: 01h 29m 23s 353ms\n",
            "\u001b[32m2022-12-09T22:05:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6650, train/total_loss: 0.6419, train/total_loss/avg: 0.6650, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 741ms, time_since_start: 06m 40s 018ms, eta: 01h 28m 23s 995ms\n",
            "\u001b[32m2022-12-09T22:06:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6709, train/total_loss: 0.6419, train/total_loss/avg: 0.6709, max mem: 7138.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 737ms, time_since_start: 07m 24s 755ms, eta: 01h 27m 35s 718ms\n",
            "\u001b[32m2022-12-09T22:06:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T22:06:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T22:06:30 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T22:06:30 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T22:06:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:06:37 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T22:06:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:06:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:06:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, val/hateful_memes/cross_entropy: 0.6582, val/total_loss: 0.6582, val/hateful_memes/accuracy: 0.6241, val/hateful_memes/binary_f1: 0.0897, val/hateful_memes/roc_auc: 0.5587, num_updates: 500, epoch: 1, iterations: 500, max_updates: 6000, val_time: 34s 315ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.558691\n",
            "\u001b[32m2022-12-09T22:07:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/6000, train/hateful_memes/cross_entropy: 0.7041, train/hateful_memes/cross_entropy/avg: 0.6801, train/total_loss: 0.7041, train/total_loss/avg: 0.6801, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 595ms, time_since_start: 08m 44s 667ms, eta: 01h 28m 27s 858ms\n",
            "\u001b[32m2022-12-09T22:08:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/6000, train/hateful_memes/cross_entropy: 0.6878, train/hateful_memes/cross_entropy/avg: 0.6807, train/total_loss: 0.6878, train/total_loss/avg: 0.6807, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 561ms, time_since_start: 09m 29s 229ms, eta: 01h 25m 39s 955ms\n",
            "\u001b[32m2022-12-09T22:09:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/6000, train/hateful_memes/cross_entropy: 0.6878, train/hateful_memes/cross_entropy/avg: 0.6738, train/total_loss: 0.6878, train/total_loss/avg: 0.6738, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 002ms, time_since_start: 10m 14s 231ms, eta: 01h 25m 42s 657ms\n",
            "\u001b[32m2022-12-09T22:09:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6705, train/total_loss: 0.6419, train/total_loss/avg: 0.6705, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 688ms, time_since_start: 10m 58s 919ms, eta: 01h 24m 19s 086ms\n",
            "\u001b[32m2022-12-09T22:10:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6630, train/total_loss: 0.6419, train/total_loss/avg: 0.6630, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 811ms, time_since_start: 11m 43s 731ms, eta: 01h 23m 45s 181ms\n",
            "\u001b[32m2022-12-09T22:11:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6662, train/total_loss: 0.6419, train/total_loss/avg: 0.6662, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 870ms, time_since_start: 12m 28s 601ms, eta: 01h 23m 03s 804ms\n",
            "\u001b[32m2022-12-09T22:12:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6581, train/total_loss: 0.6419, train/total_loss/avg: 0.6581, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 766ms, time_since_start: 13m 13s 367ms, eta: 01h 22m 04s 442ms\n",
            "\u001b[32m2022-12-09T22:12:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6613, train/total_loss: 0.6419, train/total_loss/avg: 0.6613, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 900, iterations: 900, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 838ms, time_since_start: 13m 58s 206ms, eta: 01h 21m 24s 553ms\n",
            "\u001b[32m2022-12-09T22:13:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/6000, train/hateful_memes/cross_entropy: 0.6419, train/hateful_memes/cross_entropy/avg: 0.6545, train/total_loss: 0.6419, train/total_loss/avg: 0.6545, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 950, iterations: 950, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 697ms, time_since_start: 14m 42s 904ms, eta: 01h 20m 21s 470ms\n",
            "\u001b[32m2022-12-09T22:14:22 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T22:14:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:14:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:14:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:14:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, train/hateful_memes/cross_entropy: 0.6312, train/hateful_memes/cross_entropy/avg: 0.6448, train/total_loss: 0.6312, train/total_loss/avg: 0.6448, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 1000, iterations: 1000, max_updates: 6000, lr: 0.00001, ups: 0.83, time: 01m 883ms, time_since_start: 15m 43s 787ms, eta: 01h 48m 22s 327ms\n",
            "\u001b[32m2022-12-09T22:14:38 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T22:14:38 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T22:14:49 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T22:14:49 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T22:14:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:14:57 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T22:15:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:15:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:15:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, val/hateful_memes/cross_entropy: 0.7530, val/total_loss: 0.7530, val/hateful_memes/accuracy: 0.6352, val/hateful_memes/binary_f1: 0.2088, val/hateful_memes/roc_auc: 0.5965, num_updates: 1000, epoch: 2, iterations: 1000, max_updates: 6000, val_time: 34s 737ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.596471\n",
            "\u001b[32m2022-12-09T22:15:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/6000, train/hateful_memes/cross_entropy: 0.6312, train/hateful_memes/cross_entropy/avg: 0.6399, train/total_loss: 0.6312, train/total_loss/avg: 0.6399, max mem: 7138.0, experiment: run, epoch: 2, num_updates: 1050, iterations: 1050, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 068ms, time_since_start: 17m 04s 594ms, eta: 01h 21m 10s 937ms\n",
            "\u001b[32m2022-12-09T22:16:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/6000, train/hateful_memes/cross_entropy: 0.6288, train/hateful_memes/cross_entropy/avg: 0.6300, train/total_loss: 0.6288, train/total_loss/avg: 0.6300, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 277ms, time_since_start: 17m 48s 872ms, eta: 01h 17m 14s 232ms\n",
            "\u001b[32m2022-12-09T22:17:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/6000, train/hateful_memes/cross_entropy: 0.5904, train/hateful_memes/cross_entropy/avg: 0.6175, train/total_loss: 0.5904, train/total_loss/avg: 0.6175, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 036ms, time_since_start: 18m 33s 908ms, eta: 01h 17m 45s 608ms\n",
            "\u001b[32m2022-12-09T22:18:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/6000, train/hateful_memes/cross_entropy: 0.5831, train/hateful_memes/cross_entropy/avg: 0.6118, train/total_loss: 0.5831, train/total_loss/avg: 0.6118, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 725ms, time_since_start: 19m 18s 634ms, eta: 01h 16m 25s 600ms\n",
            "\u001b[32m2022-12-09T22:18:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/6000, train/hateful_memes/cross_entropy: 0.5831, train/hateful_memes/cross_entropy/avg: 0.6180, train/total_loss: 0.5831, train/total_loss/avg: 0.6180, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 885ms, time_since_start: 20m 03s 520ms, eta: 01h 15m 54s 131ms\n",
            "\u001b[32m2022-12-09T22:19:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/6000, train/hateful_memes/cross_entropy: 0.5685, train/hateful_memes/cross_entropy/avg: 0.6145, train/total_loss: 0.5685, train/total_loss/avg: 0.6145, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 745ms, time_since_start: 20m 48s 265ms, eta: 01h 14m 52s 088ms\n",
            "\u001b[32m2022-12-09T22:20:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/6000, train/hateful_memes/cross_entropy: 0.5685, train/hateful_memes/cross_entropy/avg: 0.6136, train/total_loss: 0.5685, train/total_loss/avg: 0.6136, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 759ms, time_since_start: 21m 33s 025ms, eta: 01h 14m 05s 702ms\n",
            "\u001b[32m2022-12-09T22:21:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/6000, train/hateful_memes/cross_entropy: 0.5569, train/hateful_memes/cross_entropy/avg: 0.6080, train/total_loss: 0.5569, train/total_loss/avg: 0.6080, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 777ms, time_since_start: 22m 17s 803ms, eta: 01h 13m 19s 701ms\n",
            "\u001b[32m2022-12-09T22:21:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/6000, train/hateful_memes/cross_entropy: 0.5428, train/hateful_memes/cross_entropy/avg: 0.5991, train/total_loss: 0.5428, train/total_loss/avg: 0.5991, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 718ms, time_since_start: 23m 02s 521ms, eta: 01h 12m 26s 064ms\n",
            "\u001b[32m2022-12-09T22:22:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, train/hateful_memes/cross_entropy: 0.5331, train/hateful_memes/cross_entropy/avg: 0.5897, train/total_loss: 0.5331, train/total_loss/avg: 0.5897, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 884ms, time_since_start: 23m 47s 405ms, eta: 01h 11m 54s 278ms\n",
            "\u001b[32m2022-12-09T22:22:42 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T22:22:42 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T22:22:52 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T22:22:52 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T22:22:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:23:00 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T22:23:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:23:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:23:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, val/hateful_memes/cross_entropy: 0.7846, val/total_loss: 0.7846, val/hateful_memes/accuracy: 0.6426, val/hateful_memes/binary_f1: 0.2772, val/hateful_memes/roc_auc: 0.6176, num_updates: 1500, epoch: 3, iterations: 1500, max_updates: 6000, val_time: 34s 237ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.617632\n",
            "\u001b[32m2022-12-09T22:24:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/6000, train/hateful_memes/cross_entropy: 0.5331, train/hateful_memes/cross_entropy/avg: 0.5887, train/total_loss: 0.5331, train/total_loss/avg: 0.5887, max mem: 7138.0, experiment: run, epoch: 3, num_updates: 1550, iterations: 1550, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 823ms, time_since_start: 25m 07s 467ms, eta: 01h 12m 35s 617ms\n",
            "\u001b[32m2022-12-09T22:24:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/6000, train/hateful_memes/cross_entropy: 0.5293, train/hateful_memes/cross_entropy/avg: 0.5846, train/total_loss: 0.5293, train/total_loss/avg: 0.5846, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1600, iterations: 1600, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 323ms, time_since_start: 25m 51s 790ms, eta: 01h 09m 25s 674ms\n",
            "\u001b[32m2022-12-09T22:25:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/6000, train/hateful_memes/cross_entropy: 0.5266, train/hateful_memes/cross_entropy/avg: 0.5784, train/total_loss: 0.5266, train/total_loss/avg: 0.5784, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1650, iterations: 1650, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 995ms, time_since_start: 26m 36s 786ms, eta: 01h 09m 40s 808ms\n",
            "\u001b[32m2022-12-09T22:26:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/6000, train/hateful_memes/cross_entropy: 0.4799, train/hateful_memes/cross_entropy/avg: 0.5730, train/total_loss: 0.4799, train/total_loss/avg: 0.5730, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1700, iterations: 1700, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 720ms, time_since_start: 27m 21s 506ms, eta: 01h 08m 27s 459ms\n",
            "\u001b[32m2022-12-09T22:27:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/6000, train/hateful_memes/cross_entropy: 0.4598, train/hateful_memes/cross_entropy/avg: 0.5694, train/total_loss: 0.4598, train/total_loss/avg: 0.5694, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 913ms, time_since_start: 28m 06s 420ms, eta: 01h 07m 57s 264ms\n",
            "\u001b[32m2022-12-09T22:27:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/6000, train/hateful_memes/cross_entropy: 0.4577, train/hateful_memes/cross_entropy/avg: 0.5663, train/total_loss: 0.4577, train/total_loss/avg: 0.5663, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 724ms, time_since_start: 28m 51s 144ms, eta: 01h 06m 52s 306ms\n",
            "\u001b[32m2022-12-09T22:28:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/6000, train/hateful_memes/cross_entropy: 0.4577, train/hateful_memes/cross_entropy/avg: 0.5563, train/total_loss: 0.4577, train/total_loss/avg: 0.5563, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 704ms, time_since_start: 29m 35s 848ms, eta: 01h 06m 02s 776ms\n",
            "\u001b[32m2022-12-09T22:29:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/6000, train/hateful_memes/cross_entropy: 0.4569, train/hateful_memes/cross_entropy/avg: 0.5533, train/total_loss: 0.4569, train/total_loss/avg: 0.5533, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 763ms, time_since_start: 30m 20s 612ms, eta: 01h 05m 20s 220ms\n",
            "\u001b[32m2022-12-09T22:30:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/6000, train/hateful_memes/cross_entropy: 0.4569, train/hateful_memes/cross_entropy/avg: 0.5530, train/total_loss: 0.4569, train/total_loss/avg: 0.5530, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 855ms, time_since_start: 31m 05s 467ms, eta: 01h 04m 40s 342ms\n",
            "\u001b[32m2022-12-09T22:30:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T22:30:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:30:52 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:31:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:31:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, train/hateful_memes/cross_entropy: 0.4569, train/hateful_memes/cross_entropy/avg: 0.5515, train/total_loss: 0.4569, train/total_loss/avg: 0.5515, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 6000, lr: 0.00001, ups: 0.83, time: 01m 169ms, time_since_start: 32m 05s 637ms, eta: 01h 25m 40s 908ms\n",
            "\u001b[32m2022-12-09T22:31:00 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T22:31:00 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T22:31:11 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T22:31:11 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T22:31:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:31:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:31:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:31:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, val/hateful_memes/cross_entropy: 0.7611, val/total_loss: 0.7611, val/hateful_memes/accuracy: 0.6259, val/hateful_memes/binary_f1: 0.3176, val/hateful_memes/roc_auc: 0.6155, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 6000, val_time: 26s 695ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.617632\n",
            "\u001b[32m2022-12-09T22:32:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/6000, train/hateful_memes/cross_entropy: 0.4476, train/hateful_memes/cross_entropy/avg: 0.5487, train/total_loss: 0.4476, train/total_loss/avg: 0.5487, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 092ms, time_since_start: 33m 18s 427ms, eta: 01h 04m 48s 932ms\n",
            "\u001b[32m2022-12-09T22:32:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/6000, train/hateful_memes/cross_entropy: 0.4476, train/hateful_memes/cross_entropy/avg: 0.5413, train/total_loss: 0.4476, train/total_loss/avg: 0.5413, max mem: 7138.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 473ms, time_since_start: 34m 02s 901ms, eta: 01h 01m 44s 838ms\n",
            "\u001b[32m2022-12-09T22:33:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/6000, train/hateful_memes/cross_entropy: 0.4476, train/hateful_memes/cross_entropy/avg: 0.5377, train/total_loss: 0.4476, train/total_loss/avg: 0.5377, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 047ms, time_since_start: 34m 47s 949ms, eta: 01h 01m 44s 555ms\n",
            "\u001b[32m2022-12-09T22:34:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/6000, train/hateful_memes/cross_entropy: 0.4476, train/hateful_memes/cross_entropy/avg: 0.5374, train/total_loss: 0.4476, train/total_loss/avg: 0.5374, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 706ms, time_since_start: 35m 32s 655ms, eta: 01h 28s 738ms\n",
            "\u001b[32m2022-12-09T22:35:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/6000, train/hateful_memes/cross_entropy: 0.4449, train/hateful_memes/cross_entropy/avg: 0.5304, train/total_loss: 0.4449, train/total_loss/avg: 0.5304, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 830ms, time_since_start: 36m 17s 486ms, eta: 59m 50s 953ms\n",
            "\u001b[32m2022-12-09T22:35:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/6000, train/hateful_memes/cross_entropy: 0.4359, train/hateful_memes/cross_entropy/avg: 0.5274, train/total_loss: 0.4359, train/total_loss/avg: 0.5274, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 830ms, time_since_start: 37m 02s 317ms, eta: 59m 03s 019ms\n",
            "\u001b[32m2022-12-09T22:36:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/6000, train/hateful_memes/cross_entropy: 0.3951, train/hateful_memes/cross_entropy/avg: 0.5191, train/total_loss: 0.3951, train/total_loss/avg: 0.5191, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 877ms, time_since_start: 37m 47s 194ms, eta: 58m 18s 854ms\n",
            "\u001b[32m2022-12-09T22:37:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/6000, train/hateful_memes/cross_entropy: 0.3915, train/hateful_memes/cross_entropy/avg: 0.5116, train/total_loss: 0.3915, train/total_loss/avg: 0.5116, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 809ms, time_since_start: 38m 32s 004ms, eta: 57m 25s 685ms\n",
            "\u001b[32m2022-12-09T22:38:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/6000, train/hateful_memes/cross_entropy: 0.3915, train/hateful_memes/cross_entropy/avg: 0.5054, train/total_loss: 0.3915, train/total_loss/avg: 0.5054, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 726ms, time_since_start: 39m 16s 730ms, eta: 56m 31s 488ms\n",
            "\u001b[32m2022-12-09T22:38:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, train/hateful_memes/cross_entropy: 0.3915, train/hateful_memes/cross_entropy/avg: 0.5012, train/total_loss: 0.3915, train/total_loss/avg: 0.5012, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 798ms, time_since_start: 40m 01s 528ms, eta: 55m 49s 104ms\n",
            "\u001b[32m2022-12-09T22:38:56 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T22:38:56 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T22:39:07 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T22:39:07 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T22:39:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:39:14 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T22:39:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:39:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:39:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, val/hateful_memes/cross_entropy: 0.9129, val/total_loss: 0.9129, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.3576, val/hateful_memes/roc_auc: 0.6238, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 6000, val_time: 34s 207ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.623794\n",
            "\u001b[32m2022-12-09T22:40:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/6000, train/hateful_memes/cross_entropy: 0.3889, train/hateful_memes/cross_entropy/avg: 0.4934, train/total_loss: 0.3889, train/total_loss/avg: 0.4934, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 805ms, time_since_start: 41m 21s 543ms, eta: 56m 15s 531ms\n",
            "\u001b[32m2022-12-09T22:41:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/6000, train/hateful_memes/cross_entropy: 0.3811, train/hateful_memes/cross_entropy/avg: 0.4880, train/total_loss: 0.3811, train/total_loss/avg: 0.4880, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 605ms, time_since_start: 42m 06s 148ms, eta: 53m 59s 408ms\n",
            "\u001b[32m2022-12-09T22:41:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/6000, train/hateful_memes/cross_entropy: 0.3889, train/hateful_memes/cross_entropy/avg: 0.4930, train/total_loss: 0.3889, train/total_loss/avg: 0.4930, max mem: 7138.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 964ms, time_since_start: 42m 51s 113ms, eta: 53m 37s 496ms\n",
            "\u001b[32m2022-12-09T22:42:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/6000, train/hateful_memes/cross_entropy: 0.2950, train/hateful_memes/cross_entropy/avg: 0.4847, train/total_loss: 0.2950, train/total_loss/avg: 0.4847, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 669ms, time_since_start: 43m 35s 782ms, eta: 52m 28s 639ms\n",
            "\u001b[32m2022-12-09T22:43:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/6000, train/hateful_memes/cross_entropy: 0.2386, train/hateful_memes/cross_entropy/avg: 0.4772, train/total_loss: 0.2386, train/total_loss/avg: 0.4772, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 931ms, time_since_start: 44m 20s 714ms, eta: 51m 59s 153ms\n",
            "\u001b[32m2022-12-09T22:44:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/6000, train/hateful_memes/cross_entropy: 0.2231, train/hateful_memes/cross_entropy/avg: 0.4714, train/total_loss: 0.2231, train/total_loss/avg: 0.4714, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 826ms, time_since_start: 45m 05s 541ms, eta: 51m 03s 988ms\n",
            "\u001b[32m2022-12-09T22:44:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/6000, train/hateful_memes/cross_entropy: 0.2231, train/hateful_memes/cross_entropy/avg: 0.4643, train/total_loss: 0.2231, train/total_loss/avg: 0.4643, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 829ms, time_since_start: 45m 50s 370ms, eta: 50m 16s 332ms\n",
            "\u001b[32m2022-12-09T22:45:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/6000, train/hateful_memes/cross_entropy: 0.2172, train/hateful_memes/cross_entropy/avg: 0.4588, train/total_loss: 0.2172, train/total_loss/avg: 0.4588, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 782ms, time_since_start: 46m 35s 153ms, eta: 49m 25s 349ms\n",
            "\u001b[32m2022-12-09T22:46:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/6000, train/hateful_memes/cross_entropy: 0.2172, train/hateful_memes/cross_entropy/avg: 0.4571, train/total_loss: 0.2172, train/total_loss/avg: 0.4571, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 722ms, time_since_start: 47m 19s 876ms, eta: 48m 33s 604ms\n",
            "\u001b[32m2022-12-09T22:46:59 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T22:46:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:47:07 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:47:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:47:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, train/hateful_memes/cross_entropy: 0.2172, train/hateful_memes/cross_entropy/avg: 0.4540, train/total_loss: 0.2172, train/total_loss/avg: 0.4540, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 6000, lr: 0.00001, ups: 0.82, time: 01m 01s 145ms, time_since_start: 48m 21s 022ms, eta: 01h 05m 18s 200ms\n",
            "\u001b[32m2022-12-09T22:47:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T22:47:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T22:47:26 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T22:47:26 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T22:47:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:47:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:47:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:47:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, val/hateful_memes/cross_entropy: 1.2287, val/total_loss: 1.2287, val/hateful_memes/accuracy: 0.6259, val/hateful_memes/binary_f1: 0.2628, val/hateful_memes/roc_auc: 0.6129, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 6000, val_time: 26s 426ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.623794\n",
            "\u001b[32m2022-12-09T22:48:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3050/6000, train/hateful_memes/cross_entropy: 0.2048, train/hateful_memes/cross_entropy/avg: 0.4494, train/total_loss: 0.2048, train/total_loss/avg: 0.4494, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 3050, iterations: 3050, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 023ms, time_since_start: 49m 33s 473ms, eta: 48m 20s 032ms\n",
            "\u001b[32m2022-12-09T22:49:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/6000, train/hateful_memes/cross_entropy: 0.1749, train/hateful_memes/cross_entropy/avg: 0.4438, train/total_loss: 0.1749, train/total_loss/avg: 0.4438, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 3100, iterations: 3100, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 406ms, time_since_start: 50m 17s 880ms, eta: 45m 50s 740ms\n",
            "\u001b[32m2022-12-09T22:49:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3150/6000, train/hateful_memes/cross_entropy: 0.1622, train/hateful_memes/cross_entropy/avg: 0.4389, train/total_loss: 0.1622, train/total_loss/avg: 0.4389, max mem: 7138.0, experiment: run, epoch: 6, num_updates: 3150, iterations: 3150, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 018ms, time_since_start: 51m 02s 899ms, eta: 45m 40s 576ms\n",
            "\u001b[32m2022-12-09T22:50:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/6000, train/hateful_memes/cross_entropy: 0.1622, train/hateful_memes/cross_entropy/avg: 0.4376, train/total_loss: 0.1622, train/total_loss/avg: 0.4376, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3200, iterations: 3200, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 514ms, time_since_start: 51m 47s 414ms, eta: 44m 22s 340ms\n",
            "\u001b[32m2022-12-09T22:51:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3250/6000, train/hateful_memes/cross_entropy: 0.1553, train/hateful_memes/cross_entropy/avg: 0.4310, train/total_loss: 0.1553, train/total_loss/avg: 0.4310, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3250, iterations: 3250, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 953ms, time_since_start: 52m 32s 367ms, eta: 44m 559ms\n",
            "\u001b[32m2022-12-09T22:52:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/6000, train/hateful_memes/cross_entropy: 0.1467, train/hateful_memes/cross_entropy/avg: 0.4254, train/total_loss: 0.1467, train/total_loss/avg: 0.4254, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3300, iterations: 3300, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 623ms, time_since_start: 53m 16s 990ms, eta: 42m 53s 518ms\n",
            "\u001b[32m2022-12-09T22:52:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3350/6000, train/hateful_memes/cross_entropy: 0.1467, train/hateful_memes/cross_entropy/avg: 0.4192, train/total_loss: 0.1467, train/total_loss/avg: 0.4192, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3350, iterations: 3350, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 794ms, time_since_start: 54m 01s 785ms, eta: 42m 15s 572ms\n",
            "\u001b[32m2022-12-09T22:53:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/6000, train/hateful_memes/cross_entropy: 0.1385, train/hateful_memes/cross_entropy/avg: 0.4151, train/total_loss: 0.1385, train/total_loss/avg: 0.4151, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3400, iterations: 3400, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 767ms, time_since_start: 54m 46s 552ms, eta: 41m 26s 192ms\n",
            "\u001b[32m2022-12-09T22:54:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3450/6000, train/hateful_memes/cross_entropy: 0.1385, train/hateful_memes/cross_entropy/avg: 0.4118, train/total_loss: 0.1385, train/total_loss/avg: 0.4118, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3450, iterations: 3450, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 714ms, time_since_start: 55m 31s 267ms, eta: 40m 35s 496ms\n",
            "\u001b[32m2022-12-09T22:55:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, train/hateful_memes/cross_entropy: 0.1354, train/hateful_memes/cross_entropy/avg: 0.4070, train/total_loss: 0.1354, train/total_loss/avg: 0.4070, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3500, iterations: 3500, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 895ms, time_since_start: 56m 16s 162ms, eta: 39m 57s 424ms\n",
            "\u001b[32m2022-12-09T22:55:11 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T22:55:11 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T22:55:21 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T22:55:21 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T22:55:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T22:55:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T22:55:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T22:55:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, val/hateful_memes/cross_entropy: 1.5180, val/total_loss: 1.5180, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.3434, val/hateful_memes/roc_auc: 0.6214, num_updates: 3500, epoch: 7, iterations: 3500, max_updates: 6000, val_time: 25s 948ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.623794\n",
            "\u001b[32m2022-12-09T22:56:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3550/6000, train/hateful_memes/cross_entropy: 0.1354, train/hateful_memes/cross_entropy/avg: 0.4019, train/total_loss: 0.1354, train/total_loss/avg: 0.4019, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3550, iterations: 3550, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 872ms, time_since_start: 57m 27s 985ms, eta: 40m 613ms\n",
            "\u001b[32m2022-12-09T22:57:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/6000, train/hateful_memes/cross_entropy: 0.1354, train/hateful_memes/cross_entropy/avg: 0.3985, train/total_loss: 0.1354, train/total_loss/avg: 0.3985, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3600, iterations: 3600, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 436ms, time_since_start: 58m 12s 422ms, eta: 37m 58s 008ms\n",
            "\u001b[32m2022-12-09T22:57:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3650/6000, train/hateful_memes/cross_entropy: 0.1018, train/hateful_memes/cross_entropy/avg: 0.3938, train/total_loss: 0.1018, train/total_loss/avg: 0.3938, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3650, iterations: 3650, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 099ms, time_since_start: 58m 57s 521ms, eta: 37m 43s 792ms\n",
            "\u001b[32m2022-12-09T22:58:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/6000, train/hateful_memes/cross_entropy: 0.1018, train/hateful_memes/cross_entropy/avg: 0.3893, train/total_loss: 0.1018, train/total_loss/avg: 0.3893, max mem: 7138.0, experiment: run, epoch: 7, num_updates: 3700, iterations: 3700, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 736ms, time_since_start: 59m 42s 257ms, eta: 36m 37s 807ms\n",
            "\u001b[32m2022-12-09T22:59:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3750/6000, train/hateful_memes/cross_entropy: 0.1354, train/hateful_memes/cross_entropy/avg: 0.3873, train/total_loss: 0.1354, train/total_loss/avg: 0.3873, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 3750, iterations: 3750, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 724ms, time_since_start: 01h 26s 982ms, eta: 35m 49s 479ms\n",
            "\u001b[32m2022-12-09T23:00:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/6000, train/hateful_memes/cross_entropy: 0.1018, train/hateful_memes/cross_entropy/avg: 0.3823, train/total_loss: 0.1018, train/total_loss/avg: 0.3823, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 3800, iterations: 3800, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 851ms, time_since_start: 01h 01m 11s 834ms, eta: 35m 07s 663ms\n",
            "\u001b[32m2022-12-09T23:00:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3850/6000, train/hateful_memes/cross_entropy: 0.1018, train/hateful_memes/cross_entropy/avg: 0.3778, train/total_loss: 0.1018, train/total_loss/avg: 0.3778, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 3850, iterations: 3850, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 740ms, time_since_start: 01h 01m 56s 574ms, eta: 34m 14s 666ms\n",
            "\u001b[32m2022-12-09T23:01:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/6000, train/hateful_memes/cross_entropy: 0.0718, train/hateful_memes/cross_entropy/avg: 0.3732, train/total_loss: 0.0718, train/total_loss/avg: 0.3732, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 3900, iterations: 3900, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 765ms, time_since_start: 01h 02m 41s 340ms, eta: 33m 28s 008ms\n",
            "\u001b[32m2022-12-09T23:02:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3950/6000, train/hateful_memes/cross_entropy: 0.0645, train/hateful_memes/cross_entropy/avg: 0.3688, train/total_loss: 0.0645, train/total_loss/avg: 0.3688, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 3950, iterations: 3950, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 658ms, time_since_start: 01h 03m 25s 999ms, eta: 32m 35s 525ms\n",
            "\u001b[32m2022-12-09T23:03:05 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T23:03:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:03:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:03:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:03:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, train/hateful_memes/cross_entropy: 0.0590, train/hateful_memes/cross_entropy/avg: 0.3642, train/total_loss: 0.0590, train/total_loss/avg: 0.3642, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 4000, iterations: 4000, max_updates: 6000, lr: 0.00001, ups: 0.83, time: 01m 099ms, time_since_start: 01h 04m 26s 098ms, eta: 42m 47s 440ms\n",
            "\u001b[32m2022-12-09T23:03:21 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T23:03:21 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T23:03:31 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T23:03:31 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T23:03:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:03:40 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:03:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:03:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, val/hateful_memes/cross_entropy: 1.6325, val/total_loss: 1.6325, val/hateful_memes/accuracy: 0.6222, val/hateful_memes/binary_f1: 0.4000, val/hateful_memes/roc_auc: 0.6199, num_updates: 4000, epoch: 8, iterations: 4000, max_updates: 6000, val_time: 26s 455ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.623794\n",
            "\u001b[32m2022-12-09T23:04:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4050/6000, train/hateful_memes/cross_entropy: 0.0560, train/hateful_memes/cross_entropy/avg: 0.3598, train/total_loss: 0.0560, train/total_loss/avg: 0.3598, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 4050, iterations: 4050, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 969ms, time_since_start: 01h 05m 38s 525ms, eta: 31m 54s 741ms\n",
            "\u001b[32m2022-12-09T23:05:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/6000, train/hateful_memes/cross_entropy: 0.0469, train/hateful_memes/cross_entropy/avg: 0.3555, train/total_loss: 0.0469, train/total_loss/avg: 0.3555, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 4100, iterations: 4100, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 479ms, time_since_start: 01h 06m 23s 005ms, eta: 30m 05s 158ms\n",
            "\u001b[32m2022-12-09T23:06:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4150/6000, train/hateful_memes/cross_entropy: 0.0325, train/hateful_memes/cross_entropy/avg: 0.3516, train/total_loss: 0.0325, train/total_loss/avg: 0.3516, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 4150, iterations: 4150, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 064ms, time_since_start: 01h 07m 08s 069ms, eta: 29m 40s 756ms\n",
            "\u001b[32m2022-12-09T23:06:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/6000, train/hateful_memes/cross_entropy: 0.0312, train/hateful_memes/cross_entropy/avg: 0.3475, train/total_loss: 0.0312, train/total_loss/avg: 0.3475, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 4200, iterations: 4200, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 694ms, time_since_start: 01h 07m 52s 764ms, eta: 28m 38s 424ms\n",
            "\u001b[32m2022-12-09T23:07:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4250/6000, train/hateful_memes/cross_entropy: 0.0325, train/hateful_memes/cross_entropy/avg: 0.3462, train/total_loss: 0.0325, train/total_loss/avg: 0.3462, max mem: 7138.0, experiment: run, epoch: 8, num_updates: 4250, iterations: 4250, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 800ms, time_since_start: 01h 08m 37s 564ms, eta: 27m 54s 640ms\n",
            "\u001b[32m2022-12-09T23:08:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/6000, train/hateful_memes/cross_entropy: 0.0312, train/hateful_memes/cross_entropy/avg: 0.3423, train/total_loss: 0.0312, train/total_loss/avg: 0.3423, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4300, iterations: 4300, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 566ms, time_since_start: 01h 09m 22s 131ms, eta: 26m 58s 298ms\n",
            "\u001b[32m2022-12-09T23:09:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4350/6000, train/hateful_memes/cross_entropy: 0.0312, train/hateful_memes/cross_entropy/avg: 0.3385, train/total_loss: 0.0312, train/total_loss/avg: 0.3385, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4350, iterations: 4350, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 872ms, time_since_start: 01h 10m 07s 003ms, eta: 26m 21s 490ms\n",
            "\u001b[32m2022-12-09T23:09:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/6000, train/hateful_memes/cross_entropy: 0.0207, train/hateful_memes/cross_entropy/avg: 0.3347, train/total_loss: 0.0207, train/total_loss/avg: 0.3347, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4400, iterations: 4400, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 719ms, time_since_start: 01h 10m 51s 723ms, eta: 25m 28s 332ms\n",
            "\u001b[32m2022-12-09T23:10:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4450/6000, train/hateful_memes/cross_entropy: 0.0207, train/hateful_memes/cross_entropy/avg: 0.3318, train/total_loss: 0.0207, train/total_loss/avg: 0.3318, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4450, iterations: 4450, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 796ms, time_since_start: 01h 11m 36s 520ms, eta: 24m 43s 136ms\n",
            "\u001b[32m2022-12-09T23:11:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, train/hateful_memes/cross_entropy: 0.0207, train/hateful_memes/cross_entropy/avg: 0.3285, train/total_loss: 0.0207, train/total_loss/avg: 0.3285, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4500, iterations: 4500, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 832ms, time_since_start: 01h 12m 21s 352ms, eta: 23m 56s 436ms\n",
            "\u001b[32m2022-12-09T23:11:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T23:11:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T23:11:26 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T23:11:26 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T23:11:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:11:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:11:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:11:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, val/hateful_memes/cross_entropy: 1.9871, val/total_loss: 1.9871, val/hateful_memes/accuracy: 0.6204, val/hateful_memes/binary_f1: 0.3322, val/hateful_memes/roc_auc: 0.6090, num_updates: 4500, epoch: 9, iterations: 4500, max_updates: 6000, val_time: 26s 372ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.623794\n",
            "\u001b[32m2022-12-09T23:12:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4550/6000, train/hateful_memes/cross_entropy: 0.0205, train/hateful_memes/cross_entropy/avg: 0.3251, train/total_loss: 0.0205, train/total_loss/avg: 0.3251, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4550, iterations: 4550, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 964ms, time_since_start: 01h 13m 33s 690ms, eta: 23m 43s 615ms\n",
            "\u001b[32m2022-12-09T23:13:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/6000, train/hateful_memes/cross_entropy: 0.0205, train/hateful_memes/cross_entropy/avg: 0.3218, train/total_loss: 0.0205, train/total_loss/avg: 0.3218, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4600, iterations: 4600, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 482ms, time_since_start: 01h 14m 18s 173ms, eta: 22m 10s 204ms\n",
            "\u001b[32m2022-12-09T23:13:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4650/6000, train/hateful_memes/cross_entropy: 0.0198, train/hateful_memes/cross_entropy/avg: 0.3185, train/total_loss: 0.0198, train/total_loss/avg: 0.3185, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4650, iterations: 4650, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 046ms, time_since_start: 01h 15m 03s 220ms, eta: 21m 38s 969ms\n",
            "\u001b[32m2022-12-09T23:14:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/6000, train/hateful_memes/cross_entropy: 0.0198, train/hateful_memes/cross_entropy/avg: 0.3171, train/total_loss: 0.0198, train/total_loss/avg: 0.3171, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4700, iterations: 4700, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 655ms, time_since_start: 01h 15m 47s 875ms, eta: 20m 39s 995ms\n",
            "\u001b[32m2022-12-09T23:15:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4750/6000, train/hateful_memes/cross_entropy: 0.0128, train/hateful_memes/cross_entropy/avg: 0.3138, train/total_loss: 0.0128, train/total_loss/avg: 0.3138, max mem: 7138.0, experiment: run, epoch: 9, num_updates: 4750, iterations: 4750, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 773ms, time_since_start: 01h 16m 32s 649ms, eta: 19m 55s 457ms\n",
            "\u001b[32m2022-12-09T23:16:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/6000, train/hateful_memes/cross_entropy: 0.0110, train/hateful_memes/cross_entropy/avg: 0.3106, train/total_loss: 0.0110, train/total_loss/avg: 0.3106, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 4800, iterations: 4800, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 595ms, time_since_start: 01h 17m 17s 245ms, eta: 19m 03s 073ms\n",
            "\u001b[32m2022-12-09T23:16:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4850/6000, train/hateful_memes/cross_entropy: 0.0110, train/hateful_memes/cross_entropy/avg: 0.3081, train/total_loss: 0.0110, train/total_loss/avg: 0.3081, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 4850, iterations: 4850, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 781ms, time_since_start: 01h 18m 02s 026ms, eta: 18m 20s 022ms\n",
            "\u001b[32m2022-12-09T23:17:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/6000, train/hateful_memes/cross_entropy: 0.0106, train/hateful_memes/cross_entropy/avg: 0.3050, train/total_loss: 0.0106, train/total_loss/avg: 0.3050, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 4900, iterations: 4900, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 794ms, time_since_start: 01h 18m 46s 821ms, eta: 17m 32s 485ms\n",
            "\u001b[32m2022-12-09T23:18:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4950/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.3019, train/total_loss: 0.0097, train/total_loss/avg: 0.3019, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 4950, iterations: 4950, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 782ms, time_since_start: 01h 19m 31s 604ms, eta: 16m 44s 391ms\n",
            "\u001b[32m2022-12-09T23:19:11 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T23:19:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:19:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:19:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:19:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2990, train/total_loss: 0.0097, train/total_loss/avg: 0.2990, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 5000, iterations: 5000, max_updates: 6000, lr: 0., ups: 0.83, time: 01m 180ms, time_since_start: 01h 20m 31s 784ms, eta: 21m 25s 452ms\n",
            "\u001b[32m2022-12-09T23:19:26 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T23:19:26 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T23:19:37 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T23:19:37 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T23:19:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:19:45 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-09T23:19:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:20:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:20:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, val/hateful_memes/cross_entropy: 2.1545, val/total_loss: 2.1545, val/hateful_memes/accuracy: 0.6222, val/hateful_memes/binary_f1: 0.3665, val/hateful_memes/roc_auc: 0.6260, num_updates: 5000, epoch: 10, iterations: 5000, max_updates: 6000, val_time: 34s 355ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.625993\n",
            "\u001b[32m2022-12-09T23:20:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5050/6000, train/hateful_memes/cross_entropy: 0.0106, train/hateful_memes/cross_entropy/avg: 0.2968, train/total_loss: 0.0106, train/total_loss/avg: 0.2968, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 5050, iterations: 5050, max_updates: 6000, lr: 0., ups: 1.09, time: 46s 024ms, time_since_start: 01h 21m 52s 165ms, eta: 15m 33s 932ms\n",
            "\u001b[32m2022-12-09T23:21:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2940, train/total_loss: 0.0097, train/total_loss/avg: 0.2940, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 5100, iterations: 5100, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 412ms, time_since_start: 01h 22m 36s 578ms, eta: 14m 13s 785ms\n",
            "\u001b[32m2022-12-09T23:22:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5150/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2913, train/total_loss: 0.0097, train/total_loss/avg: 0.2913, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 5150, iterations: 5150, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 931ms, time_since_start: 01h 23m 21s 509ms, eta: 13m 35s 771ms\n",
            "\u001b[32m2022-12-09T23:23:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2885, train/total_loss: 0.0097, train/total_loss/avg: 0.2885, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 5200, iterations: 5200, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 784ms, time_since_start: 01h 24m 06s 294ms, eta: 12m 45s 274ms\n",
            "\u001b[32m2022-12-09T23:23:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5250/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2861, train/total_loss: 0.0097, train/total_loss/avg: 0.2861, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 5250, iterations: 5250, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 806ms, time_since_start: 01h 24m 51s 100ms, eta: 11m 57s 806ms\n",
            "\u001b[32m2022-12-09T23:24:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2834, train/total_loss: 0.0097, train/total_loss/avg: 0.2834, max mem: 7138.0, experiment: run, epoch: 10, num_updates: 5300, iterations: 5300, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 728ms, time_since_start: 01h 25m 35s 829ms, eta: 11m 08s 784ms\n",
            "\u001b[32m2022-12-09T23:25:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5350/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2808, train/total_loss: 0.0097, train/total_loss/avg: 0.2808, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5350, iterations: 5350, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 730ms, time_since_start: 01h 26m 20s 560ms, eta: 10m 21s 036ms\n",
            "\u001b[32m2022-12-09T23:26:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2783, train/total_loss: 0.0097, train/total_loss/avg: 0.2783, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5400, iterations: 5400, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 711ms, time_since_start: 01h 27m 05s 271ms, eta: 09m 33s 027ms\n",
            "\u001b[32m2022-12-09T23:26:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5450/6000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.2759, train/total_loss: 0.0097, train/total_loss/avg: 0.2759, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5450, iterations: 5450, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 699ms, time_since_start: 01h 27m 49s 971ms, eta: 08m 45s 134ms\n",
            "\u001b[32m2022-12-09T23:27:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, train/hateful_memes/cross_entropy: 0.0093, train/hateful_memes/cross_entropy/avg: 0.2735, train/total_loss: 0.0093, train/total_loss/avg: 0.2735, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5500, iterations: 5500, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 786ms, time_since_start: 01h 28m 34s 758ms, eta: 07m 58s 323ms\n",
            "\u001b[32m2022-12-09T23:27:29 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T23:27:29 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T23:27:40 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T23:27:40 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T23:27:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:27:47 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:27:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:27:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, val/hateful_memes/cross_entropy: 2.2710, val/total_loss: 2.2710, val/hateful_memes/accuracy: 0.6185, val/hateful_memes/binary_f1: 0.3439, val/hateful_memes/roc_auc: 0.6174, num_updates: 5500, epoch: 11, iterations: 5500, max_updates: 6000, val_time: 26s 539ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.625993\n",
            "\u001b[32m2022-12-09T23:28:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5550/6000, train/hateful_memes/cross_entropy: 0.0087, train/hateful_memes/cross_entropy/avg: 0.2710, train/total_loss: 0.0087, train/total_loss/avg: 0.2710, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5550, iterations: 5550, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 855ms, time_since_start: 01h 29m 47s 154ms, eta: 07m 20s 758ms\n",
            "\u001b[32m2022-12-09T23:29:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/6000, train/hateful_memes/cross_entropy: 0.0087, train/hateful_memes/cross_entropy/avg: 0.2687, train/total_loss: 0.0087, train/total_loss/avg: 0.2687, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5600, iterations: 5600, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 585ms, time_since_start: 01h 30m 31s 739ms, eta: 06m 20s 940ms\n",
            "\u001b[32m2022-12-09T23:30:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5650/6000, train/hateful_memes/cross_entropy: 0.0087, train/hateful_memes/cross_entropy/avg: 0.2664, train/total_loss: 0.0087, train/total_loss/avg: 0.2664, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5650, iterations: 5650, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 907ms, time_since_start: 01h 31m 16s 647ms, eta: 05m 35s 726ms\n",
            "\u001b[32m2022-12-09T23:30:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/6000, train/hateful_memes/cross_entropy: 0.0080, train/hateful_memes/cross_entropy/avg: 0.2641, train/total_loss: 0.0080, train/total_loss/avg: 0.2641, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5700, iterations: 5700, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 750ms, time_since_start: 01h 32m 01s 397ms, eta: 04m 46s 761ms\n",
            "\u001b[32m2022-12-09T23:31:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5750/6000, train/hateful_memes/cross_entropy: 0.0080, train/hateful_memes/cross_entropy/avg: 0.2618, train/total_loss: 0.0080, train/total_loss/avg: 0.2618, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5750, iterations: 5750, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 811ms, time_since_start: 01h 32m 46s 209ms, eta: 03m 59s 295ms\n",
            "\u001b[32m2022-12-09T23:32:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/6000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.2596, train/total_loss: 0.0049, train/total_loss/avg: 0.2596, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5800, iterations: 5800, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 673ms, time_since_start: 01h 33m 30s 882ms, eta: 03m 10s 843ms\n",
            "\u001b[32m2022-12-09T23:33:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5850/6000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.2575, train/total_loss: 0.0049, train/total_loss/avg: 0.2575, max mem: 7138.0, experiment: run, epoch: 11, num_updates: 5850, iterations: 5850, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 801ms, time_since_start: 01h 34m 15s 684ms, eta: 02m 23s 545ms\n",
            "\u001b[32m2022-12-09T23:33:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/6000, train/hateful_memes/cross_entropy: 0.0034, train/hateful_memes/cross_entropy/avg: 0.2553, train/total_loss: 0.0034, train/total_loss/avg: 0.2553, max mem: 7138.0, experiment: run, epoch: 12, num_updates: 5900, iterations: 5900, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 662ms, time_since_start: 01h 35m 347ms, eta: 01m 35s 399ms\n",
            "\u001b[32m2022-12-09T23:34:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5950/6000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.2532, train/total_loss: 0.0049, train/total_loss/avg: 0.2532, max mem: 7138.0, experiment: run, epoch: 12, num_updates: 5950, iterations: 5950, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 834ms, time_since_start: 01h 35m 45s 181ms, eta: 47s 882ms\n",
            "\u001b[32m2022-12-09T23:35:25 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-09T23:35:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:35:32 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:35:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:35:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.2512, train/total_loss: 0.0049, train/total_loss/avg: 0.2512, max mem: 7138.0, experiment: run, epoch: 12, num_updates: 6000, iterations: 6000, max_updates: 6000, lr: 0., ups: 0.83, time: 01m 871ms, time_since_start: 01h 36m 46s 053ms, eta: 0ms\n",
            "\u001b[32m2022-12-09T23:35:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-09T23:35:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-09T23:35:51 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-09T23:35:51 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T23:35:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-09T23:35:59 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-09T23:36:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-09T23:36:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, val/hateful_memes/cross_entropy: 2.3729, val/total_loss: 2.3729, val/hateful_memes/accuracy: 0.6241, val/hateful_memes/binary_f1: 0.3430, val/hateful_memes/roc_auc: 0.6162, num_updates: 6000, epoch: 12, iterations: 6000, max_updates: 6000, val_time: 26s 760ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.625993\n",
            "\u001b[32m2022-12-09T23:36:08 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2022-12-09T23:36:08 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2022-12-09T23:36:08 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2022-12-09T23:36:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-12-09T23:36:17 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 5000\n",
            "\u001b[32m2022-12-09T23:36:17 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 5000\n",
            "\u001b[32m2022-12-09T23:36:17 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 10\n",
            "\u001b[32m2022-12-09T23:36:19 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-12-09T23:36:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 125/125 [00:38<00:00,  3.26it/s]\n",
            "\u001b[32m2022-12-09T23:36:58 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 125\n",
            "\u001b[32m2022-12-09T23:36:58 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-09T23:36:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, test/hateful_memes/cross_entropy: 1.8144, test/total_loss: 1.8144, test/hateful_memes/accuracy: 0.6710, test/hateful_memes/binary_f1: 0.4650, test/hateful_memes/roc_auc: 0.6689\n",
            "\u001b[32m2022-12-09T23:36:58 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 01h 38m 03s 321ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/vilbert/defaults.yaml \\\n",
        "  model=vilbert \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=6000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100 \\\n",
        "  env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rAwNRkfBFJ4",
        "outputId": "6f1bf68d-d0f5-4915-832f-703486924733"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "\u001b[32m2022-12-10T21:55:16 | mmf: \u001b[0mLogging to: /drive/MyDrive/final_project/mmf/projects/hateful_memes/save/train.log\n",
            "\u001b[32m2022-12-10T21:55:16 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=6000', 'training.batch_size=16', 'training.evaluation_interval=500', 'trainer.params.gpus=100', 'env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save'])\n",
            "\u001b[32m2022-12-10T21:55:16 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n",
            "\u001b[32m2022-12-10T21:55:16 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla T4\n",
            "\u001b[32m2022-12-10T21:55:16 | mmf_cli.run: \u001b[0mUsing seed 16008848\n",
            "\u001b[32m2022-12-10T21:55:16 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n",
            "Downloading features.tar.gz: 100% 10.3G/10.3G [14:19<00:00, 12.0MB/s]\n",
            "[ Starting checksum for features.tar.gz]\n",
            "[ Checksum successful for features.tar.gz]\n",
            "Unpacking features.tar.gz\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:01<00:00, 124kB/s] \n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpogsk_ap3\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 24.4kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpusd8qx9j\n",
            "Downloading: 100% 570/570 [00:00<00:00, 411kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpowm7nnsb\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 256kB/s] \n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp38nhc4sm\n",
            "Downloading: 100% 466k/466k [00:01<00:00, 415kB/s] \n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "\u001b[32m2022-12-10T22:12:37 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-10T22:12:37 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-10T22:12:37 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-10T22:12:37 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bert_model_name\": \"bert-base-uncased\",\n",
            "  \"bi_attention_type\": 1,\n",
            "  \"bi_hidden_size\": 1024,\n",
            "  \"bi_intermediate_size\": 1024,\n",
            "  \"bi_num_attention_heads\": 8,\n",
            "  \"bypass_transformer\": false,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"cut_first\": \"text\",\n",
            "  \"dynamic_attention\": false,\n",
            "  \"embedding_strategy\": \"plain\",\n",
            "  \"fast_mode\": false,\n",
            "  \"finetune_lr_multiplier\": 1,\n",
            "  \"fixed_t_layer\": 0,\n",
            "  \"fixed_v_layer\": 0,\n",
            "  \"freeze_base\": false,\n",
            "  \"fusion_method\": \"mul\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hard_cap_seq_len\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"in_batch_pairs\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"losses\": [\n",
            "    \"cross_entropy\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model\": \"vilbert\",\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_negative\": 128,\n",
            "  \"objective\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooling_method\": \"mul\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"random_initialize\": false,\n",
            "  \"special_visual_initialize\": true,\n",
            "  \"t_biattention_id\": [\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    11\n",
            "  ],\n",
            "  \"task_specific_tokens\": false,\n",
            "  \"text_only\": false,\n",
            "  \"training_head_type\": \"classification\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"v_attention_probs_dropout_prob\": 0.1,\n",
            "  \"v_biattention_id\": [\n",
            "    0,\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5\n",
            "  ],\n",
            "  \"v_feature_size\": 2048,\n",
            "  \"v_hidden_act\": \"gelu\",\n",
            "  \"v_hidden_dropout_prob\": 0.1,\n",
            "  \"v_hidden_size\": 1024,\n",
            "  \"v_initializer_range\": 0.02,\n",
            "  \"v_intermediate_size\": 1024,\n",
            "  \"v_num_attention_heads\": 8,\n",
            "  \"v_num_hidden_layers\": 6,\n",
            "  \"v_target_size\": 1601,\n",
            "  \"visual_embedding_dim\": 2048,\n",
            "  \"visual_target\": 0,\n",
            "  \"visualization\": false,\n",
            "  \"vocab_size\": 30522,\n",
            "  \"with_coattention\": true\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/mmf/distributed_-1/tmpiarhp3zg\n",
            "Downloading: 100% 440M/440M [00:04<00:00, 108MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "creating metadata file for /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.bias', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.v_pooler.dense.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.v_embeddings.image_embeddings.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.t_pooler.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.t_pooler.dense.weight', 'bert.v_pooler.dense.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.c_layer.5.biOutput.dense1.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2022-12-10T22:12:52 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-12-10T22:12:52 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-12-10T22:12:52 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-12-10T22:12:52 | mmf.trainers.mmf_trainer: \u001b[0mViLBERT(\n",
            "  (model): ViLBERTForClassification(\n",
            "    (bert): ViLBERTBase(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (v_embeddings): BertImageFeatureEmbeddings(\n",
            "        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)\n",
            "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (v_layer): ModuleList(\n",
            "          (0): BertImageLayer(\n",
            "            (attention): BertImageAttention(\n",
            "              (self): BertImageSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertImageSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertImageLayer(\n",
            "            (attention): BertImageAttention(\n",
            "              (self): BertImageSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertImageSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertImageLayer(\n",
            "            (attention): BertImageAttention(\n",
            "              (self): BertImageSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertImageSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertImageLayer(\n",
            "            (attention): BertImageAttention(\n",
            "              (self): BertImageSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertImageSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertImageLayer(\n",
            "            (attention): BertImageAttention(\n",
            "              (self): BertImageSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertImageSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertImageLayer(\n",
            "            (attention): BertImageAttention(\n",
            "              (self): BertImageSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertImageSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (c_layer): ModuleList(\n",
            "          (0): BertConnectionLayer(\n",
            "            (biattention): BertBiAttention(\n",
            "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (biOutput): BertBiOutput(\n",
            "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (v_intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (v_output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (t_intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (t_output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertConnectionLayer(\n",
            "            (biattention): BertBiAttention(\n",
            "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (biOutput): BertBiOutput(\n",
            "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (v_intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (v_output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (t_intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (t_output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertConnectionLayer(\n",
            "            (biattention): BertBiAttention(\n",
            "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (biOutput): BertBiOutput(\n",
            "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (v_intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (v_output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (t_intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (t_output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertConnectionLayer(\n",
            "            (biattention): BertBiAttention(\n",
            "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (biOutput): BertBiOutput(\n",
            "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (v_intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (v_output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (t_intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (t_output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertConnectionLayer(\n",
            "            (biattention): BertBiAttention(\n",
            "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (biOutput): BertBiOutput(\n",
            "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (v_intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (v_output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (t_intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (t_output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertConnectionLayer(\n",
            "            (biattention): BertBiAttention(\n",
            "              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (biOutput): BertBiOutput(\n",
            "              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_dropout1): Dropout(p=0.1, inplace=False)\n",
            "              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout2): Dropout(p=0.1, inplace=False)\n",
            "              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "              (q_dropout2): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (v_intermediate): BertImageIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (v_output): BertImageOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (t_intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (t_output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (t_pooler): BertTextPooler(\n",
            "        (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (v_pooler): BertImagePooler(\n",
            "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=1024, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-12-10T22:12:52 | mmf.utils.general: \u001b[0mTotal Parameters: 247780354. Trained Parameters: 247780354\n",
            "\u001b[32m2022-12-10T22:12:52 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2022-12-10T22:13:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/6000, train/hateful_memes/cross_entropy: 0.7606, train/hateful_memes/cross_entropy/avg: 0.7606, train/total_loss: 0.7606, train/total_loss/avg: 0.7606, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 6000, lr: 0., ups: 1.19, time: 42s 270ms, time_since_start: 42s 361ms, eta: 01h 29m 32s 221ms\n",
            "\u001b[32m2022-12-10T22:14:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/6000, train/hateful_memes/cross_entropy: 0.6812, train/hateful_memes/cross_entropy/avg: 0.7209, train/total_loss: 0.6812, train/total_loss/avg: 0.7209, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 6000, lr: 0., ups: 1.19, time: 42s 427ms, time_since_start: 01m 24s 789ms, eta: 01h 29m 06s 889ms\n",
            "\u001b[32m2022-12-10T22:15:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/6000, train/hateful_memes/cross_entropy: 0.6812, train/hateful_memes/cross_entropy/avg: 0.6506, train/total_loss: 0.6812, train/total_loss/avg: 0.6506, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 833ms, time_since_start: 02m 09s 623ms, eta: 01h 33m 22s 247ms\n",
            "\u001b[32m2022-12-10T22:15:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6494, train/total_loss: 0.6460, train/total_loss/avg: 0.6494, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 779ms, time_since_start: 02m 54s 403ms, eta: 01h 32m 27s 681ms\n",
            "\u001b[32m2022-12-10T22:16:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/6000, train/hateful_memes/cross_entropy: 0.6812, train/hateful_memes/cross_entropy/avg: 0.6982, train/total_loss: 0.6812, train/total_loss/avg: 0.6982, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 833ms, time_since_start: 03m 39s 236ms, eta: 01h 31m 46s 476ms\n",
            "\u001b[32m2022-12-10T22:17:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/6000, train/hateful_memes/cross_entropy: 0.6812, train/hateful_memes/cross_entropy/avg: 0.7126, train/total_loss: 0.6812, train/total_loss/avg: 0.7126, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 861ms, time_since_start: 04m 24s 098ms, eta: 01h 31m 01s 963ms\n",
            "\u001b[32m2022-12-10T22:18:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/6000, train/hateful_memes/cross_entropy: 0.7606, train/hateful_memes/cross_entropy/avg: 0.7321, train/total_loss: 0.7606, train/total_loss/avg: 0.7321, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 947ms, time_since_start: 05m 09s 046ms, eta: 01h 30m 24s 503ms\n",
            "\u001b[32m2022-12-10T22:18:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/6000, train/hateful_memes/cross_entropy: 0.6812, train/hateful_memes/cross_entropy/avg: 0.7113, train/total_loss: 0.6812, train/total_loss/avg: 0.7113, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 878ms, time_since_start: 05m 53s 924ms, eta: 01h 29m 28s 184ms\n",
            "\u001b[32m2022-12-10T22:19:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/6000, train/hateful_memes/cross_entropy: 0.6812, train/hateful_memes/cross_entropy/avg: 0.7035, train/total_loss: 0.6812, train/total_loss/avg: 0.7035, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 957ms, time_since_start: 06m 38s 882ms, eta: 01h 28m 49s 609ms\n",
            "\u001b[32m2022-12-10T22:20:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6900, train/total_loss: 0.6460, train/total_loss/avg: 0.6900, max mem: 7248.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 826ms, time_since_start: 07m 23s 709ms, eta: 01h 27m 46s 261ms\n",
            "\u001b[32m2022-12-10T22:20:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T22:20:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T22:20:26 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T22:20:26 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T22:20:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T22:20:37 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T22:20:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T22:21:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T22:21:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, val/hateful_memes/cross_entropy: 0.6817, val/total_loss: 0.6817, val/hateful_memes/accuracy: 0.5852, val/hateful_memes/binary_f1: 0.3043, val/hateful_memes/roc_auc: 0.5147, num_updates: 500, epoch: 1, iterations: 500, max_updates: 6000, val_time: 44s 256ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.514706\n",
            "\u001b[32m2022-12-10T22:21:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/6000, train/hateful_memes/cross_entropy: 0.6812, train/hateful_memes/cross_entropy/avg: 0.6927, train/total_loss: 0.6812, train/total_loss/avg: 0.6927, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 743ms, time_since_start: 08m 53s 709ms, eta: 01h 28m 45s 056ms\n",
            "\u001b[32m2022-12-10T22:22:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6835, train/total_loss: 0.6460, train/total_loss/avg: 0.6835, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 810ms, time_since_start: 09m 38s 520ms, eta: 01h 26m 08s 674ms\n",
            "\u001b[32m2022-12-10T22:23:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6720, train/total_loss: 0.6460, train/total_loss/avg: 0.6720, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 367ms, time_since_start: 10m 23s 887ms, eta: 01h 26m 24s 406ms\n",
            "\u001b[32m2022-12-10T22:24:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6800, train/total_loss: 0.6460, train/total_loss/avg: 0.6800, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 877ms, time_since_start: 11m 08s 765ms, eta: 01h 24m 40s 479ms\n",
            "\u001b[32m2022-12-10T22:24:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6715, train/total_loss: 0.6460, train/total_loss/avg: 0.6715, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 141ms, time_since_start: 11m 53s 906ms, eta: 01h 24m 22s 215ms\n",
            "\u001b[32m2022-12-10T22:25:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/6000, train/hateful_memes/cross_entropy: 0.6406, train/hateful_memes/cross_entropy/avg: 0.6591, train/total_loss: 0.6406, train/total_loss/avg: 0.6591, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 007ms, time_since_start: 12m 38s 914ms, eta: 01h 23m 19s 120ms\n",
            "\u001b[32m2022-12-10T22:26:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6619, train/total_loss: 0.6460, train/total_loss/avg: 0.6619, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 186ms, time_since_start: 13m 24s 101ms, eta: 01h 22m 50s 682ms\n",
            "\u001b[32m2022-12-10T22:27:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6689, train/total_loss: 0.6460, train/total_loss/avg: 0.6689, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 900, iterations: 900, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 936ms, time_since_start: 14m 09s 038ms, eta: 01h 21m 35s 249ms\n",
            "\u001b[32m2022-12-10T22:27:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/6000, train/hateful_memes/cross_entropy: 0.6460, train/hateful_memes/cross_entropy/avg: 0.6618, train/total_loss: 0.6460, train/total_loss/avg: 0.6618, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 950, iterations: 950, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 143ms, time_since_start: 14m 54s 181ms, eta: 01h 21m 09s 530ms\n",
            "\u001b[32m2022-12-10T22:28:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-10T22:28:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T22:28:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T22:28:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T22:28:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, train/hateful_memes/cross_entropy: 0.6406, train/hateful_memes/cross_entropy/avg: 0.6571, train/total_loss: 0.6406, train/total_loss/avg: 0.6571, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 1000, iterations: 1000, max_updates: 6000, lr: 0.00001, ups: 0.75, time: 01m 07s 796ms, time_since_start: 16m 01s 978ms, eta: 02h 40s 682ms\n",
            "\u001b[32m2022-12-10T22:28:54 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T22:28:54 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T22:29:05 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T22:29:05 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T22:29:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T22:29:16 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T22:29:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T22:29:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T22:29:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, val/hateful_memes/cross_entropy: 0.7132, val/total_loss: 0.7132, val/hateful_memes/accuracy: 0.5333, val/hateful_memes/binary_f1: 0.4793, val/hateful_memes/roc_auc: 0.5723, num_updates: 1000, epoch: 2, iterations: 1000, max_updates: 6000, val_time: 44s 850ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.572309\n",
            "\u001b[32m2022-12-10T22:30:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/6000, train/hateful_memes/cross_entropy: 0.5826, train/hateful_memes/cross_entropy/avg: 0.6498, train/total_loss: 0.5826, train/total_loss/avg: 0.6498, max mem: 7248.0, experiment: run, epoch: 2, num_updates: 1050, iterations: 1050, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 778ms, time_since_start: 17m 33s 608ms, eta: 01h 22m 25s 988ms\n",
            "\u001b[32m2022-12-10T22:31:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/6000, train/hateful_memes/cross_entropy: 0.5694, train/hateful_memes/cross_entropy/avg: 0.6411, train/total_loss: 0.5694, train/total_loss/avg: 0.6411, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 462ms, time_since_start: 18m 18s 070ms, eta: 01h 17m 33s 581ms\n",
            "\u001b[32m2022-12-10T22:31:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/6000, train/hateful_memes/cross_entropy: 0.5826, train/hateful_memes/cross_entropy/avg: 0.6390, train/total_loss: 0.5826, train/total_loss/avg: 0.6390, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 413ms, time_since_start: 19m 03s 483ms, eta: 01h 18m 24s 621ms\n",
            "\u001b[32m2022-12-10T22:32:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/6000, train/hateful_memes/cross_entropy: 0.5826, train/hateful_memes/cross_entropy/avg: 0.6438, train/total_loss: 0.5826, train/total_loss/avg: 0.6438, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 931ms, time_since_start: 19m 48s 415ms, eta: 01h 16m 46s 715ms\n",
            "\u001b[32m2022-12-10T22:33:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/6000, train/hateful_memes/cross_entropy: 0.5694, train/hateful_memes/cross_entropy/avg: 0.6349, train/total_loss: 0.5694, train/total_loss/avg: 0.6349, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 140ms, time_since_start: 20m 33s 555ms, eta: 01h 16m 19s 981ms\n",
            "\u001b[32m2022-12-10T22:34:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/6000, train/hateful_memes/cross_entropy: 0.5684, train/hateful_memes/cross_entropy/avg: 0.6291, train/total_loss: 0.5684, train/total_loss/avg: 0.6291, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 014ms, time_since_start: 21m 18s 570ms, eta: 01h 15m 19s 133ms\n",
            "\u001b[32m2022-12-10T22:34:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/6000, train/hateful_memes/cross_entropy: 0.5662, train/hateful_memes/cross_entropy/avg: 0.6193, train/total_loss: 0.5662, train/total_loss/avg: 0.6193, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 212ms, time_since_start: 22m 03s 783ms, eta: 01h 14m 50s 720ms\n",
            "\u001b[32m2022-12-10T22:35:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/6000, train/hateful_memes/cross_entropy: 0.5527, train/hateful_memes/cross_entropy/avg: 0.6120, train/total_loss: 0.5527, train/total_loss/avg: 0.6120, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 874ms, time_since_start: 22m 48s 658ms, eta: 01h 13m 29s 218ms\n",
            "\u001b[32m2022-12-10T22:36:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/6000, train/hateful_memes/cross_entropy: 0.5527, train/hateful_memes/cross_entropy/avg: 0.6170, train/total_loss: 0.5527, train/total_loss/avg: 0.6170, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 129ms, time_since_start: 23m 33s 787ms, eta: 01h 13m 06s 027ms\n",
            "\u001b[32m2022-12-10T22:37:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, train/hateful_memes/cross_entropy: 0.5527, train/hateful_memes/cross_entropy/avg: 0.6305, train/total_loss: 0.5527, train/total_loss/avg: 0.6305, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 926ms, time_since_start: 24m 18s 714ms, eta: 01h 11m 58s 339ms\n",
            "\u001b[32m2022-12-10T22:37:11 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T22:37:11 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T22:37:21 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T22:37:21 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T22:37:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T22:37:32 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T22:37:44 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T22:37:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T22:37:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, val/hateful_memes/cross_entropy: 0.8581, val/total_loss: 0.8581, val/hateful_memes/accuracy: 0.6222, val/hateful_memes/binary_f1: 0.2766, val/hateful_memes/roc_auc: 0.6160, num_updates: 1500, epoch: 3, iterations: 1500, max_updates: 6000, val_time: 44s 481ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.615956\n",
            "\u001b[32m2022-12-10T22:38:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/6000, train/hateful_memes/cross_entropy: 0.5343, train/hateful_memes/cross_entropy/avg: 0.6235, train/total_loss: 0.5343, train/total_loss/avg: 0.6235, max mem: 7248.0, experiment: run, epoch: 3, num_updates: 1550, iterations: 1550, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 205ms, time_since_start: 25m 49s 403ms, eta: 01h 13m 11s 920ms\n",
            "\u001b[32m2022-12-10T22:39:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/6000, train/hateful_memes/cross_entropy: 0.5343, train/hateful_memes/cross_entropy/avg: 0.6295, train/total_loss: 0.5343, train/total_loss/avg: 0.6295, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1600, iterations: 1600, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 211ms, time_since_start: 26m 33s 615ms, eta: 01h 09m 15s 152ms\n",
            "\u001b[32m2022-12-10T22:40:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/6000, train/hateful_memes/cross_entropy: 0.5331, train/hateful_memes/cross_entropy/avg: 0.6209, train/total_loss: 0.5331, train/total_loss/avg: 0.6209, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1650, iterations: 1650, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 260ms, time_since_start: 27m 18s 875ms, eta: 01h 10m 05s 384ms\n",
            "\u001b[32m2022-12-10T22:40:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/6000, train/hateful_memes/cross_entropy: 0.5022, train/hateful_memes/cross_entropy/avg: 0.6154, train/total_loss: 0.5022, train/total_loss/avg: 0.6154, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1700, iterations: 1700, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 901ms, time_since_start: 28m 03s 776ms, eta: 01h 08m 44s 081ms\n",
            "\u001b[32m2022-12-10T22:41:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/6000, train/hateful_memes/cross_entropy: 0.4862, train/hateful_memes/cross_entropy/avg: 0.6079, train/total_loss: 0.4862, train/total_loss/avg: 0.6079, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 128ms, time_since_start: 28m 48s 904ms, eta: 01h 08m 16s 722ms\n",
            "\u001b[32m2022-12-10T22:42:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/6000, train/hateful_memes/cross_entropy: 0.5022, train/hateful_memes/cross_entropy/avg: 0.6153, train/total_loss: 0.5022, train/total_loss/avg: 0.6153, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 912ms, time_since_start: 29m 33s 817ms, eta: 01h 07m 09s 227ms\n",
            "\u001b[32m2022-12-10T22:43:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/6000, train/hateful_memes/cross_entropy: 0.5022, train/hateful_memes/cross_entropy/avg: 0.6175, train/total_loss: 0.5022, train/total_loss/avg: 0.6175, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 043ms, time_since_start: 30m 18s 860ms, eta: 01h 06m 32s 842ms\n",
            "\u001b[32m2022-12-10T22:43:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/6000, train/hateful_memes/cross_entropy: 0.5022, train/hateful_memes/cross_entropy/avg: 0.6176, train/total_loss: 0.5022, train/total_loss/avg: 0.6176, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 890ms, time_since_start: 31m 03s 751ms, eta: 01h 05m 31s 308ms\n",
            "\u001b[32m2022-12-10T22:44:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/6000, train/hateful_memes/cross_entropy: 0.4862, train/hateful_memes/cross_entropy/avg: 0.6110, train/total_loss: 0.4862, train/total_loss/avg: 0.6110, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 197ms, time_since_start: 31m 48s 948ms, eta: 01h 05m 09s 914ms\n",
            "\u001b[32m2022-12-10T22:45:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-10T22:45:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T22:45:37 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T22:45:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T22:45:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, train/hateful_memes/cross_entropy: 0.4648, train/hateful_memes/cross_entropy/avg: 0.6073, train/total_loss: 0.4648, train/total_loss/avg: 0.6073, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 6000, lr: 0.00001, ups: 0.74, time: 01m 08s 411ms, time_since_start: 32m 57s 359ms, eta: 01h 37m 25s 072ms\n",
            "\u001b[32m2022-12-10T22:45:49 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T22:45:49 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T22:46:00 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T22:46:00 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T22:46:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T22:46:11 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T22:46:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T22:46:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T22:46:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, val/hateful_memes/cross_entropy: 0.7515, val/total_loss: 0.7515, val/hateful_memes/accuracy: 0.6463, val/hateful_memes/binary_f1: 0.3779, val/hateful_memes/roc_auc: 0.6392, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 6000, val_time: 44s 725ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.639221\n",
            "\u001b[32m2022-12-10T22:47:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/6000, train/hateful_memes/cross_entropy: 0.4648, train/hateful_memes/cross_entropy/avg: 0.6148, train/total_loss: 0.4648, train/total_loss/avg: 0.6148, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 284ms, time_since_start: 34m 28s 371ms, eta: 01h 05m 05s 122ms\n",
            "\u001b[32m2022-12-10T22:48:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/6000, train/hateful_memes/cross_entropy: 0.4862, train/hateful_memes/cross_entropy/avg: 0.6124, train/total_loss: 0.4862, train/total_loss/avg: 0.6124, max mem: 7248.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 659ms, time_since_start: 35m 13s 030ms, eta: 01h 02m 327ms\n",
            "\u001b[32m2022-12-10T22:48:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/6000, train/hateful_memes/cross_entropy: 0.4862, train/hateful_memes/cross_entropy/avg: 0.6115, train/total_loss: 0.4862, train/total_loss/avg: 0.6115, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 784ms, time_since_start: 35m 57s 815ms, eta: 01h 01m 22s 938ms\n",
            "\u001b[32m2022-12-10T22:49:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/6000, train/hateful_memes/cross_entropy: 0.4648, train/hateful_memes/cross_entropy/avg: 0.6051, train/total_loss: 0.4648, train/total_loss/avg: 0.6051, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 952ms, time_since_start: 36m 42s 768ms, eta: 01h 48s 692ms\n",
            "\u001b[32m2022-12-10T22:50:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/6000, train/hateful_memes/cross_entropy: 0.4648, train/hateful_memes/cross_entropy/avg: 0.5998, train/total_loss: 0.4648, train/total_loss/avg: 0.5998, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 036ms, time_since_start: 37m 27s 804ms, eta: 01h 07s 426ms\n",
            "\u001b[32m2022-12-10T22:51:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/6000, train/hateful_memes/cross_entropy: 0.4332, train/hateful_memes/cross_entropy/avg: 0.5944, train/total_loss: 0.4332, train/total_loss/avg: 0.5944, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 991ms, time_since_start: 38m 12s 796ms, eta: 59m 15s 746ms\n",
            "\u001b[32m2022-12-10T22:51:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/6000, train/hateful_memes/cross_entropy: 0.4332, train/hateful_memes/cross_entropy/avg: 0.5881, train/total_loss: 0.4332, train/total_loss/avg: 0.5881, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 098ms, time_since_start: 38m 57s 894ms, eta: 58m 36s 044ms\n",
            "\u001b[32m2022-12-10T22:52:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/6000, train/hateful_memes/cross_entropy: 0.4332, train/hateful_memes/cross_entropy/avg: 0.5829, train/total_loss: 0.4332, train/total_loss/avg: 0.5829, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 930ms, time_since_start: 39m 42s 824ms, eta: 57m 34s 947ms\n",
            "\u001b[32m2022-12-10T22:53:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/6000, train/hateful_memes/cross_entropy: 0.4143, train/hateful_memes/cross_entropy/avg: 0.5744, train/total_loss: 0.4143, train/total_loss/avg: 0.5744, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 195ms, time_since_start: 40m 28s 019ms, eta: 57m 07s 065ms\n",
            "\u001b[32m2022-12-10T22:54:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, train/hateful_memes/cross_entropy: 0.4143, train/hateful_memes/cross_entropy/avg: 0.5746, train/total_loss: 0.4143, train/total_loss/avg: 0.5746, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 839ms, time_since_start: 41m 12s 859ms, eta: 55m 52s 226ms\n",
            "\u001b[32m2022-12-10T22:54:05 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T22:54:05 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T22:54:15 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T22:54:15 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T22:54:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T22:54:26 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T22:54:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T22:54:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T22:54:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, val/hateful_memes/cross_entropy: 0.7548, val/total_loss: 0.7548, val/hateful_memes/accuracy: 0.6481, val/hateful_memes/binary_f1: 0.4025, val/hateful_memes/roc_auc: 0.6473, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 6000, val_time: 44s 425ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.647324\n",
            "\u001b[32m2022-12-10T22:55:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/6000, train/hateful_memes/cross_entropy: 0.4332, train/hateful_memes/cross_entropy/avg: 0.5752, train/total_loss: 0.4332, train/total_loss/avg: 0.5752, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 140ms, time_since_start: 42m 43s 426ms, eta: 56m 40s 169ms\n",
            "\u001b[32m2022-12-10T22:56:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/6000, train/hateful_memes/cross_entropy: 0.3697, train/hateful_memes/cross_entropy/avg: 0.5712, train/total_loss: 0.3697, train/total_loss/avg: 0.5712, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 603ms, time_since_start: 43m 28s 030ms, eta: 53m 59s 319ms\n",
            "\u001b[32m2022-12-10T22:57:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/6000, train/hateful_memes/cross_entropy: 0.3697, train/hateful_memes/cross_entropy/avg: 0.5661, train/total_loss: 0.3697, train/total_loss/avg: 0.5661, max mem: 7248.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 162ms, time_since_start: 44m 13s 193ms, eta: 53m 51s 671ms\n",
            "\u001b[32m2022-12-10T22:57:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/6000, train/hateful_memes/cross_entropy: 0.3697, train/hateful_memes/cross_entropy/avg: 0.5637, train/total_loss: 0.3697, train/total_loss/avg: 0.5637, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 306ms, time_since_start: 44m 57s 499ms, eta: 52m 03s 087ms\n",
            "\u001b[32m2022-12-10T22:58:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/6000, train/hateful_memes/cross_entropy: 0.3697, train/hateful_memes/cross_entropy/avg: 0.5580, train/total_loss: 0.3697, train/total_loss/avg: 0.5580, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 038ms, time_since_start: 45m 42s 538ms, eta: 52m 06s 604ms\n",
            "\u001b[32m2022-12-10T22:59:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/6000, train/hateful_memes/cross_entropy: 0.3632, train/hateful_memes/cross_entropy/avg: 0.5499, train/total_loss: 0.3632, train/total_loss/avg: 0.5499, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 964ms, time_since_start: 46m 27s 503ms, eta: 51m 13s 402ms\n",
            "\u001b[32m2022-12-10T23:00:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/6000, train/hateful_memes/cross_entropy: 0.3632, train/hateful_memes/cross_entropy/avg: 0.5480, train/total_loss: 0.3632, train/total_loss/avg: 0.5480, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 966ms, time_since_start: 47m 12s 469ms, eta: 50m 25s 495ms\n",
            "\u001b[32m2022-12-10T23:00:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/6000, train/hateful_memes/cross_entropy: 0.3613, train/hateful_memes/cross_entropy/avg: 0.5432, train/total_loss: 0.3613, train/total_loss/avg: 0.5432, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 902ms, time_since_start: 47m 57s 371ms, eta: 49m 33s 233ms\n",
            "\u001b[32m2022-12-10T23:01:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/6000, train/hateful_memes/cross_entropy: 0.3542, train/hateful_memes/cross_entropy/avg: 0.5372, train/total_loss: 0.3542, train/total_loss/avg: 0.5372, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 109ms, time_since_start: 48m 42s 480ms, eta: 48m 58s 797ms\n",
            "\u001b[32m2022-12-10T23:02:20 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-10T23:02:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:02:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:02:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:02:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, train/hateful_memes/cross_entropy: 0.3406, train/hateful_memes/cross_entropy/avg: 0.5338, train/total_loss: 0.3406, train/total_loss/avg: 0.5338, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 6000, lr: 0.00001, ups: 0.75, time: 01m 07s 216ms, time_since_start: 49m 49s 697ms, eta: 01h 11m 47s 257ms\n",
            "\u001b[32m2022-12-10T23:02:42 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T23:02:42 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T23:02:53 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T23:02:53 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:02:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:03:05 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T23:03:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:03:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:03:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, val/hateful_memes/cross_entropy: 0.9033, val/total_loss: 0.9033, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.3599, val/hateful_memes/roc_auc: 0.6720, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 6000, val_time: 45s 293ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.671985\n",
            "\u001b[32m2022-12-10T23:04:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3050/6000, train/hateful_memes/cross_entropy: 0.3355, train/hateful_memes/cross_entropy/avg: 0.5296, train/total_loss: 0.3355, train/total_loss/avg: 0.5296, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 3050, iterations: 3050, max_updates: 6000, lr: 0.00001, ups: 1.09, time: 46s 289ms, time_since_start: 51m 21s 282ms, eta: 48m 36s 780ms\n",
            "\u001b[32m2022-12-10T23:04:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/6000, train/hateful_memes/cross_entropy: 0.3340, train/hateful_memes/cross_entropy/avg: 0.5245, train/total_loss: 0.3340, train/total_loss/avg: 0.5245, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 3100, iterations: 3100, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 610ms, time_since_start: 52m 05s 892ms, eta: 46m 03s 361ms\n",
            "\u001b[32m2022-12-10T23:05:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3150/6000, train/hateful_memes/cross_entropy: 0.3018, train/hateful_memes/cross_entropy/avg: 0.5181, train/total_loss: 0.3018, train/total_loss/avg: 0.5181, max mem: 7248.0, experiment: run, epoch: 6, num_updates: 3150, iterations: 3150, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 269ms, time_since_start: 52m 51s 162ms, eta: 45m 55s 832ms\n",
            "\u001b[32m2022-12-10T23:06:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/6000, train/hateful_memes/cross_entropy: 0.2956, train/hateful_memes/cross_entropy/avg: 0.5131, train/total_loss: 0.2956, train/total_loss/avg: 0.5131, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3200, iterations: 3200, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 268ms, time_since_start: 53m 35s 430ms, eta: 44m 07s 589ms\n",
            "\u001b[32m2022-12-10T23:07:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3250/6000, train/hateful_memes/cross_entropy: 0.2776, train/hateful_memes/cross_entropy/avg: 0.5056, train/total_loss: 0.2776, train/total_loss/avg: 0.5056, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3250, iterations: 3250, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 886ms, time_since_start: 54m 20s 317ms, eta: 43m 56s 656ms\n",
            "\u001b[32m2022-12-10T23:07:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/6000, train/hateful_memes/cross_entropy: 0.2676, train/hateful_memes/cross_entropy/avg: 0.4997, train/total_loss: 0.2676, train/total_loss/avg: 0.4997, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3300, iterations: 3300, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 756ms, time_since_start: 55m 05s 074ms, eta: 43m 01s 211ms\n",
            "\u001b[32m2022-12-10T23:08:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3350/6000, train/hateful_memes/cross_entropy: 0.2526, train/hateful_memes/cross_entropy/avg: 0.4939, train/total_loss: 0.2526, train/total_loss/avg: 0.4939, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3350, iterations: 3350, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 766ms, time_since_start: 55m 49s 840ms, eta: 42m 13s 943ms\n",
            "\u001b[32m2022-12-10T23:09:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/6000, train/hateful_memes/cross_entropy: 0.2155, train/hateful_memes/cross_entropy/avg: 0.4879, train/total_loss: 0.2155, train/total_loss/avg: 0.4879, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3400, iterations: 3400, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 643ms, time_since_start: 56m 34s 484ms, eta: 41m 19s 330ms\n",
            "\u001b[32m2022-12-10T23:10:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3450/6000, train/hateful_memes/cross_entropy: 0.2526, train/hateful_memes/cross_entropy/avg: 0.4873, train/total_loss: 0.2526, train/total_loss/avg: 0.4873, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3450, iterations: 3450, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 738ms, time_since_start: 57m 19s 222ms, eta: 40m 36s 831ms\n",
            "\u001b[32m2022-12-10T23:10:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, train/hateful_memes/cross_entropy: 0.2155, train/hateful_memes/cross_entropy/avg: 0.4822, train/total_loss: 0.2155, train/total_loss/avg: 0.4822, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3500, iterations: 3500, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 750ms, time_since_start: 58m 03s 973ms, eta: 39m 49s 681ms\n",
            "\u001b[32m2022-12-10T23:10:56 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T23:10:56 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T23:11:07 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T23:11:07 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:11:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:11:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:11:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:11:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, val/hateful_memes/cross_entropy: 1.2358, val/total_loss: 1.2358, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.3223, val/hateful_memes/roc_auc: 0.6615, num_updates: 3500, epoch: 7, iterations: 3500, max_updates: 6000, val_time: 32s 958ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.671985\n",
            "\u001b[32m2022-12-10T23:12:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3550/6000, train/hateful_memes/cross_entropy: 0.1963, train/hateful_memes/cross_entropy/avg: 0.4758, train/total_loss: 0.1963, train/total_loss/avg: 0.4758, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3550, iterations: 3550, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 801ms, time_since_start: 59m 22s 734ms, eta: 39m 56s 896ms\n",
            "\u001b[32m2022-12-10T23:12:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/6000, train/hateful_memes/cross_entropy: 0.1963, train/hateful_memes/cross_entropy/avg: 0.4747, train/total_loss: 0.1963, train/total_loss/avg: 0.4747, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3600, iterations: 3600, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 487ms, time_since_start: 01h 07s 222ms, eta: 38m 590ms\n",
            "\u001b[32m2022-12-10T23:13:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3650/6000, train/hateful_memes/cross_entropy: 0.1864, train/hateful_memes/cross_entropy/avg: 0.4700, train/total_loss: 0.1864, train/total_loss/avg: 0.4700, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3650, iterations: 3650, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 813ms, time_since_start: 01h 52s 035ms, eta: 37m 29s 478ms\n",
            "\u001b[32m2022-12-10T23:14:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/6000, train/hateful_memes/cross_entropy: 0.1311, train/hateful_memes/cross_entropy/avg: 0.4644, train/total_loss: 0.1311, train/total_loss/avg: 0.4644, max mem: 7248.0, experiment: run, epoch: 7, num_updates: 3700, iterations: 3700, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 700ms, time_since_start: 01h 01m 36s 736ms, eta: 36m 36s 055ms\n",
            "\u001b[32m2022-12-10T23:15:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3750/6000, train/hateful_memes/cross_entropy: 0.1302, train/hateful_memes/cross_entropy/avg: 0.4584, train/total_loss: 0.1302, train/total_loss/avg: 0.4584, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 3750, iterations: 3750, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 311ms, time_since_start: 01h 02m 21s 048ms, eta: 35m 29s 617ms\n",
            "\u001b[32m2022-12-10T23:15:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/6000, train/hateful_memes/cross_entropy: 0.1302, train/hateful_memes/cross_entropy/avg: 0.4529, train/total_loss: 0.1302, train/total_loss/avg: 0.4529, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 3800, iterations: 3800, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 717ms, time_since_start: 01h 03m 05s 766ms, eta: 35m 01s 386ms\n",
            "\u001b[32m2022-12-10T23:16:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3850/6000, train/hateful_memes/cross_entropy: 0.1207, train/hateful_memes/cross_entropy/avg: 0.4475, train/total_loss: 0.1207, train/total_loss/avg: 0.4475, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 3850, iterations: 3850, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 930ms, time_since_start: 01h 03m 50s 697ms, eta: 34m 23s 403ms\n",
            "\u001b[32m2022-12-10T23:17:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/6000, train/hateful_memes/cross_entropy: 0.1207, train/hateful_memes/cross_entropy/avg: 0.4434, train/total_loss: 0.1207, train/total_loss/avg: 0.4434, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 3900, iterations: 3900, max_updates: 6000, lr: 0.00001, ups: 1.14, time: 44s 887ms, time_since_start: 01h 04m 35s 585ms, eta: 33m 33s 492ms\n",
            "\u001b[32m2022-12-10T23:18:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3950/6000, train/hateful_memes/cross_entropy: 0.1177, train/hateful_memes/cross_entropy/avg: 0.4383, train/total_loss: 0.1177, train/total_loss/avg: 0.4383, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 3950, iterations: 3950, max_updates: 6000, lr: 0.00001, ups: 1.11, time: 45s 056ms, time_since_start: 01h 05m 20s 641ms, eta: 32m 52s 949ms\n",
            "\u001b[32m2022-12-10T23:18:58 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-10T23:18:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:19:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:19:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:19:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, train/hateful_memes/cross_entropy: 0.1177, train/hateful_memes/cross_entropy/avg: 0.4375, train/total_loss: 0.1177, train/total_loss/avg: 0.4375, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 4000, iterations: 4000, max_updates: 6000, lr: 0.00001, ups: 0.75, time: 01m 07s 406ms, time_since_start: 01h 06m 28s 048ms, eta: 47m 59s 606ms\n",
            "\u001b[32m2022-12-10T23:19:20 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T23:19:20 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T23:19:31 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T23:19:31 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:19:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:19:42 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T23:19:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:20:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:20:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, val/hateful_memes/cross_entropy: 1.3176, val/total_loss: 1.3176, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.3973, val/hateful_memes/roc_auc: 0.6756, num_updates: 4000, epoch: 8, iterations: 4000, max_updates: 6000, val_time: 45s 301ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.675629\n",
            "\u001b[32m2022-12-10T23:20:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4050/6000, train/hateful_memes/cross_entropy: 0.1118, train/hateful_memes/cross_entropy/avg: 0.4329, train/total_loss: 0.1118, train/total_loss/avg: 0.4329, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 4050, iterations: 4050, max_updates: 6000, lr: 0., ups: 1.09, time: 46s 319ms, time_since_start: 01h 07m 59s 671ms, eta: 32m 09s 319ms\n",
            "\u001b[32m2022-12-10T23:21:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/6000, train/hateful_memes/cross_entropy: 0.1118, train/hateful_memes/cross_entropy/avg: 0.4307, train/total_loss: 0.1118, train/total_loss/avg: 0.4307, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 4100, iterations: 4100, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 510ms, time_since_start: 01h 08m 44s 182ms, eta: 30m 06s 434ms\n",
            "\u001b[32m2022-12-10T23:22:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4150/6000, train/hateful_memes/cross_entropy: 0.0812, train/hateful_memes/cross_entropy/avg: 0.4256, train/total_loss: 0.0812, train/total_loss/avg: 0.4256, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 4150, iterations: 4150, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 137ms, time_since_start: 01h 09m 29s 320ms, eta: 29m 43s 657ms\n",
            "\u001b[32m2022-12-10T23:23:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/6000, train/hateful_memes/cross_entropy: 0.0812, train/hateful_memes/cross_entropy/avg: 0.4249, train/total_loss: 0.0812, train/total_loss/avg: 0.4249, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 4200, iterations: 4200, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 864ms, time_since_start: 01h 10m 14s 184ms, eta: 28m 44s 963ms\n",
            "\u001b[32m2022-12-10T23:23:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4250/6000, train/hateful_memes/cross_entropy: 0.1118, train/hateful_memes/cross_entropy/avg: 0.4236, train/total_loss: 0.1118, train/total_loss/avg: 0.4236, max mem: 7248.0, experiment: run, epoch: 8, num_updates: 4250, iterations: 4250, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 994ms, time_since_start: 01h 10m 59s 179ms, eta: 28m 01s 887ms\n",
            "\u001b[32m2022-12-10T23:24:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/6000, train/hateful_memes/cross_entropy: 0.0812, train/hateful_memes/cross_entropy/avg: 0.4190, train/total_loss: 0.0812, train/total_loss/avg: 0.4190, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4300, iterations: 4300, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 171ms, time_since_start: 01h 11m 43s 350ms, eta: 26m 43s 941ms\n",
            "\u001b[32m2022-12-10T23:25:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4350/6000, train/hateful_memes/cross_entropy: 0.0787, train/hateful_memes/cross_entropy/avg: 0.4150, train/total_loss: 0.0787, train/total_loss/avg: 0.4150, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4350, iterations: 4350, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 756ms, time_since_start: 01h 12m 28s 107ms, eta: 26m 17s 409ms\n",
            "\u001b[32m2022-12-10T23:26:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/6000, train/hateful_memes/cross_entropy: 0.0692, train/hateful_memes/cross_entropy/avg: 0.4111, train/total_loss: 0.0692, train/total_loss/avg: 0.4111, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4400, iterations: 4400, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 667ms, time_since_start: 01h 13m 12s 774ms, eta: 25m 26s 554ms\n",
            "\u001b[32m2022-12-10T23:26:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4450/6000, train/hateful_memes/cross_entropy: 0.0628, train/hateful_memes/cross_entropy/avg: 0.4066, train/total_loss: 0.0628, train/total_loss/avg: 0.4066, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4450, iterations: 4450, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 729ms, time_since_start: 01h 13m 57s 504ms, eta: 24m 40s 920ms\n",
            "\u001b[32m2022-12-10T23:27:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, train/hateful_memes/cross_entropy: 0.0570, train/hateful_memes/cross_entropy/avg: 0.4023, train/total_loss: 0.0570, train/total_loss/avg: 0.4023, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4500, iterations: 4500, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 615ms, time_since_start: 01h 14m 42s 120ms, eta: 23m 49s 489ms\n",
            "\u001b[32m2022-12-10T23:27:34 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T23:27:34 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T23:27:45 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T23:27:45 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:27:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:27:55 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T23:28:07 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:28:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:28:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, val/hateful_memes/cross_entropy: 1.3112, val/total_loss: 1.3112, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4685, val/hateful_memes/roc_auc: 0.6817, num_updates: 4500, epoch: 9, iterations: 4500, max_updates: 6000, val_time: 44s 991ms, best_update: 4500, best_iteration: 4500, best_val/hateful_memes/roc_auc: 0.681721\n",
            "\u001b[32m2022-12-10T23:29:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4550/6000, train/hateful_memes/cross_entropy: 0.0570, train/hateful_memes/cross_entropy/avg: 0.3980, train/total_loss: 0.0570, train/total_loss/avg: 0.3980, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4550, iterations: 4550, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 766ms, time_since_start: 01h 16m 12s 879ms, eta: 23m 37s 476ms\n",
            "\u001b[32m2022-12-10T23:29:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/6000, train/hateful_memes/cross_entropy: 0.0482, train/hateful_memes/cross_entropy/avg: 0.3938, train/total_loss: 0.0482, train/total_loss/avg: 0.3938, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4600, iterations: 4600, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 552ms, time_since_start: 01h 16m 57s 432ms, eta: 22m 12s 295ms\n",
            "\u001b[32m2022-12-10T23:30:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4650/6000, train/hateful_memes/cross_entropy: 0.0482, train/hateful_memes/cross_entropy/avg: 0.3903, train/total_loss: 0.0482, train/total_loss/avg: 0.3903, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4650, iterations: 4650, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 840ms, time_since_start: 01h 17m 42s 272ms, eta: 21m 33s 023ms\n",
            "\u001b[32m2022-12-10T23:31:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/6000, train/hateful_memes/cross_entropy: 0.0426, train/hateful_memes/cross_entropy/avg: 0.3866, train/total_loss: 0.0426, train/total_loss/avg: 0.3866, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4700, iterations: 4700, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 632ms, time_since_start: 01h 18m 26s 904ms, eta: 20m 39s 342ms\n",
            "\u001b[32m2022-12-10T23:32:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4750/6000, train/hateful_memes/cross_entropy: 0.0426, train/hateful_memes/cross_entropy/avg: 0.3826, train/total_loss: 0.0426, train/total_loss/avg: 0.3826, max mem: 7248.0, experiment: run, epoch: 9, num_updates: 4750, iterations: 4750, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 718ms, time_since_start: 01h 19m 11s 623ms, eta: 19m 53s 987ms\n",
            "\u001b[32m2022-12-10T23:32:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/6000, train/hateful_memes/cross_entropy: 0.0426, train/hateful_memes/cross_entropy/avg: 0.3789, train/total_loss: 0.0426, train/total_loss/avg: 0.3789, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 4800, iterations: 4800, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 219ms, time_since_start: 01h 19m 55s 842ms, eta: 18m 53s 433ms\n",
            "\u001b[32m2022-12-10T23:33:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4850/6000, train/hateful_memes/cross_entropy: 0.0426, train/hateful_memes/cross_entropy/avg: 0.3753, train/total_loss: 0.0426, train/total_loss/avg: 0.3753, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 4850, iterations: 4850, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 858ms, time_since_start: 01h 20m 40s 701ms, eta: 18m 21s 903ms\n",
            "\u001b[32m2022-12-10T23:34:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/6000, train/hateful_memes/cross_entropy: 0.0326, train/hateful_memes/cross_entropy/avg: 0.3715, train/total_loss: 0.0326, train/total_loss/avg: 0.3715, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 4900, iterations: 4900, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 677ms, time_since_start: 01h 21m 25s 378ms, eta: 17m 29s 741ms\n",
            "\u001b[32m2022-12-10T23:35:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4950/6000, train/hateful_memes/cross_entropy: 0.0272, train/hateful_memes/cross_entropy/avg: 0.3680, train/total_loss: 0.0272, train/total_loss/avg: 0.3680, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 4950, iterations: 4950, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 852ms, time_since_start: 01h 22m 10s 231ms, eta: 16m 45s 957ms\n",
            "\u001b[32m2022-12-10T23:35:47 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-10T23:35:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:35:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:36:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:36:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, train/hateful_memes/cross_entropy: 0.0260, train/hateful_memes/cross_entropy/avg: 0.3643, train/total_loss: 0.0260, train/total_loss/avg: 0.3643, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 5000, iterations: 5000, max_updates: 6000, lr: 0., ups: 0.76, time: 01m 06s 905ms, time_since_start: 01h 23m 17s 137ms, eta: 23m 49s 111ms\n",
            "\u001b[32m2022-12-10T23:36:09 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T23:36:09 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T23:36:20 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T23:36:20 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:36:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:36:31 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-10T23:36:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:36:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:36:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, val/hateful_memes/cross_entropy: 1.5714, val/total_loss: 1.5714, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4395, val/hateful_memes/roc_auc: 0.6833, num_updates: 5000, epoch: 10, iterations: 5000, max_updates: 6000, val_time: 44s 866ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.683290\n",
            "\u001b[32m2022-12-10T23:37:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5050/6000, train/hateful_memes/cross_entropy: 0.0260, train/hateful_memes/cross_entropy/avg: 0.3619, train/total_loss: 0.0260, train/total_loss/avg: 0.3619, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 5050, iterations: 5050, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 999ms, time_since_start: 01h 24m 48s 004ms, eta: 15m 33s 413ms\n",
            "\u001b[32m2022-12-10T23:38:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/6000, train/hateful_memes/cross_entropy: 0.0260, train/hateful_memes/cross_entropy/avg: 0.3586, train/total_loss: 0.0260, train/total_loss/avg: 0.3586, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 5100, iterations: 5100, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 413ms, time_since_start: 01h 25m 32s 417ms, eta: 14m 13s 806ms\n",
            "\u001b[32m2022-12-10T23:39:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5150/6000, train/hateful_memes/cross_entropy: 0.0260, train/hateful_memes/cross_entropy/avg: 0.3553, train/total_loss: 0.0260, train/total_loss/avg: 0.3553, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 5150, iterations: 5150, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 872ms, time_since_start: 01h 26m 17s 290ms, eta: 13m 34s 712ms\n",
            "\u001b[32m2022-12-10T23:39:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/6000, train/hateful_memes/cross_entropy: 0.0260, train/hateful_memes/cross_entropy/avg: 0.3522, train/total_loss: 0.0260, train/total_loss/avg: 0.3522, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 5200, iterations: 5200, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 649ms, time_since_start: 01h 27m 01s 940ms, eta: 12m 42s 968ms\n",
            "\u001b[32m2022-12-10T23:40:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5250/6000, train/hateful_memes/cross_entropy: 0.0190, train/hateful_memes/cross_entropy/avg: 0.3489, train/total_loss: 0.0190, train/total_loss/avg: 0.3489, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 5250, iterations: 5250, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 682ms, time_since_start: 01h 27m 46s 622ms, eta: 11m 55s 807ms\n",
            "\u001b[32m2022-12-10T23:41:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/6000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.3458, train/total_loss: 0.0179, train/total_loss/avg: 0.3458, max mem: 7248.0, experiment: run, epoch: 10, num_updates: 5300, iterations: 5300, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 719ms, time_since_start: 01h 28m 31s 341ms, eta: 11m 08s 641ms\n",
            "\u001b[32m2022-12-10T23:42:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5350/6000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.3437, train/total_loss: 0.0179, train/total_loss/avg: 0.3437, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5350, iterations: 5350, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 133ms, time_since_start: 01h 29m 15s 474ms, eta: 10m 12s 746ms\n",
            "\u001b[32m2022-12-10T23:42:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/6000, train/hateful_memes/cross_entropy: 0.0158, train/hateful_memes/cross_entropy/avg: 0.3407, train/total_loss: 0.0158, train/total_loss/avg: 0.3407, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5400, iterations: 5400, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 598ms, time_since_start: 01h 30m 073ms, eta: 09m 31s 572ms\n",
            "\u001b[32m2022-12-10T23:43:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5450/6000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.3377, train/total_loss: 0.0179, train/total_loss/avg: 0.3377, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5450, iterations: 5450, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 874ms, time_since_start: 01h 30m 44s 948ms, eta: 08m 47s 190ms\n",
            "\u001b[32m2022-12-10T23:44:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, train/hateful_memes/cross_entropy: 0.0158, train/hateful_memes/cross_entropy/avg: 0.3347, train/total_loss: 0.0158, train/total_loss/avg: 0.3347, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5500, iterations: 5500, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 688ms, time_since_start: 01h 31m 29s 636ms, eta: 07m 57s 273ms\n",
            "\u001b[32m2022-12-10T23:44:22 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T23:44:22 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T23:44:32 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T23:44:32 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:44:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:44:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:44:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:44:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, val/hateful_memes/cross_entropy: 1.6705, val/total_loss: 1.6705, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4395, val/hateful_memes/roc_auc: 0.6829, num_updates: 5500, epoch: 11, iterations: 5500, max_updates: 6000, val_time: 32s 998ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.683290\n",
            "\u001b[32m2022-12-10T23:45:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5550/6000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.3321, train/total_loss: 0.0179, train/total_loss/avg: 0.3321, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5550, iterations: 5550, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 732ms, time_since_start: 01h 32m 48s 368ms, eta: 07m 19s 578ms\n",
            "\u001b[32m2022-12-10T23:46:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/6000, train/hateful_memes/cross_entropy: 0.0186, train/hateful_memes/cross_entropy/avg: 0.3297, train/total_loss: 0.0186, train/total_loss/avg: 0.3297, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5600, iterations: 5600, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 559ms, time_since_start: 01h 33m 32s 927ms, eta: 06m 20s 712ms\n",
            "\u001b[32m2022-12-10T23:47:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5650/6000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.3269, train/total_loss: 0.0179, train/total_loss/avg: 0.3269, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5650, iterations: 5650, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 838ms, time_since_start: 01h 34m 17s 766ms, eta: 05m 35s 212ms\n",
            "\u001b[32m2022-12-10T23:47:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/6000, train/hateful_memes/cross_entropy: 0.0158, train/hateful_memes/cross_entropy/avg: 0.3241, train/total_loss: 0.0158, train/total_loss/avg: 0.3241, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5700, iterations: 5700, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 832ms, time_since_start: 01h 35m 02s 598ms, eta: 04m 47s 287ms\n",
            "\u001b[32m2022-12-10T23:48:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5750/6000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.3222, train/total_loss: 0.0179, train/total_loss/avg: 0.3222, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5750, iterations: 5750, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 743ms, time_since_start: 01h 35m 47s 342ms, eta: 03m 58s 932ms\n",
            "\u001b[32m2022-12-10T23:49:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/6000, train/hateful_memes/cross_entropy: 0.0158, train/hateful_memes/cross_entropy/avg: 0.3195, train/total_loss: 0.0158, train/total_loss/avg: 0.3195, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5800, iterations: 5800, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 808ms, time_since_start: 01h 36m 32s 151ms, eta: 03m 11s 423ms\n",
            "\u001b[32m2022-12-10T23:50:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5850/6000, train/hateful_memes/cross_entropy: 0.0158, train/hateful_memes/cross_entropy/avg: 0.3173, train/total_loss: 0.0158, train/total_loss/avg: 0.3173, max mem: 7248.0, experiment: run, epoch: 11, num_updates: 5850, iterations: 5850, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 627ms, time_since_start: 01h 37m 16s 779ms, eta: 02m 22s 986ms\n",
            "\u001b[32m2022-12-10T23:50:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/6000, train/hateful_memes/cross_entropy: 0.0158, train/hateful_memes/cross_entropy/avg: 0.3147, train/total_loss: 0.0158, train/total_loss/avg: 0.3147, max mem: 7248.0, experiment: run, epoch: 12, num_updates: 5900, iterations: 5900, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 306ms, time_since_start: 01h 38m 01s 085ms, eta: 01m 34s 637ms\n",
            "\u001b[32m2022-12-10T23:51:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5950/6000, train/hateful_memes/cross_entropy: 0.0147, train/hateful_memes/cross_entropy/avg: 0.3121, train/total_loss: 0.0147, train/total_loss/avg: 0.3121, max mem: 7248.0, experiment: run, epoch: 12, num_updates: 5950, iterations: 5950, max_updates: 6000, lr: 0., ups: 1.14, time: 44s 916ms, time_since_start: 01h 38m 46s 001ms, eta: 47s 970ms\n",
            "\u001b[32m2022-12-10T23:52:23 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-10T23:52:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:52:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:52:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:52:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, train/hateful_memes/cross_entropy: 0.0158, train/hateful_memes/cross_entropy/avg: 0.3097, train/total_loss: 0.0158, train/total_loss/avg: 0.3097, max mem: 7248.0, experiment: run, epoch: 12, num_updates: 6000, iterations: 6000, max_updates: 6000, lr: 0., ups: 0.76, time: 01m 06s 986ms, time_since_start: 01h 39m 52s 988ms, eta: 0ms\n",
            "\u001b[32m2022-12-10T23:52:45 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-10T23:52:45 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-10T23:52:56 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-10T23:52:56 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:52:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-10T23:53:07 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-10T23:53:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-10T23:53:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, val/hateful_memes/cross_entropy: 1.7196, val/total_loss: 1.7196, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.4331, val/hateful_memes/roc_auc: 0.6827, num_updates: 6000, epoch: 12, iterations: 6000, max_updates: 6000, val_time: 34s 395ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.683290\n",
            "\u001b[32m2022-12-10T23:53:20 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2022-12-10T23:53:20 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2022-12-10T23:53:20 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2022-12-10T23:53:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-12-10T23:53:33 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 5000\n",
            "\u001b[32m2022-12-10T23:53:33 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 5000\n",
            "\u001b[32m2022-12-10T23:53:33 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 10\n",
            "\u001b[32m2022-12-10T23:53:36 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-12-10T23:53:36 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 125/125 [00:38<00:00,  3.21it/s]\n",
            "\u001b[32m2022-12-10T23:54:15 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 125\n",
            "\u001b[32m2022-12-10T23:54:15 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-10T23:54:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, test/hateful_memes/cross_entropy: 1.5319, test/total_loss: 1.5319, test/hateful_memes/accuracy: 0.6960, test/hateful_memes/binary_f1: 0.4667, test/hateful_memes/roc_auc: 0.7224\n",
            "\u001b[32m2022-12-10T23:54:15 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 01h 41m 23s 045ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/visual_bert/defaults.yaml \\\n",
        "  model=visual_bert \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=6000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100 \\\n",
        "  env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEW5Lo5rGaJu",
        "outputId": "3bad0647-9cef-4188-8663-2024e5ae87ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "\u001b[32m2022-12-11T02:58:37 | mmf: \u001b[0mLogging to: /drive/MyDrive/final_project/mmf/projects/hateful_memes/save/train.log\n",
            "\u001b[32m2022-12-11T02:58:37 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/visual_bert/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=6000', 'training.batch_size=16', 'training.evaluation_interval=500', 'trainer.params.gpus=100', 'env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save'])\n",
            "\u001b[32m2022-12-11T02:58:37 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n",
            "\u001b[32m2022-12-11T02:58:37 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla T4\n",
            "\u001b[32m2022-12-11T02:58:37 | mmf_cli.run: \u001b[0mUsing seed 37878704\n",
            "\u001b[32m2022-12-11T02:58:37 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n",
            "Downloading features.tar.gz: 100% 10.3G/10.3G [08:45<00:00, 19.6MB/s]\n",
            "[ Starting checksum for features.tar.gz]\n",
            "[ Checksum successful for features.tar.gz]\n",
            "Unpacking features.tar.gz\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:01<00:00, 146kB/s] \n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmphx3yxz\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 25.1kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpp8441y4w\n",
            "Downloading: 100% 570/570 [00:00<00:00, 449kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpic591jzp\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 316kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpa9pdqov7\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 506kB/s] \n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "\u001b[32m2022-12-11T03:10:27 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-11T03:10:28 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-11T03:10:28 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-11T03:10:28 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bert_model_name\": \"bert-base-uncased\",\n",
            "  \"bypass_transformer\": false,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_strategy\": \"plain\",\n",
            "  \"finetune_lr_multiplier\": 1,\n",
            "  \"freeze_base\": false,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"losses\": [\n",
            "    \"cross_entropy\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model\": \"visual_bert\",\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_strategy\": \"default\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"random_initialize\": false,\n",
            "  \"special_visual_initialize\": true,\n",
            "  \"training_head_type\": \"classification\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"visual_embedding_dim\": 2048,\n",
            "  \"vocab_size\": 30522,\n",
            "  \"zerobias\": false\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/mmf/distributed_-1/tmp2kwm1348\n",
            "Downloading: 100% 440M/440M [00:04<00:00, 105MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "creating metadata file for /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing VisualBERTBase: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing VisualBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing VisualBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias', 'bert.embeddings.token_type_embeddings_visual.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2022-12-11T03:10:43 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-12-11T03:10:43 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-12-11T03:10:43 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-12-11T03:10:43 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-12-11T03:10:43 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2022-12-11T03:10:43 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2022-12-11T03:11:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/6000, train/hateful_memes/cross_entropy: 0.6508, train/hateful_memes/cross_entropy/avg: 0.6508, train/total_loss: 0.6508, train/total_loss/avg: 0.6508, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 6000, lr: 0., ups: 1.52, time: 33s 943ms, time_since_start: 34s 010ms, eta: 01h 11m 53s 960ms\n",
            "\u001b[32m2022-12-11T03:11:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/6000, train/hateful_memes/cross_entropy: 0.6508, train/hateful_memes/cross_entropy/avg: 0.6793, train/total_loss: 0.6508, train/total_loss/avg: 0.6793, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 6000, lr: 0., ups: 1.47, time: 34s 170ms, time_since_start: 01m 08s 181ms, eta: 01h 11m 46s 269ms\n",
            "\u001b[32m2022-12-11T03:12:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/6000, train/hateful_memes/cross_entropy: 0.6946, train/hateful_memes/cross_entropy/avg: 0.6844, train/total_loss: 0.6946, train/total_loss/avg: 0.6844, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 6000, lr: 0., ups: 1.43, time: 35s 799ms, time_since_start: 01m 43s 981ms, eta: 01h 14m 33s 415ms\n",
            "\u001b[32m2022-12-11T03:13:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/6000, train/hateful_memes/cross_entropy: 0.6946, train/hateful_memes/cross_entropy/avg: 0.6886, train/total_loss: 0.6946, train/total_loss/avg: 0.6886, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 333ms, time_since_start: 02m 20s 314ms, eta: 01h 15m 01s 308ms\n",
            "\u001b[32m2022-12-11T03:13:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/6000, train/hateful_memes/cross_entropy: 0.6946, train/hateful_memes/cross_entropy/avg: 0.6730, train/total_loss: 0.6946, train/total_loss/avg: 0.6730, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 617ms, time_since_start: 02m 55s 932ms, eta: 01h 12m 54s 530ms\n",
            "\u001b[32m2022-12-11T03:14:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6728, train/total_loss: 0.6717, train/total_loss/avg: 0.6728, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 968ms, time_since_start: 03m 31s 900ms, eta: 01h 12m 59s 207ms\n",
            "\u001b[32m2022-12-11T03:14:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/6000, train/hateful_memes/cross_entropy: 0.6946, train/hateful_memes/cross_entropy/avg: 0.6874, train/total_loss: 0.6946, train/total_loss/avg: 0.6874, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 659ms, time_since_start: 04m 07s 559ms, eta: 01h 11m 43s 488ms\n",
            "\u001b[32m2022-12-11T03:15:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/6000, train/hateful_memes/cross_entropy: 0.6876, train/hateful_memes/cross_entropy/avg: 0.6874, train/total_loss: 0.6876, train/total_loss/avg: 0.6874, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 783ms, time_since_start: 04m 43s 343ms, eta: 01h 11m 20s 293ms\n",
            "\u001b[32m2022-12-11T03:16:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/6000, train/hateful_memes/cross_entropy: 0.6876, train/hateful_memes/cross_entropy/avg: 0.6833, train/total_loss: 0.6876, train/total_loss/avg: 0.6833, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 790ms, time_since_start: 05m 19s 133ms, eta: 01h 10m 42s 892ms\n",
            "\u001b[32m2022-12-11T03:16:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6657, train/total_loss: 0.6717, train/total_loss/avg: 0.6657, max mem: 5481.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 646ms, time_since_start: 05m 54s 780ms, eta: 01h 09m 47s 810ms\n",
            "\u001b[32m2022-12-11T03:16:37 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T03:16:37 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T03:16:46 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T03:16:46 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T03:16:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:16:51 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-11T03:16:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:17:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:17:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, val/hateful_memes/cross_entropy: 0.6787, val/total_loss: 0.6787, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.0100, val/hateful_memes/roc_auc: 0.5224, num_updates: 500, epoch: 1, iterations: 500, max_updates: 6000, val_time: 24s 869ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.522368\n",
            "\u001b[32m2022-12-11T03:17:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/6000, train/hateful_memes/cross_entropy: 0.6876, train/hateful_memes/cross_entropy/avg: 0.6756, train/total_loss: 0.6876, train/total_loss/avg: 0.6756, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 554ms, time_since_start: 06m 56s 212ms, eta: 01h 10m 55s 409ms\n",
            "\u001b[32m2022-12-11T03:18:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/6000, train/hateful_memes/cross_entropy: 0.6876, train/hateful_memes/cross_entropy/avg: 0.7068, train/total_loss: 0.6876, train/total_loss/avg: 0.7068, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 198ms, time_since_start: 07m 32s 411ms, eta: 01h 09m 35s 298ms\n",
            "\u001b[32m2022-12-11T03:18:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/6000, train/hateful_memes/cross_entropy: 0.6876, train/hateful_memes/cross_entropy/avg: 0.7033, train/total_loss: 0.6876, train/total_loss/avg: 0.7033, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 016ms, time_since_start: 08m 08s 427ms, eta: 01h 08m 35s 849ms\n",
            "\u001b[32m2022-12-11T03:19:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6982, train/total_loss: 0.6717, train/total_loss/avg: 0.6982, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 362ms, time_since_start: 08m 44s 790ms, eta: 01h 08m 36s 582ms\n",
            "\u001b[32m2022-12-11T03:20:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6958, train/total_loss: 0.6717, train/total_loss/avg: 0.6958, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 022ms, time_since_start: 09m 20s 813ms, eta: 01h 07m 19s 512ms\n",
            "\u001b[32m2022-12-11T03:20:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/6000, train/hateful_memes/cross_entropy: 0.6628, train/hateful_memes/cross_entropy/avg: 0.6918, train/total_loss: 0.6628, train/total_loss/avg: 0.6918, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 087ms, time_since_start: 09m 56s 900ms, eta: 01h 06m 48s 314ms\n",
            "\u001b[32m2022-12-11T03:21:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6919, train/total_loss: 0.6717, train/total_loss/avg: 0.6919, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 181ms, time_since_start: 10m 33s 082ms, eta: 01h 06m 20s 142ms\n",
            "\u001b[32m2022-12-11T03:21:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6995, train/total_loss: 0.6717, train/total_loss/avg: 0.6995, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 900, iterations: 900, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 086ms, time_since_start: 11m 09s 168ms, eta: 01h 05m 31s 099ms\n",
            "\u001b[32m2022-12-11T03:22:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6963, train/total_loss: 0.6717, train/total_loss/avg: 0.6963, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 950, iterations: 950, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 048ms, time_since_start: 11m 45s 217ms, eta: 01h 04m 48s 510ms\n",
            "\u001b[32m2022-12-11T03:23:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-11T03:23:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:23:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:23:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:23:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, train/hateful_memes/cross_entropy: 0.6628, train/hateful_memes/cross_entropy/avg: 0.6911, train/total_loss: 0.6628, train/total_loss/avg: 0.6911, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 1000, iterations: 1000, max_updates: 6000, lr: 0.00003, ups: 1.11, time: 45s 948ms, time_since_start: 12m 31s 166ms, eta: 01h 21m 47s 333ms\n",
            "\u001b[32m2022-12-11T03:23:14 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T03:23:14 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T03:23:24 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T03:23:24 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T03:23:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:23:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:23:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:23:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, val/hateful_memes/cross_entropy: 0.6612, val/total_loss: 0.6612, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.4939, num_updates: 1000, epoch: 2, iterations: 1000, max_updates: 6000, val_time: 20s 088ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.522368\n",
            "\u001b[32m2022-12-11T03:24:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/6000, train/hateful_memes/cross_entropy: 0.6717, train/hateful_memes/cross_entropy/avg: 0.6965, train/total_loss: 0.6717, train/total_loss/avg: 0.6965, max mem: 5495.0, experiment: run, epoch: 2, num_updates: 1050, iterations: 1050, max_updates: 6000, lr: 0.00003, ups: 1.35, time: 37s 445ms, time_since_start: 13m 28s 701ms, eta: 01h 05m 59s 182ms\n",
            "\u001b[32m2022-12-11T03:24:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/6000, train/hateful_memes/cross_entropy: 0.6628, train/hateful_memes/cross_entropy/avg: 0.6932, train/total_loss: 0.6628, train/total_loss/avg: 0.6932, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 6000, lr: 0.00003, ups: 1.43, time: 35s 358ms, time_since_start: 14m 04s 060ms, eta: 01h 01m 40s 736ms\n",
            "\u001b[32m2022-12-11T03:25:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/6000, train/hateful_memes/cross_entropy: 0.6628, train/hateful_memes/cross_entropy/avg: 0.6979, train/total_loss: 0.6628, train/total_loss/avg: 0.6979, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 030ms, time_since_start: 14m 40s 090ms, eta: 01h 02m 12s 618ms\n",
            "\u001b[32m2022-12-11T03:25:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/6000, train/hateful_memes/cross_entropy: 0.6628, train/hateful_memes/cross_entropy/avg: 0.6996, train/total_loss: 0.6628, train/total_loss/avg: 0.6996, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 122ms, time_since_start: 15m 16s 213ms, eta: 01h 01m 43s 563ms\n",
            "\u001b[32m2022-12-11T03:26:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/6000, train/hateful_memes/cross_entropy: 0.6628, train/hateful_memes/cross_entropy/avg: 0.6952, train/total_loss: 0.6628, train/total_loss/avg: 0.6952, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 000ms, time_since_start: 15m 52s 213ms, eta: 01h 52s 573ms\n",
            "\u001b[32m2022-12-11T03:27:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/6000, train/hateful_memes/cross_entropy: 0.6628, train/hateful_memes/cross_entropy/avg: 0.6970, train/total_loss: 0.6628, train/total_loss/avg: 0.6970, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 047ms, time_since_start: 16m 28s 260ms, eta: 01h 18s 849ms\n",
            "\u001b[32m2022-12-11T03:27:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6945, train/total_loss: 0.6618, train/total_loss/avg: 0.6945, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 186ms, time_since_start: 17m 04s 446ms, eta: 59m 54s 177ms\n",
            "\u001b[32m2022-12-11T03:28:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/6000, train/hateful_memes/cross_entropy: 0.6500, train/hateful_memes/cross_entropy/avg: 0.6923, train/total_loss: 0.6500, train/total_loss/avg: 0.6923, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 6000, lr: 0.00003, ups: 1.43, time: 35s 972ms, time_since_start: 17m 40s 419ms, eta: 58m 54s 527ms\n",
            "\u001b[32m2022-12-11T03:28:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6918, train/total_loss: 0.6618, train/total_loss/avg: 0.6918, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 000ms, time_since_start: 18m 16s 420ms, eta: 58m 18s 831ms\n",
            "\u001b[32m2022-12-11T03:29:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6877, train/total_loss: 0.6618, train/total_loss/avg: 0.6877, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 013ms, time_since_start: 18m 52s 433ms, eta: 57m 41s 578ms\n",
            "\u001b[32m2022-12-11T03:29:35 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T03:29:35 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T03:29:44 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T03:29:44 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T03:29:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:29:48 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-11T03:29:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:30:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:30:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, val/hateful_memes/cross_entropy: 0.6592, val/total_loss: 0.6592, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5381, num_updates: 1500, epoch: 3, iterations: 1500, max_updates: 6000, val_time: 25s 093ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.538077\n",
            "\u001b[32m2022-12-11T03:30:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/6000, train/hateful_memes/cross_entropy: 0.6381, train/hateful_memes/cross_entropy/avg: 0.6860, train/total_loss: 0.6381, train/total_loss/avg: 0.6860, max mem: 5495.0, experiment: run, epoch: 3, num_updates: 1550, iterations: 1550, max_updates: 6000, lr: 0.00004, ups: 1.35, time: 37s 076ms, time_since_start: 19m 54s 611ms, eta: 58m 44s 220ms\n",
            "\u001b[32m2022-12-11T03:31:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6838, train/total_loss: 0.6355, train/total_loss/avg: 0.6838, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1600, iterations: 1600, max_updates: 6000, lr: 0.00004, ups: 1.43, time: 35s 611ms, time_since_start: 20m 30s 222ms, eta: 55m 46s 918ms\n",
            "\u001b[32m2022-12-11T03:31:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6856, train/total_loss: 0.6355, train/total_loss/avg: 0.6856, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1650, iterations: 1650, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 180ms, time_since_start: 21m 06s 403ms, eta: 56m 01s 726ms\n",
            "\u001b[32m2022-12-11T03:32:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/6000, train/hateful_memes/cross_entropy: 0.6381, train/hateful_memes/cross_entropy/avg: 0.6870, train/total_loss: 0.6381, train/total_loss/avg: 0.6870, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1700, iterations: 1700, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 658ms, time_since_start: 21m 43s 061ms, eta: 56m 06s 988ms\n",
            "\u001b[32m2022-12-11T03:33:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/6000, train/hateful_memes/cross_entropy: 0.6381, train/hateful_memes/cross_entropy/avg: 0.6885, train/total_loss: 0.6381, train/total_loss/avg: 0.6885, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 394ms, time_since_start: 22m 19s 456ms, eta: 55m 03s 932ms\n",
            "\u001b[32m2022-12-11T03:33:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/6000, train/hateful_memes/cross_entropy: 0.6381, train/hateful_memes/cross_entropy/avg: 0.6840, train/total_loss: 0.6381, train/total_loss/avg: 0.6840, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 489ms, time_since_start: 22m 55s 946ms, eta: 54m 33s 565ms\n",
            "\u001b[32m2022-12-11T03:34:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/6000, train/hateful_memes/cross_entropy: 0.6381, train/hateful_memes/cross_entropy/avg: 0.6844, train/total_loss: 0.6381, train/total_loss/avg: 0.6844, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 516ms, time_since_start: 23m 32s 462ms, eta: 53m 56s 932ms\n",
            "\u001b[32m2022-12-11T03:34:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6828, train/total_loss: 0.6355, train/total_loss/avg: 0.6828, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 476ms, time_since_start: 24m 08s 938ms, eta: 53m 14s 456ms\n",
            "\u001b[32m2022-12-11T03:35:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6816, train/total_loss: 0.6355, train/total_loss/avg: 0.6816, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 459ms, time_since_start: 24m 45s 398ms, eta: 52m 34s 065ms\n",
            "\u001b[32m2022-12-11T03:36:05 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-11T03:36:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:36:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:36:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:36:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, train/hateful_memes/cross_entropy: 0.6363, train/hateful_memes/cross_entropy/avg: 0.6810, train/total_loss: 0.6363, train/total_loss/avg: 0.6810, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 6000, lr: 0.00005, ups: 1.09, time: 46s 416ms, time_since_start: 25m 31s 814ms, eta: 01h 06m 05s 812ms\n",
            "\u001b[32m2022-12-11T03:36:14 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T03:36:14 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T03:36:24 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T03:36:24 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T03:36:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:36:29 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-11T03:36:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:36:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:36:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, val/hateful_memes/cross_entropy: 0.6640, val/total_loss: 0.6640, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5530, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 6000, val_time: 24s 864ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T03:37:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/6000, train/hateful_memes/cross_entropy: 0.6363, train/hateful_memes/cross_entropy/avg: 0.6839, train/total_loss: 0.6363, train/total_loss/avg: 0.6839, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 6000, lr: 0.00005, ups: 1.35, time: 37s 733ms, time_since_start: 26m 34s 414ms, eta: 53m 03s 682ms\n",
            "\u001b[32m2022-12-11T03:37:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/6000, train/hateful_memes/cross_entropy: 0.6363, train/hateful_memes/cross_entropy/avg: 0.6818, train/total_loss: 0.6363, train/total_loss/avg: 0.6818, max mem: 5495.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 149ms, time_since_start: 27m 10s 563ms, eta: 50m 11s 380ms\n",
            "\u001b[32m2022-12-11T03:38:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6799, train/total_loss: 0.6355, train/total_loss/avg: 0.6799, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 6000, lr: 0.00005, ups: 1.43, time: 35s 862ms, time_since_start: 27m 46s 426ms, eta: 49m 09s 188ms\n",
            "\u001b[32m2022-12-11T03:39:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6807, train/total_loss: 0.6355, train/total_loss/avg: 0.6807, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 280ms, time_since_start: 28m 22s 706ms, eta: 49m 04s 813ms\n",
            "\u001b[32m2022-12-11T03:39:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6777, train/total_loss: 0.6355, train/total_loss/avg: 0.6777, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 339ms, time_since_start: 28m 59s 046ms, eta: 48m 30s 800ms\n",
            "\u001b[32m2022-12-11T03:40:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/6000, train/hateful_memes/cross_entropy: 0.6329, train/hateful_memes/cross_entropy/avg: 0.6738, train/total_loss: 0.6329, train/total_loss/avg: 0.6738, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 320ms, time_since_start: 29m 35s 366ms, eta: 47m 50s 469ms\n",
            "\u001b[32m2022-12-11T03:40:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6759, train/total_loss: 0.6355, train/total_loss/avg: 0.6759, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 411ms, time_since_start: 30m 11s 777ms, eta: 47m 18s 750ms\n",
            "\u001b[32m2022-12-11T03:41:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6718, train/total_loss: 0.6355, train/total_loss/avg: 0.6718, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 6000, lr: 0.00005, ups: 1.39, time: 36s 312ms, time_since_start: 30m 48s 090ms, eta: 46m 32s 287ms\n",
            "\u001b[32m2022-12-11T03:42:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6738, train/total_loss: 0.6355, train/total_loss/avg: 0.6738, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 345ms, time_since_start: 31m 24s 435ms, eta: 45m 55s 998ms\n",
            "\u001b[32m2022-12-11T03:42:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, train/hateful_memes/cross_entropy: 0.6355, train/hateful_memes/cross_entropy/avg: 0.6731, train/total_loss: 0.6355, train/total_loss/avg: 0.6731, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 272ms, time_since_start: 32m 708ms, eta: 45m 11s 768ms\n",
            "\u001b[32m2022-12-11T03:42:43 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T03:42:43 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T03:42:52 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T03:42:52 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T03:42:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:42:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:43:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:43:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, val/hateful_memes/cross_entropy: 0.6595, val/total_loss: 0.6595, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.4521, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 6000, val_time: 19s 313ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T03:43:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/6000, train/hateful_memes/cross_entropy: 0.6354, train/hateful_memes/cross_entropy/avg: 0.6711, train/total_loss: 0.6354, train/total_loss/avg: 0.6711, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 6000, lr: 0.00004, ups: 1.35, time: 37s 063ms, time_since_start: 32m 57s 092ms, eta: 45m 31s 249ms\n",
            "\u001b[32m2022-12-11T03:44:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/6000, train/hateful_memes/cross_entropy: 0.6354, train/hateful_memes/cross_entropy/avg: 0.6701, train/total_loss: 0.6354, train/total_loss/avg: 0.6701, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 142ms, time_since_start: 33m 33s 235ms, eta: 43m 44s 807ms\n",
            "\u001b[32m2022-12-11T03:44:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/6000, train/hateful_memes/cross_entropy: 0.6253, train/hateful_memes/cross_entropy/avg: 0.6692, train/total_loss: 0.6253, train/total_loss/avg: 0.6692, max mem: 5495.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 132ms, time_since_start: 34m 09s 367ms, eta: 43m 05s 522ms\n",
            "\u001b[32m2022-12-11T03:45:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/6000, train/hateful_memes/cross_entropy: 0.6236, train/hateful_memes/cross_entropy/avg: 0.6665, train/total_loss: 0.6236, train/total_loss/avg: 0.6665, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 6000, lr: 0.00004, ups: 1.43, time: 35s 820ms, time_since_start: 34m 45s 188ms, eta: 42m 04s 885ms\n",
            "\u001b[32m2022-12-11T03:46:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/6000, train/hateful_memes/cross_entropy: 0.6236, train/hateful_memes/cross_entropy/avg: 0.6686, train/total_loss: 0.6236, train/total_loss/avg: 0.6686, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 317ms, time_since_start: 35m 21s 505ms, eta: 42m 01s 168ms\n",
            "\u001b[32m2022-12-11T03:46:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/6000, train/hateful_memes/cross_entropy: 0.6236, train/hateful_memes/cross_entropy/avg: 0.6676, train/total_loss: 0.6236, train/total_loss/avg: 0.6676, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 342ms, time_since_start: 35m 57s 848ms, eta: 41m 24s 080ms\n",
            "\u001b[32m2022-12-11T03:47:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/6000, train/hateful_memes/cross_entropy: 0.6236, train/hateful_memes/cross_entropy/avg: 0.6683, train/total_loss: 0.6236, train/total_loss/avg: 0.6683, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 560ms, time_since_start: 36m 34s 408ms, eta: 40m 59s 919ms\n",
            "\u001b[32m2022-12-11T03:47:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/6000, train/hateful_memes/cross_entropy: 0.6253, train/hateful_memes/cross_entropy/avg: 0.6687, train/total_loss: 0.6253, train/total_loss/avg: 0.6687, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 299ms, time_since_start: 37m 10s 707ms, eta: 40m 03s 615ms\n",
            "\u001b[32m2022-12-11T03:48:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/6000, train/hateful_memes/cross_entropy: 0.6160, train/hateful_memes/cross_entropy/avg: 0.6675, train/total_loss: 0.6160, train/total_loss/avg: 0.6675, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 446ms, time_since_start: 37m 47s 154ms, eta: 39m 34s 447ms\n",
            "\u001b[32m2022-12-11T03:49:06 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-11T03:49:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:49:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:49:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:49:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, train/hateful_memes/cross_entropy: 0.6160, train/hateful_memes/cross_entropy/avg: 0.6685, train/total_loss: 0.6160, train/total_loss/avg: 0.6685, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 6000, lr: 0.00004, ups: 1.09, time: 46s 185ms, time_since_start: 38m 33s 340ms, eta: 49m 19s 591ms\n",
            "\u001b[32m2022-12-11T03:49:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T03:49:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T03:49:25 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T03:49:25 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T03:49:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:49:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:49:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:49:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, val/hateful_memes/cross_entropy: 0.6670, val/total_loss: 0.6670, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5076, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 6000, val_time: 20s 315ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T03:50:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3050/6000, train/hateful_memes/cross_entropy: 0.6160, train/hateful_memes/cross_entropy/avg: 0.6677, train/total_loss: 0.6160, train/total_loss/avg: 0.6677, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 3050, iterations: 3050, max_updates: 6000, lr: 0.00004, ups: 1.35, time: 37s 724ms, time_since_start: 39m 31s 381ms, eta: 39m 37s 085ms\n",
            "\u001b[32m2022-12-11T03:50:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/6000, train/hateful_memes/cross_entropy: 0.6184, train/hateful_memes/cross_entropy/avg: 0.6671, train/total_loss: 0.6184, train/total_loss/avg: 0.6671, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 3100, iterations: 3100, max_updates: 6000, lr: 0.00004, ups: 1.43, time: 35s 992ms, time_since_start: 40m 07s 374ms, eta: 37m 09s 502ms\n",
            "\u001b[32m2022-12-11T03:51:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3150/6000, train/hateful_memes/cross_entropy: 0.6253, train/hateful_memes/cross_entropy/avg: 0.6676, train/total_loss: 0.6253, train/total_loss/avg: 0.6676, max mem: 5495.0, experiment: run, epoch: 6, num_updates: 3150, iterations: 3150, max_updates: 6000, lr: 0.00004, ups: 1.39, time: 36s 420ms, time_since_start: 40m 43s 794ms, eta: 36m 57s 153ms\n",
            "\u001b[32m2022-12-11T03:52:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/6000, train/hateful_memes/cross_entropy: 0.6184, train/hateful_memes/cross_entropy/avg: 0.6664, train/total_loss: 0.6184, train/total_loss/avg: 0.6664, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3200, iterations: 3200, max_updates: 6000, lr: 0.00003, ups: 1.43, time: 35s 977ms, time_since_start: 41m 19s 772ms, eta: 35m 51s 754ms\n",
            "\u001b[32m2022-12-11T03:52:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3250/6000, train/hateful_memes/cross_entropy: 0.6253, train/hateful_memes/cross_entropy/avg: 0.6664, train/total_loss: 0.6253, train/total_loss/avg: 0.6664, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3250, iterations: 3250, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 453ms, time_since_start: 41m 56s 226ms, eta: 35m 41s 278ms\n",
            "\u001b[32m2022-12-11T03:53:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/6000, train/hateful_memes/cross_entropy: 0.6306, train/hateful_memes/cross_entropy/avg: 0.6665, train/total_loss: 0.6306, train/total_loss/avg: 0.6665, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3300, iterations: 3300, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 317ms, time_since_start: 42m 32s 543ms, eta: 34m 54s 483ms\n",
            "\u001b[32m2022-12-11T03:53:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3350/6000, train/hateful_memes/cross_entropy: 0.6306, train/hateful_memes/cross_entropy/avg: 0.6666, train/total_loss: 0.6306, train/total_loss/avg: 0.6666, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3350, iterations: 3350, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 681ms, time_since_start: 43m 09s 224ms, eta: 34m 36s 316ms\n",
            "\u001b[32m2022-12-11T03:54:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/6000, train/hateful_memes/cross_entropy: 0.6354, train/hateful_memes/cross_entropy/avg: 0.6704, train/total_loss: 0.6354, train/total_loss/avg: 0.6704, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3400, iterations: 3400, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 419ms, time_since_start: 43m 45s 643ms, eta: 33m 42s 572ms\n",
            "\u001b[32m2022-12-11T03:55:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3450/6000, train/hateful_memes/cross_entropy: 0.6354, train/hateful_memes/cross_entropy/avg: 0.6708, train/total_loss: 0.6354, train/total_loss/avg: 0.6708, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3450, iterations: 3450, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 610ms, time_since_start: 44m 22s 254ms, eta: 33m 14s 121ms\n",
            "\u001b[32m2022-12-11T03:55:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, train/hateful_memes/cross_entropy: 0.6306, train/hateful_memes/cross_entropy/avg: 0.6702, train/total_loss: 0.6306, train/total_loss/avg: 0.6702, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3500, iterations: 3500, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 422ms, time_since_start: 44m 58s 676ms, eta: 32m 24s 946ms\n",
            "\u001b[32m2022-12-11T03:55:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T03:55:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T03:55:50 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T03:55:50 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T03:55:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T03:55:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T03:56:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T03:56:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, val/hateful_memes/cross_entropy: 0.6592, val/total_loss: 0.6592, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.4920, num_updates: 3500, epoch: 7, iterations: 3500, max_updates: 6000, val_time: 18s 449ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T03:56:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3550/6000, train/hateful_memes/cross_entropy: 0.6306, train/hateful_memes/cross_entropy/avg: 0.6692, train/total_loss: 0.6306, train/total_loss/avg: 0.6692, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3550, iterations: 3550, max_updates: 6000, lr: 0.00003, ups: 1.35, time: 37s 265ms, time_since_start: 45m 54s 398ms, eta: 32m 30s 175ms\n",
            "\u001b[32m2022-12-11T03:57:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/6000, train/hateful_memes/cross_entropy: 0.6648, train/hateful_memes/cross_entropy/avg: 0.6703, train/total_loss: 0.6648, train/total_loss/avg: 0.6703, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3600, iterations: 3600, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 376ms, time_since_start: 46m 30s 775ms, eta: 31m 04s 793ms\n",
            "\u001b[32m2022-12-11T03:57:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3650/6000, train/hateful_memes/cross_entropy: 0.6648, train/hateful_memes/cross_entropy/avg: 0.6692, train/total_loss: 0.6648, train/total_loss/avg: 0.6692, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3650, iterations: 3650, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 499ms, time_since_start: 47m 07s 274ms, eta: 30m 32s 127ms\n",
            "\u001b[32m2022-12-11T03:58:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/6000, train/hateful_memes/cross_entropy: 0.6648, train/hateful_memes/cross_entropy/avg: 0.6674, train/total_loss: 0.6648, train/total_loss/avg: 0.6674, max mem: 5495.0, experiment: run, epoch: 7, num_updates: 3700, iterations: 3700, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 477ms, time_since_start: 47m 43s 751ms, eta: 29m 52s 047ms\n",
            "\u001b[32m2022-12-11T03:59:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3750/6000, train/hateful_memes/cross_entropy: 0.6306, train/hateful_memes/cross_entropy/avg: 0.6668, train/total_loss: 0.6306, train/total_loss/avg: 0.6668, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 3750, iterations: 3750, max_updates: 6000, lr: 0.00003, ups: 1.43, time: 35s 943ms, time_since_start: 48m 19s 695ms, eta: 28m 47s 454ms\n",
            "\u001b[32m2022-12-11T03:59:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/6000, train/hateful_memes/cross_entropy: 0.6648, train/hateful_memes/cross_entropy/avg: 0.6676, train/total_loss: 0.6648, train/total_loss/avg: 0.6676, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 3800, iterations: 3800, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 226ms, time_since_start: 48m 55s 922ms, eta: 28m 22s 368ms\n",
            "\u001b[32m2022-12-11T04:00:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3850/6000, train/hateful_memes/cross_entropy: 0.6306, train/hateful_memes/cross_entropy/avg: 0.6661, train/total_loss: 0.6306, train/total_loss/avg: 0.6661, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 3850, iterations: 3850, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 295ms, time_since_start: 49m 32s 217ms, eta: 27m 46s 819ms\n",
            "\u001b[32m2022-12-11T04:00:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/6000, train/hateful_memes/cross_entropy: 0.6306, train/hateful_memes/cross_entropy/avg: 0.6673, train/total_loss: 0.6306, train/total_loss/avg: 0.6673, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 3900, iterations: 3900, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 109ms, time_since_start: 50m 08s 327ms, eta: 26m 59s 750ms\n",
            "\u001b[32m2022-12-11T04:01:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3950/6000, train/hateful_memes/cross_entropy: 0.6603, train/hateful_memes/cross_entropy/avg: 0.6672, train/total_loss: 0.6603, train/total_loss/avg: 0.6672, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 3950, iterations: 3950, max_updates: 6000, lr: 0.00003, ups: 1.39, time: 36s 298ms, time_since_start: 50m 44s 625ms, eta: 26m 29s 422ms\n",
            "\u001b[32m2022-12-11T04:02:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-11T04:02:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:02:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:02:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:02:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, train/hateful_memes/cross_entropy: 0.6603, train/hateful_memes/cross_entropy/avg: 0.6676, train/total_loss: 0.6603, train/total_loss/avg: 0.6676, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 4000, iterations: 4000, max_updates: 6000, lr: 0.00003, ups: 1.09, time: 46s 135ms, time_since_start: 51m 30s 760ms, eta: 32m 50s 907ms\n",
            "\u001b[32m2022-12-11T04:02:13 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T04:02:13 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T04:02:22 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T04:02:22 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T04:02:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:02:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:02:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:02:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, val/hateful_memes/cross_entropy: 0.6592, val/total_loss: 0.6592, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.4716, num_updates: 4000, epoch: 8, iterations: 4000, max_updates: 6000, val_time: 19s 968ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T04:03:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4050/6000, train/hateful_memes/cross_entropy: 0.6603, train/hateful_memes/cross_entropy/avg: 0.6659, train/total_loss: 0.6603, train/total_loss/avg: 0.6659, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 4050, iterations: 4050, max_updates: 6000, lr: 0.00002, ups: 1.35, time: 37s 507ms, time_since_start: 52m 28s 238ms, eta: 26m 02s 280ms\n",
            "\u001b[32m2022-12-11T04:03:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/6000, train/hateful_memes/cross_entropy: 0.6631, train/hateful_memes/cross_entropy/avg: 0.6659, train/total_loss: 0.6631, train/total_loss/avg: 0.6659, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 4100, iterations: 4100, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 846ms, time_since_start: 53m 04s 085ms, eta: 24m 14s 784ms\n",
            "\u001b[32m2022-12-11T04:04:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4150/6000, train/hateful_memes/cross_entropy: 0.6603, train/hateful_memes/cross_entropy/avg: 0.6648, train/total_loss: 0.6603, train/total_loss/avg: 0.6648, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 4150, iterations: 4150, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 334ms, time_since_start: 53m 40s 419ms, eta: 23m 55s 808ms\n",
            "\u001b[32m2022-12-11T04:04:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/6000, train/hateful_memes/cross_entropy: 0.6603, train/hateful_memes/cross_entropy/avg: 0.6644, train/total_loss: 0.6603, train/total_loss/avg: 0.6644, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 4200, iterations: 4200, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 360ms, time_since_start: 54m 16s 780ms, eta: 23m 18s 003ms\n",
            "\u001b[32m2022-12-11T04:05:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4250/6000, train/hateful_memes/cross_entropy: 0.6603, train/hateful_memes/cross_entropy/avg: 0.6648, train/total_loss: 0.6603, train/total_loss/avg: 0.6648, max mem: 5495.0, experiment: run, epoch: 8, num_updates: 4250, iterations: 4250, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 213ms, time_since_start: 54m 52s 994ms, eta: 22m 33s 667ms\n",
            "\u001b[32m2022-12-11T04:06:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/6000, train/hateful_memes/cross_entropy: 0.6297, train/hateful_memes/cross_entropy/avg: 0.6644, train/total_loss: 0.6297, train/total_loss/avg: 0.6644, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4300, iterations: 4300, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 463ms, time_since_start: 55m 28s 458ms, eta: 21m 27s 754ms\n",
            "\u001b[32m2022-12-11T04:06:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4350/6000, train/hateful_memes/cross_entropy: 0.6297, train/hateful_memes/cross_entropy/avg: 0.6644, train/total_loss: 0.6297, train/total_loss/avg: 0.6644, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4350, iterations: 4350, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 000ms, time_since_start: 56m 04s 458ms, eta: 21m 08s 788ms\n",
            "\u001b[32m2022-12-11T04:07:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/6000, train/hateful_memes/cross_entropy: 0.6296, train/hateful_memes/cross_entropy/avg: 0.6639, train/total_loss: 0.6296, train/total_loss/avg: 0.6639, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4400, iterations: 4400, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 788ms, time_since_start: 56m 40s 246ms, eta: 20m 23s 109ms\n",
            "\u001b[32m2022-12-11T04:07:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4450/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6624, train/total_loss: 0.6271, train/total_loss/avg: 0.6624, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4450, iterations: 4450, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 949ms, time_since_start: 57m 16s 196ms, eta: 19m 50s 211ms\n",
            "\u001b[32m2022-12-11T04:08:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, train/hateful_memes/cross_entropy: 0.6224, train/hateful_memes/cross_entropy/avg: 0.6615, train/total_loss: 0.6224, train/total_loss/avg: 0.6615, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4500, iterations: 4500, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 053ms, time_since_start: 57m 52s 249ms, eta: 19m 15s 161ms\n",
            "\u001b[32m2022-12-11T04:08:35 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T04:08:35 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T04:08:43 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T04:08:43 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T04:08:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:08:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:08:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:08:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, val/hateful_memes/cross_entropy: 0.6604, val/total_loss: 0.6604, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.4876, num_updates: 4500, epoch: 9, iterations: 4500, max_updates: 6000, val_time: 18s 814ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T04:09:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4550/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6624, train/total_loss: 0.6271, train/total_loss/avg: 0.6624, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4550, iterations: 4550, max_updates: 6000, lr: 0.00002, ups: 1.39, time: 36s 799ms, time_since_start: 58m 47s 871ms, eta: 18m 59s 763ms\n",
            "\u001b[32m2022-12-11T04:10:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6621, train/total_loss: 0.6271, train/total_loss/avg: 0.6621, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4600, iterations: 4600, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 891ms, time_since_start: 59m 23s 762ms, eta: 17m 53s 286ms\n",
            "\u001b[32m2022-12-11T04:10:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4650/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6611, train/total_loss: 0.6271, train/total_loss/avg: 0.6611, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4650, iterations: 4650, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 877ms, time_since_start: 59m 59s 639ms, eta: 17m 14s 550ms\n",
            "\u001b[32m2022-12-11T04:11:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/6000, train/hateful_memes/cross_entropy: 0.6297, train/hateful_memes/cross_entropy/avg: 0.6614, train/total_loss: 0.6297, train/total_loss/avg: 0.6614, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4700, iterations: 4700, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 996ms, time_since_start: 01h 35s 636ms, eta: 16m 39s 558ms\n",
            "\u001b[32m2022-12-11T04:11:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4750/6000, train/hateful_memes/cross_entropy: 0.6345, train/hateful_memes/cross_entropy/avg: 0.6614, train/total_loss: 0.6345, train/total_loss/avg: 0.6614, max mem: 5495.0, experiment: run, epoch: 9, num_updates: 4750, iterations: 4750, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 980ms, time_since_start: 01h 01m 11s 617ms, eta: 16m 687ms\n",
            "\u001b[32m2022-12-11T04:12:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/6000, train/hateful_memes/cross_entropy: 0.6297, train/hateful_memes/cross_entropy/avg: 0.6610, train/total_loss: 0.6297, train/total_loss/avg: 0.6610, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 4800, iterations: 4800, max_updates: 6000, lr: 0.00002, ups: 1.43, time: 35s 477ms, time_since_start: 01h 01m 47s 094ms, eta: 15m 09s 354ms\n",
            "\u001b[32m2022-12-11T04:13:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4850/6000, train/hateful_memes/cross_entropy: 0.6345, train/hateful_memes/cross_entropy/avg: 0.6614, train/total_loss: 0.6345, train/total_loss/avg: 0.6614, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 4850, iterations: 4850, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 459ms, time_since_start: 01h 02m 23s 554ms, eta: 14m 55s 603ms\n",
            "\u001b[32m2022-12-11T04:13:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/6000, train/hateful_memes/cross_entropy: 0.6297, train/hateful_memes/cross_entropy/avg: 0.6596, train/total_loss: 0.6297, train/total_loss/avg: 0.6596, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 4900, iterations: 4900, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 387ms, time_since_start: 01h 02m 59s 941ms, eta: 14m 14s 955ms\n",
            "\u001b[32m2022-12-11T04:14:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4950/6000, train/hateful_memes/cross_entropy: 0.6297, train/hateful_memes/cross_entropy/avg: 0.6606, train/total_loss: 0.6297, train/total_loss/avg: 0.6606, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 4950, iterations: 4950, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 624ms, time_since_start: 01h 03m 36s 566ms, eta: 13m 41s 424ms\n",
            "\u001b[32m2022-12-11T04:14:56 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-11T04:14:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:15:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:15:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:15:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6598, train/total_loss: 0.6271, train/total_loss/avg: 0.6598, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 5000, iterations: 5000, max_updates: 6000, lr: 0.00001, ups: 1.06, time: 47s 161ms, time_since_start: 01h 04m 23s 728ms, eta: 16m 47s 367ms\n",
            "\u001b[32m2022-12-11T04:15:06 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T04:15:06 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T04:15:15 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T04:15:15 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T04:15:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:15:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:15:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:15:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, val/hateful_memes/cross_entropy: 0.6608, val/total_loss: 0.6608, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.4938, num_updates: 5000, epoch: 10, iterations: 5000, max_updates: 6000, val_time: 18s 452ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T04:16:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5050/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6593, train/total_loss: 0.6271, train/total_loss/avg: 0.6593, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 5050, iterations: 5050, max_updates: 6000, lr: 0.00001, ups: 1.35, time: 37s 814ms, time_since_start: 01h 05m 19s 996ms, eta: 12m 47s 333ms\n",
            "\u001b[32m2022-12-11T04:16:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6590, train/total_loss: 0.6271, train/total_loss/avg: 0.6590, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 5100, iterations: 5100, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 124ms, time_since_start: 01h 05m 56s 121ms, eta: 11m 34s 461ms\n",
            "\u001b[32m2022-12-11T04:17:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5150/6000, train/hateful_memes/cross_entropy: 0.6271, train/hateful_memes/cross_entropy/avg: 0.6587, train/total_loss: 0.6271, train/total_loss/avg: 0.6587, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 5150, iterations: 5150, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 585ms, time_since_start: 01h 06m 32s 706ms, eta: 11m 04s 250ms\n",
            "\u001b[32m2022-12-11T04:17:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6584, train/total_loss: 0.6268, train/total_loss/avg: 0.6584, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 5200, iterations: 5200, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 578ms, time_since_start: 01h 07m 09s 285ms, eta: 10m 25s 048ms\n",
            "\u001b[32m2022-12-11T04:18:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5250/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6584, train/total_loss: 0.6268, train/total_loss/avg: 0.6584, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 5250, iterations: 5250, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 413ms, time_since_start: 01h 07m 45s 698ms, eta: 09m 43s 340ms\n",
            "\u001b[32m2022-12-11T04:19:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6585, train/total_loss: 0.6268, train/total_loss/avg: 0.6585, max mem: 5495.0, experiment: run, epoch: 10, num_updates: 5300, iterations: 5300, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 408ms, time_since_start: 01h 08m 22s 106ms, eta: 09m 04s 375ms\n",
            "\u001b[32m2022-12-11T04:19:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5350/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6590, train/total_loss: 0.6268, train/total_loss/avg: 0.6590, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5350, iterations: 5350, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 817ms, time_since_start: 01h 08m 57s 924ms, eta: 08m 17s 294ms\n",
            "\u001b[32m2022-12-11T04:20:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6583, train/total_loss: 0.6268, train/total_loss/avg: 0.6583, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5400, iterations: 5400, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 927ms, time_since_start: 01h 09m 33s 851ms, eta: 07m 40s 445ms\n",
            "\u001b[32m2022-12-11T04:20:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5450/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6575, train/total_loss: 0.6268, train/total_loss/avg: 0.6575, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5450, iterations: 5450, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 901ms, time_since_start: 01h 10m 09s 753ms, eta: 07m 01s 776ms\n",
            "\u001b[32m2022-12-11T04:21:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, train/hateful_memes/cross_entropy: 0.6330, train/hateful_memes/cross_entropy/avg: 0.6586, train/total_loss: 0.6330, train/total_loss/avg: 0.6586, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5500, iterations: 5500, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 948ms, time_since_start: 01h 10m 45s 702ms, eta: 06m 23s 932ms\n",
            "\u001b[32m2022-12-11T04:21:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T04:21:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T04:21:37 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T04:21:37 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T04:21:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:21:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:21:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:21:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, val/hateful_memes/cross_entropy: 0.6598, val/total_loss: 0.6598, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5058, num_updates: 5500, epoch: 11, iterations: 5500, max_updates: 6000, val_time: 18s 390ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T04:22:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5550/6000, train/hateful_memes/cross_entropy: 0.6330, train/hateful_memes/cross_entropy/avg: 0.6593, train/total_loss: 0.6330, train/total_loss/avg: 0.6593, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5550, iterations: 5550, max_updates: 6000, lr: 0.00001, ups: 1.39, time: 36s 775ms, time_since_start: 01h 11m 40s 875ms, eta: 05m 53s 485ms\n",
            "\u001b[32m2022-12-11T04:22:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/6000, train/hateful_memes/cross_entropy: 0.6330, train/hateful_memes/cross_entropy/avg: 0.6603, train/total_loss: 0.6330, train/total_loss/avg: 0.6603, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5600, iterations: 5600, max_updates: 6000, lr: 0.00001, ups: 1.43, time: 35s 911ms, time_since_start: 01h 12m 16s 787ms, eta: 05m 06s 828ms\n",
            "\u001b[32m2022-12-11T04:23:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5650/6000, train/hateful_memes/cross_entropy: 0.6330, train/hateful_memes/cross_entropy/avg: 0.6596, train/total_loss: 0.6330, train/total_loss/avg: 0.6596, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5650, iterations: 5650, max_updates: 6000, lr: 0., ups: 1.43, time: 35s 885ms, time_since_start: 01h 12m 52s 672ms, eta: 04m 28s 279ms\n",
            "\u001b[32m2022-12-11T04:24:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6593, train/total_loss: 0.6268, train/total_loss/avg: 0.6593, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5700, iterations: 5700, max_updates: 6000, lr: 0., ups: 1.39, time: 36s 000ms, time_since_start: 01h 13m 28s 672ms, eta: 03m 50s 689ms\n",
            "\u001b[32m2022-12-11T04:24:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5750/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6603, train/total_loss: 0.6268, train/total_loss/avg: 0.6603, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5750, iterations: 5750, max_updates: 6000, lr: 0., ups: 1.43, time: 35s 951ms, time_since_start: 01h 14m 04s 624ms, eta: 03m 11s 983ms\n",
            "\u001b[32m2022-12-11T04:25:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/6000, train/hateful_memes/cross_entropy: 0.6330, train/hateful_memes/cross_entropy/avg: 0.6603, train/total_loss: 0.6330, train/total_loss/avg: 0.6603, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5800, iterations: 5800, max_updates: 6000, lr: 0., ups: 1.43, time: 35s 832ms, time_since_start: 01h 14m 40s 457ms, eta: 02m 33s 076ms\n",
            "\u001b[32m2022-12-11T04:25:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5850/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6597, train/total_loss: 0.6268, train/total_loss/avg: 0.6597, max mem: 5495.0, experiment: run, epoch: 11, num_updates: 5850, iterations: 5850, max_updates: 6000, lr: 0., ups: 1.43, time: 35s 814ms, time_since_start: 01h 15m 16s 271ms, eta: 01m 54s 749ms\n",
            "\u001b[32m2022-12-11T04:26:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/6000, train/hateful_memes/cross_entropy: 0.6330, train/hateful_memes/cross_entropy/avg: 0.6603, train/total_loss: 0.6330, train/total_loss/avg: 0.6603, max mem: 5495.0, experiment: run, epoch: 12, num_updates: 5900, iterations: 5900, max_updates: 6000, lr: 0., ups: 1.43, time: 35s 257ms, time_since_start: 01h 15m 51s 529ms, eta: 01m 15s 310ms\n",
            "\u001b[32m2022-12-11T04:27:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5950/6000, train/hateful_memes/cross_entropy: 0.6268, train/hateful_memes/cross_entropy/avg: 0.6600, train/total_loss: 0.6268, train/total_loss/avg: 0.6600, max mem: 5495.0, experiment: run, epoch: 12, num_updates: 5950, iterations: 5950, max_updates: 6000, lr: 0., ups: 1.43, time: 35s 625ms, time_since_start: 01h 16m 27s 155ms, eta: 38s 048ms\n",
            "\u001b[32m2022-12-11T04:27:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-11T04:27:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:27:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:27:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:27:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, train/hateful_memes/cross_entropy: 0.6330, train/hateful_memes/cross_entropy/avg: 0.6607, train/total_loss: 0.6330, train/total_loss/avg: 0.6607, max mem: 5495.0, experiment: run, epoch: 12, num_updates: 6000, iterations: 6000, max_updates: 6000, lr: 0., ups: 1.11, time: 45s 509ms, time_since_start: 01h 17m 12s 665ms, eta: 0ms\n",
            "\u001b[32m2022-12-11T04:27:55 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-11T04:27:55 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-11T04:28:04 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-11T04:28:04 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T04:28:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-11T04:28:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-11T04:28:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-11T04:28:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, val/hateful_memes/cross_entropy: 0.6596, val/total_loss: 0.6596, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5042, num_updates: 6000, epoch: 12, iterations: 6000, max_updates: 6000, val_time: 19s 984ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.553007\n",
            "\u001b[32m2022-12-11T04:28:16 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2022-12-11T04:28:16 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2022-12-11T04:28:16 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2022-12-11T04:28:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-12-11T04:28:22 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2000\n",
            "\u001b[32m2022-12-11T04:28:22 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2000\n",
            "\u001b[32m2022-12-11T04:28:22 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 4\n",
            "\u001b[32m2022-12-11T04:28:23 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-12-11T04:28:23 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 125/125 [00:31<00:00,  3.91it/s]\n",
            "\u001b[32m2022-12-11T04:28:55 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 125\n",
            "\u001b[32m2022-12-11T04:28:55 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-11T04:28:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, test/hateful_memes/cross_entropy: 0.6674, test/total_loss: 0.6674, test/hateful_memes/accuracy: 0.6250, test/hateful_memes/binary_f1: 0.0000, test/hateful_memes/roc_auc: 0.5901\n",
            "\u001b[32m2022-12-11T04:28:55 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 01h 18m 12s 577ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/mmbt/with_features.yaml \\\n",
        "  model=mmbt \\\n",
        "  dataset=hateful_memes \\\n",
        "  training.log_interval=50 \\\n",
        "  training.max_updates=6000 \\\n",
        "  training.batch_size=16 \\\n",
        "  training.evaluation_interval=500 \\\n",
        "  trainer.params.gpus=100 \\\n",
        "  env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQlsd1lMlaiv",
        "outputId": "c63b7770-d06b-43e3-debd-9423669972ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 09:13:40.212774: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/omegaconf/grammar_visitor.py:253: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  warnings.warn(\n",
            "\u001b[32m2022-12-12T09:13:47 | mmf: \u001b[0mLogging to: /drive/MyDrive/final_project/mmf/projects/hateful_memes/save/train.log\n",
            "\u001b[32m2022-12-12T09:13:47 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=drive/MyDrive/final_project/mmf/projects/hateful_memes/configs/mmbt/with_features.yaml', 'model=mmbt', 'dataset=hateful_memes', 'training.log_interval=50', 'training.max_updates=6000', 'training.batch_size=16', 'training.evaluation_interval=500', 'trainer.params.gpus=100', 'env.save_dir=/drive/MyDrive/final_project/mmf/projects/hateful_memes/save'])\n",
            "\u001b[32m2022-12-12T09:13:47 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu111\n",
            "\u001b[32m2022-12-12T09:13:47 | mmf.utils.general: \u001b[0mCUDA Device 0 is: A100-SXM4-40GB\n",
            "\u001b[32m2022-12-12T09:13:47 | mmf_cli.run: \u001b[0mUsing seed 47643846\n",
            "\u001b[32m2022-12-12T09:13:47 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n",
            "Downloading features.tar.gz: 100% 10.3G/10.3G [03:02<00:00, 56.4MB/s]\n",
            "[ Starting checksum for features.tar.gz]\n",
            "[ Checksum successful for features.tar.gz]\n",
            "Unpacking features.tar.gz\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:00<00:00, 371kB/s]\n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpyobbe0co\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 33.4kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpl1pnjylu\n",
            "Downloading: 100% 570/570 [00:00<00:00, 773kB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqu5ix7pj\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 2.60MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgy3_o6m3\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 3.22MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "\u001b[32m2022-12-12T09:19:30 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-12T09:19:30 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-12T09:19:30 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-12-12T09:19:30 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_83u1qci\n",
            "Downloading: 100% 440M/440M [00:05<00:00, 83.7MB/s]\n",
            "storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelJit: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModelJit from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModelJit from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModelJit were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModelJit for predictions without further training.\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/detectron/vmb_weights.tar.gz to /root/.cache/torch/mmf/data/models/detectron.vmb_weights/vmb_weights.tar.gz ]\n",
            "Downloading vmb_weights.tar.gz: 100% 15.5M/15.5M [00:01<00:00, 14.1MB/s]\n",
            "[ Starting checksum for vmb_weights.tar.gz]\n",
            "[ Checksum successful for vmb_weights.tar.gz]\n",
            "Unpacking vmb_weights.tar.gz\n",
            "\u001b[32m2022-12-12T09:19:47 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-12-12T09:19:47 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-12-12T09:19:47 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-12-12T09:19:47 | mmf.trainers.mmf_trainer: \u001b[0mMMBT(\n",
            "  (model): MMBTForClassification(\n",
            "    (bert): MMBTBase(\n",
            "      (mmbt): MMBTModel(\n",
            "        (transformer): BertModelJit(\n",
            "          (embeddings): BertEmbeddingsJit(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoderJit(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayerJit(\n",
            "                (attention): BertAttentionJit(\n",
            "                  (self): BertSelfAttentionJit(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "        (modal_encoder): ModalEmbeddings(\n",
            "          (encoder): FinetuneFasterRcnnFpnFc7(\n",
            "            (lc): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          )\n",
            "          (proj_embeddings): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-12-12T09:19:47 | mmf.utils.general: \u001b[0mTotal Parameters: 115845890. Trained Parameters: 115845890\n",
            "\u001b[32m2022-12-12T09:19:47 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2022-12-12T09:19:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.6661, train/total_loss: 0.6661, train/total_loss/avg: 0.6661, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 50, iterations: 50, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 769ms, time_since_start: 06s 862ms, eta: 14m 20s 363ms\n",
            "\u001b[32m2022-12-12T09:20:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6639, train/total_loss: 0.6618, train/total_loss/avg: 0.6639, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 321ms, time_since_start: 13s 184ms, eta: 13m 16s 602ms\n",
            "\u001b[32m2022-12-12T09:20:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6483, train/total_loss: 0.6618, train/total_loss/avg: 0.6483, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 150, iterations: 150, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 295ms, time_since_start: 19s 479ms, eta: 13m 06s 627ms\n",
            "\u001b[32m2022-12-12T09:20:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.7038, train/total_loss: 0.6618, train/total_loss/avg: 0.7038, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 312ms, time_since_start: 25s 792ms, eta: 13m 02s 098ms\n",
            "\u001b[32m2022-12-12T09:20:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.7300, train/total_loss: 0.6661, train/total_loss/avg: 0.7300, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 250, iterations: 250, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 310ms, time_since_start: 32s 103ms, eta: 12m 55s 110ms\n",
            "\u001b[32m2022-12-12T09:20:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.7202, train/total_loss: 0.6661, train/total_loss/avg: 0.7202, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 300, iterations: 300, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 328ms, time_since_start: 38s 431ms, eta: 12m 50s 513ms\n",
            "\u001b[32m2022-12-12T09:20:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.7071, train/total_loss: 0.6661, train/total_loss/avg: 0.7071, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 350, iterations: 350, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 351ms, time_since_start: 44s 782ms, eta: 12m 46s 469ms\n",
            "\u001b[32m2022-12-12T09:20:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.7085, train/total_loss: 0.6661, train/total_loss/avg: 0.7085, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 365ms, time_since_start: 51s 148ms, eta: 12m 41s 463ms\n",
            "\u001b[32m2022-12-12T09:20:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.7008, train/total_loss: 0.6661, train/total_loss/avg: 0.7008, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 450, iterations: 450, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 355ms, time_since_start: 57s 503ms, eta: 12m 33s 384ms\n",
            "\u001b[32m2022-12-12T09:20:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.7010, train/total_loss: 0.6661, train/total_loss/avg: 0.7010, max mem: 5630.0, experiment: run, epoch: 1, num_updates: 500, iterations: 500, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 354ms, time_since_start: 01m 03s 858ms, eta: 12m 26s 505ms\n",
            "\u001b[32m2022-12-12T09:20:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:20:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:20:53 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:20:53 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:20:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:20:56 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-12T09:20:58 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:21:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:21:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/6000, val/hateful_memes/cross_entropy: 0.6601, val/total_loss: 0.6601, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5341, num_updates: 500, epoch: 1, iterations: 500, max_updates: 6000, val_time: 11s 944ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.534129\n",
            "\u001b[32m2022-12-12T09:21:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/6000, train/hateful_memes/cross_entropy: 0.6661, train/hateful_memes/cross_entropy/avg: 0.6925, train/total_loss: 0.6661, train/total_loss/avg: 0.6925, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 550, iterations: 550, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 613ms, time_since_start: 01m 22s 420ms, eta: 12m 49s 930ms\n",
            "\u001b[32m2022-12-12T09:21:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6863, train/total_loss: 0.6618, train/total_loss/avg: 0.6863, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 600, iterations: 600, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 312ms, time_since_start: 01m 28s 733ms, eta: 12m 08s 154ms\n",
            "\u001b[32m2022-12-12T09:21:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6833, train/total_loss: 0.6618, train/total_loss/avg: 0.6833, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 650, iterations: 650, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 462ms, time_since_start: 01m 35s 195ms, eta: 12m 18s 462ms\n",
            "\u001b[32m2022-12-12T09:21:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/6000, train/hateful_memes/cross_entropy: 0.6471, train/hateful_memes/cross_entropy/avg: 0.6738, train/total_loss: 0.6471, train/total_loss/avg: 0.6738, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 700, iterations: 700, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 334ms, time_since_start: 01m 41s 530ms, eta: 11m 57s 117ms\n",
            "\u001b[32m2022-12-12T09:21:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/6000, train/hateful_memes/cross_entropy: 0.6618, train/hateful_memes/cross_entropy/avg: 0.6811, train/total_loss: 0.6618, train/total_loss/avg: 0.6811, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 750, iterations: 750, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 433ms, time_since_start: 01m 47s 963ms, eta: 12m 01s 399ms\n",
            "\u001b[32m2022-12-12T09:21:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/6000, train/hateful_memes/cross_entropy: 0.6471, train/hateful_memes/cross_entropy/avg: 0.6669, train/total_loss: 0.6471, train/total_loss/avg: 0.6669, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 800, iterations: 800, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 415ms, time_since_start: 01m 54s 379ms, eta: 11m 52s 615ms\n",
            "\u001b[32m2022-12-12T09:21:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/6000, train/hateful_memes/cross_entropy: 0.6471, train/hateful_memes/cross_entropy/avg: 0.6560, train/total_loss: 0.6471, train/total_loss/avg: 0.6560, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 850, iterations: 850, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 472ms, time_since_start: 02m 851ms, eta: 11m 52s 002ms\n",
            "\u001b[32m2022-12-12T09:21:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/6000, train/hateful_memes/cross_entropy: 0.6389, train/hateful_memes/cross_entropy/avg: 0.6432, train/total_loss: 0.6389, train/total_loss/avg: 0.6432, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 900, iterations: 900, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 339ms, time_since_start: 02m 07s 191ms, eta: 11m 30s 592ms\n",
            "\u001b[32m2022-12-12T09:22:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/6000, train/hateful_memes/cross_entropy: 0.6389, train/hateful_memes/cross_entropy/avg: 0.6340, train/total_loss: 0.6389, train/total_loss/avg: 0.6340, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 950, iterations: 950, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 463ms, time_since_start: 02m 13s 654ms, eta: 11m 37s 170ms\n",
            "\u001b[32m2022-12-12T09:22:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-12T09:22:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:22:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:22:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:22:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, train/hateful_memes/cross_entropy: 0.6283, train/hateful_memes/cross_entropy/avg: 0.6277, train/total_loss: 0.6283, train/total_loss/avg: 0.6277, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 1000, iterations: 1000, max_updates: 6000, lr: 0.00003, ups: 3.57, time: 14s 902ms, time_since_start: 02m 28s 557ms, eta: 26m 31s 634ms\n",
            "\u001b[32m2022-12-12T09:22:15 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:22:15 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:22:18 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:22:18 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:22:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:22:22 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-12T09:22:26 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:22:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:22:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/6000, val/hateful_memes/cross_entropy: 0.7292, val/total_loss: 0.7292, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.2205, val/hateful_memes/roc_auc: 0.5777, num_updates: 1000, epoch: 2, iterations: 1000, max_updates: 6000, val_time: 16s 028ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.577676\n",
            "\u001b[32m2022-12-12T09:22:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/6000, train/hateful_memes/cross_entropy: 0.6187, train/hateful_memes/cross_entropy/avg: 0.6152, train/total_loss: 0.6187, train/total_loss/avg: 0.6152, max mem: 5632.0, experiment: run, epoch: 2, num_updates: 1050, iterations: 1050, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 630ms, time_since_start: 02m 51s 218ms, eta: 11m 41s 091ms\n",
            "\u001b[32m2022-12-12T09:22:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/6000, train/hateful_memes/cross_entropy: 0.6187, train/hateful_memes/cross_entropy/avg: 0.6182, train/total_loss: 0.6187, train/total_loss/avg: 0.6182, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1100, iterations: 1100, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 223ms, time_since_start: 02m 57s 442ms, eta: 10m 51s 428ms\n",
            "\u001b[32m2022-12-12T09:22:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/6000, train/hateful_memes/cross_entropy: 0.6187, train/hateful_memes/cross_entropy/avg: 0.6039, train/total_loss: 0.6187, train/total_loss/avg: 0.6039, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1150, iterations: 1150, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 515ms, time_since_start: 03m 03s 957ms, eta: 11m 14s 957ms\n",
            "\u001b[32m2022-12-12T09:22:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/6000, train/hateful_memes/cross_entropy: 0.6074, train/hateful_memes/cross_entropy/avg: 0.6040, train/total_loss: 0.6074, train/total_loss/avg: 0.6040, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1200, iterations: 1200, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 339ms, time_since_start: 03m 10s 297ms, eta: 10m 50s 019ms\n",
            "\u001b[32m2022-12-12T09:23:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/6000, train/hateful_memes/cross_entropy: 0.6060, train/hateful_memes/cross_entropy/avg: 0.6034, train/total_loss: 0.6060, train/total_loss/avg: 0.6034, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1250, iterations: 1250, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 412ms, time_since_start: 03m 16s 709ms, eta: 10m 50s 571ms\n",
            "\u001b[32m2022-12-12T09:23:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/6000, train/hateful_memes/cross_entropy: 0.5872, train/hateful_memes/cross_entropy/avg: 0.6012, train/total_loss: 0.5872, train/total_loss/avg: 0.6012, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1300, iterations: 1300, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 273ms, time_since_start: 03m 22s 982ms, eta: 10m 29s 771ms\n",
            "\u001b[32m2022-12-12T09:23:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/6000, train/hateful_memes/cross_entropy: 0.5501, train/hateful_memes/cross_entropy/avg: 0.5914, train/total_loss: 0.5501, train/total_loss/avg: 0.5914, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1350, iterations: 1350, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 434ms, time_since_start: 03m 29s 416ms, eta: 10m 39s 087ms\n",
            "\u001b[32m2022-12-12T09:23:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/6000, train/hateful_memes/cross_entropy: 0.5466, train/hateful_memes/cross_entropy/avg: 0.5847, train/total_loss: 0.5466, train/total_loss/avg: 0.5847, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1400, iterations: 1400, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 308ms, time_since_start: 03m 35s 725ms, eta: 10m 19s 819ms\n",
            "\u001b[32m2022-12-12T09:23:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/6000, train/hateful_memes/cross_entropy: 0.5466, train/hateful_memes/cross_entropy/avg: 0.5857, train/total_loss: 0.5466, train/total_loss/avg: 0.5857, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1450, iterations: 1450, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 452ms, time_since_start: 03m 42s 177ms, eta: 10m 27s 121ms\n",
            "\u001b[32m2022-12-12T09:23:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, train/hateful_memes/cross_entropy: 0.5090, train/hateful_memes/cross_entropy/avg: 0.5800, train/total_loss: 0.5090, train/total_loss/avg: 0.5800, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1500, iterations: 1500, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 337ms, time_since_start: 03m 48s 514ms, eta: 10m 09s 122ms\n",
            "\u001b[32m2022-12-12T09:23:35 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:23:35 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:23:38 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:23:38 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:23:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:23:41 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-12T09:23:44 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:23:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:23:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/6000, val/hateful_memes/cross_entropy: 0.6984, val/total_loss: 0.6984, val/hateful_memes/accuracy: 0.6259, val/hateful_memes/binary_f1: 0.4229, val/hateful_memes/roc_auc: 0.6081, num_updates: 1500, epoch: 3, iterations: 1500, max_updates: 6000, val_time: 13s 256ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.608059\n",
            "\u001b[32m2022-12-12T09:23:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/6000, train/hateful_memes/cross_entropy: 0.5090, train/hateful_memes/cross_entropy/avg: 0.5803, train/total_loss: 0.5090, train/total_loss/avg: 0.5803, max mem: 5632.0, experiment: run, epoch: 3, num_updates: 1550, iterations: 1550, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 703ms, time_since_start: 04m 08s 479ms, eta: 10m 37s 185ms\n",
            "\u001b[32m2022-12-12T09:24:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/6000, train/hateful_memes/cross_entropy: 0.5090, train/hateful_memes/cross_entropy/avg: 0.5804, train/total_loss: 0.5090, train/total_loss/avg: 0.5804, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1600, iterations: 1600, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 241ms, time_since_start: 04m 14s 720ms, eta: 09m 46s 590ms\n",
            "\u001b[32m2022-12-12T09:24:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/6000, train/hateful_memes/cross_entropy: 0.4873, train/hateful_memes/cross_entropy/avg: 0.5776, train/total_loss: 0.4873, train/total_loss/avg: 0.5776, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1650, iterations: 1650, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 486ms, time_since_start: 04m 21s 207ms, eta: 10m 02s 724ms\n",
            "\u001b[32m2022-12-12T09:24:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/6000, train/hateful_memes/cross_entropy: 0.4873, train/hateful_memes/cross_entropy/avg: 0.5794, train/total_loss: 0.4873, train/total_loss/avg: 0.5794, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1700, iterations: 1700, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 283ms, time_since_start: 04m 27s 491ms, eta: 09m 37s 136ms\n",
            "\u001b[32m2022-12-12T09:24:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/6000, train/hateful_memes/cross_entropy: 0.4873, train/hateful_memes/cross_entropy/avg: 0.5799, train/total_loss: 0.4873, train/total_loss/avg: 0.5799, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1750, iterations: 1750, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 515ms, time_since_start: 04m 34s 006ms, eta: 09m 51s 446ms\n",
            "\u001b[32m2022-12-12T09:24:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/6000, train/hateful_memes/cross_entropy: 0.4873, train/hateful_memes/cross_entropy/avg: 0.5771, train/total_loss: 0.4873, train/total_loss/avg: 0.5771, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1800, iterations: 1800, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 246ms, time_since_start: 04m 40s 252ms, eta: 09m 20s 354ms\n",
            "\u001b[32m2022-12-12T09:24:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/6000, train/hateful_memes/cross_entropy: 0.4873, train/hateful_memes/cross_entropy/avg: 0.5734, train/total_loss: 0.4873, train/total_loss/avg: 0.5734, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1850, iterations: 1850, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 495ms, time_since_start: 04m 46s 747ms, eta: 09m 35s 765ms\n",
            "\u001b[32m2022-12-12T09:24:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/6000, train/hateful_memes/cross_entropy: 0.5090, train/hateful_memes/cross_entropy/avg: 0.5792, train/total_loss: 0.5090, train/total_loss/avg: 0.5792, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1900, iterations: 1900, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 282ms, time_since_start: 04m 53s 030ms, eta: 09m 10s 230ms\n",
            "\u001b[32m2022-12-12T09:24:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/6000, train/hateful_memes/cross_entropy: 0.5090, train/hateful_memes/cross_entropy/avg: 0.5730, train/total_loss: 0.5090, train/total_loss/avg: 0.5730, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 1950, iterations: 1950, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 468ms, time_since_start: 04m 59s 499ms, eta: 09m 19s 603ms\n",
            "\u001b[32m2022-12-12T09:24:53 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-12T09:24:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:24:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:24:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:24:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, train/hateful_memes/cross_entropy: 0.4873, train/hateful_memes/cross_entropy/avg: 0.5649, train/total_loss: 0.4873, train/total_loss/avg: 0.5649, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 2000, iterations: 2000, max_updates: 6000, lr: 0.00005, ups: 4.17, time: 12s 658ms, time_since_start: 05m 12s 157ms, eta: 18m 01s 541ms\n",
            "\u001b[32m2022-12-12T09:24:59 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:24:59 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:25:02 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:25:02 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:25:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:25:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:25:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:25:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/6000, val/hateful_memes/cross_entropy: 0.8945, val/total_loss: 0.8945, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.3464, val/hateful_memes/roc_auc: 0.6062, num_updates: 2000, epoch: 4, iterations: 2000, max_updates: 6000, val_time: 09s 131ms, best_update: 1500, best_iteration: 1500, best_val/hateful_memes/roc_auc: 0.608059\n",
            "\u001b[32m2022-12-12T09:25:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/6000, train/hateful_memes/cross_entropy: 0.4873, train/hateful_memes/cross_entropy/avg: 0.5626, train/total_loss: 0.4873, train/total_loss/avg: 0.5626, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 2050, iterations: 2050, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 739ms, time_since_start: 05m 28s 029ms, eta: 09m 28s 589ms\n",
            "\u001b[32m2022-12-12T09:25:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/6000, train/hateful_memes/cross_entropy: 0.4806, train/hateful_memes/cross_entropy/avg: 0.5581, train/total_loss: 0.4806, train/total_loss/avg: 0.5581, max mem: 5632.0, experiment: run, epoch: 4, num_updates: 2100, iterations: 2100, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 283ms, time_since_start: 05m 34s 312ms, eta: 08m 43s 400ms\n",
            "\u001b[32m2022-12-12T09:25:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/6000, train/hateful_memes/cross_entropy: 0.4806, train/hateful_memes/cross_entropy/avg: 0.5487, train/total_loss: 0.4806, train/total_loss/avg: 0.5487, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2150, iterations: 2150, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 390ms, time_since_start: 05m 40s 702ms, eta: 08m 45s 502ms\n",
            "\u001b[32m2022-12-12T09:25:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/6000, train/hateful_memes/cross_entropy: 0.4714, train/hateful_memes/cross_entropy/avg: 0.5456, train/total_loss: 0.4714, train/total_loss/avg: 0.5456, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2200, iterations: 2200, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 340ms, time_since_start: 05m 47s 042ms, eta: 08m 34s 614ms\n",
            "\u001b[32m2022-12-12T09:25:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/6000, train/hateful_memes/cross_entropy: 0.4373, train/hateful_memes/cross_entropy/avg: 0.5373, train/total_loss: 0.4373, train/total_loss/avg: 0.5373, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2250, iterations: 2250, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 461ms, time_since_start: 05m 53s 504ms, eta: 08m 37s 544ms\n",
            "\u001b[32m2022-12-12T09:25:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/6000, train/hateful_memes/cross_entropy: 0.4345, train/hateful_memes/cross_entropy/avg: 0.5351, train/total_loss: 0.4345, train/total_loss/avg: 0.5351, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2300, iterations: 2300, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 352ms, time_since_start: 05m 59s 856ms, eta: 08m 22s 017ms\n",
            "\u001b[32m2022-12-12T09:25:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/6000, train/hateful_memes/cross_entropy: 0.4345, train/hateful_memes/cross_entropy/avg: 0.5291, train/total_loss: 0.4345, train/total_loss/avg: 0.5291, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2350, iterations: 2350, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 425ms, time_since_start: 06m 06s 281ms, eta: 08m 20s 977ms\n",
            "\u001b[32m2022-12-12T09:25:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/6000, train/hateful_memes/cross_entropy: 0.4345, train/hateful_memes/cross_entropy/avg: 0.5207, train/total_loss: 0.4345, train/total_loss/avg: 0.5207, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2400, iterations: 2400, max_updates: 6000, lr: 0.00005, ups: 8.33, time: 06s 340ms, time_since_start: 06m 12s 622ms, eta: 08m 07s 550ms\n",
            "\u001b[32m2022-12-12T09:26:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/6000, train/hateful_memes/cross_entropy: 0.4154, train/hateful_memes/cross_entropy/avg: 0.5149, train/total_loss: 0.4154, train/total_loss/avg: 0.5149, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2450, iterations: 2450, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 520ms, time_since_start: 06m 19s 142ms, eta: 08m 14s 432ms\n",
            "\u001b[32m2022-12-12T09:26:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, train/hateful_memes/cross_entropy: 0.4345, train/hateful_memes/cross_entropy/avg: 0.5134, train/total_loss: 0.4345, train/total_loss/avg: 0.5134, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2500, iterations: 2500, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 403ms, time_since_start: 06m 25s 545ms, eta: 07m 58s 691ms\n",
            "\u001b[32m2022-12-12T09:26:12 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:26:12 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:26:15 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:26:15 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:26:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:26:18 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-12T09:26:24 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:26:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:26:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/6000, val/hateful_memes/cross_entropy: 0.8016, val/total_loss: 0.8016, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.4728, val/hateful_memes/roc_auc: 0.6484, num_updates: 2500, epoch: 5, iterations: 2500, max_updates: 6000, val_time: 14s 378ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.648426\n",
            "\u001b[32m2022-12-12T09:26:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/6000, train/hateful_memes/cross_entropy: 0.4114, train/hateful_memes/cross_entropy/avg: 0.5106, train/total_loss: 0.4114, train/total_loss/avg: 0.5106, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2550, iterations: 2550, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 661ms, time_since_start: 06m 46s 590ms, eta: 08m 10s 882ms\n",
            "\u001b[32m2022-12-12T09:26:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/6000, train/hateful_memes/cross_entropy: 0.4114, train/hateful_memes/cross_entropy/avg: 0.5093, train/total_loss: 0.4114, train/total_loss/avg: 0.5093, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2600, iterations: 2600, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 318ms, time_since_start: 06m 52s 908ms, eta: 07m 38s 853ms\n",
            "\u001b[32m2022-12-12T09:26:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/6000, train/hateful_memes/cross_entropy: 0.4114, train/hateful_memes/cross_entropy/avg: 0.5129, train/total_loss: 0.4114, train/total_loss/avg: 0.5129, max mem: 5632.0, experiment: run, epoch: 5, num_updates: 2650, iterations: 2650, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 448ms, time_since_start: 06m 59s 357ms, eta: 07m 41s 454ms\n",
            "\u001b[32m2022-12-12T09:26:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/6000, train/hateful_memes/cross_entropy: 0.3719, train/hateful_memes/cross_entropy/avg: 0.5045, train/total_loss: 0.3719, train/total_loss/avg: 0.5045, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 2700, iterations: 2700, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 250ms, time_since_start: 07m 05s 608ms, eta: 07m 20s 616ms\n",
            "\u001b[32m2022-12-12T09:26:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/6000, train/hateful_memes/cross_entropy: 0.3712, train/hateful_memes/cross_entropy/avg: 0.5013, train/total_loss: 0.3712, train/total_loss/avg: 0.5013, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 2750, iterations: 2750, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 582ms, time_since_start: 07m 12s 190ms, eta: 07m 36s 949ms\n",
            "\u001b[32m2022-12-12T09:27:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/6000, train/hateful_memes/cross_entropy: 0.3712, train/hateful_memes/cross_entropy/avg: 0.4992, train/total_loss: 0.3712, train/total_loss/avg: 0.4992, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 2800, iterations: 2800, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 410ms, time_since_start: 07m 18s 601ms, eta: 07m 18s 176ms\n",
            "\u001b[32m2022-12-12T09:27:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/6000, train/hateful_memes/cross_entropy: 0.3409, train/hateful_memes/cross_entropy/avg: 0.4944, train/total_loss: 0.3409, train/total_loss/avg: 0.4944, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 2850, iterations: 2850, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 639ms, time_since_start: 07m 25s 240ms, eta: 07m 26s 741ms\n",
            "\u001b[32m2022-12-12T09:27:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/6000, train/hateful_memes/cross_entropy: 0.3258, train/hateful_memes/cross_entropy/avg: 0.4879, train/total_loss: 0.3258, train/total_loss/avg: 0.4879, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 2900, iterations: 2900, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 293ms, time_since_start: 07m 31s 534ms, eta: 06m 56s 735ms\n",
            "\u001b[32m2022-12-12T09:27:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/6000, train/hateful_memes/cross_entropy: 0.2552, train/hateful_memes/cross_entropy/avg: 0.4826, train/total_loss: 0.2552, train/total_loss/avg: 0.4826, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 2950, iterations: 2950, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 476ms, time_since_start: 07m 38s 010ms, eta: 07m 01s 922ms\n",
            "\u001b[32m2022-12-12T09:27:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-12T09:27:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:27:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:27:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:27:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, train/hateful_memes/cross_entropy: 0.2552, train/hateful_memes/cross_entropy/avg: 0.4766, train/total_loss: 0.2552, train/total_loss/avg: 0.4766, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 3000, iterations: 3000, max_updates: 6000, lr: 0.00004, ups: 3.85, time: 13s 732ms, time_since_start: 07m 51s 742ms, eta: 14m 39s 949ms\n",
            "\u001b[32m2022-12-12T09:27:39 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:27:39 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:27:41 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:27:41 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:27:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:27:44 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:27:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:27:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/6000, val/hateful_memes/cross_entropy: 0.9238, val/total_loss: 0.9238, val/hateful_memes/accuracy: 0.6241, val/hateful_memes/binary_f1: 0.4345, val/hateful_memes/roc_auc: 0.6227, num_updates: 3000, epoch: 6, iterations: 3000, max_updates: 6000, val_time: 10s 433ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.648426\n",
            "\u001b[32m2022-12-12T09:27:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3050/6000, train/hateful_memes/cross_entropy: 0.2329, train/hateful_memes/cross_entropy/avg: 0.4717, train/total_loss: 0.2329, train/total_loss/avg: 0.4717, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 3050, iterations: 3050, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 775ms, time_since_start: 08m 08s 953ms, eta: 07m 06s 953ms\n",
            "\u001b[32m2022-12-12T09:28:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/6000, train/hateful_memes/cross_entropy: 0.2329, train/hateful_memes/cross_entropy/avg: 0.4697, train/total_loss: 0.2329, train/total_loss/avg: 0.4697, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 3100, iterations: 3100, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 285ms, time_since_start: 08m 15s 238ms, eta: 06m 29s 337ms\n",
            "\u001b[32m2022-12-12T09:28:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3150/6000, train/hateful_memes/cross_entropy: 0.2329, train/hateful_memes/cross_entropy/avg: 0.4652, train/total_loss: 0.2329, train/total_loss/avg: 0.4652, max mem: 5632.0, experiment: run, epoch: 6, num_updates: 3150, iterations: 3150, max_updates: 6000, lr: 0.00004, ups: 8.33, time: 06s 498ms, time_since_start: 08m 21s 737ms, eta: 06m 35s 598ms\n",
            "\u001b[32m2022-12-12T09:28:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/6000, train/hateful_memes/cross_entropy: 0.2228, train/hateful_memes/cross_entropy/avg: 0.4590, train/total_loss: 0.2228, train/total_loss/avg: 0.4590, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3200, iterations: 3200, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 162ms, time_since_start: 08m 27s 899ms, eta: 06m 08s 548ms\n",
            "\u001b[32m2022-12-12T09:28:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3250/6000, train/hateful_memes/cross_entropy: 0.2228, train/hateful_memes/cross_entropy/avg: 0.4541, train/total_loss: 0.2228, train/total_loss/avg: 0.4541, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3250, iterations: 3250, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 414ms, time_since_start: 08m 34s 313ms, eta: 06m 16s 760ms\n",
            "\u001b[32m2022-12-12T09:28:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/6000, train/hateful_memes/cross_entropy: 0.2228, train/hateful_memes/cross_entropy/avg: 0.4522, train/total_loss: 0.2228, train/total_loss/avg: 0.4522, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3300, iterations: 3300, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 427ms, time_since_start: 08m 40s 740ms, eta: 06m 10s 661ms\n",
            "\u001b[32m2022-12-12T09:28:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3350/6000, train/hateful_memes/cross_entropy: 0.1866, train/hateful_memes/cross_entropy/avg: 0.4463, train/total_loss: 0.1866, train/total_loss/avg: 0.4463, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3350, iterations: 3350, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 406ms, time_since_start: 08m 47s 147ms, eta: 06m 02s 660ms\n",
            "\u001b[32m2022-12-12T09:28:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/6000, train/hateful_memes/cross_entropy: 0.2228, train/hateful_memes/cross_entropy/avg: 0.4435, train/total_loss: 0.2228, train/total_loss/avg: 0.4435, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3400, iterations: 3400, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 453ms, time_since_start: 08m 53s 601ms, eta: 05m 58s 402ms\n",
            "\u001b[32m2022-12-12T09:28:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3450/6000, train/hateful_memes/cross_entropy: 0.1866, train/hateful_memes/cross_entropy/avg: 0.4386, train/total_loss: 0.1866, train/total_loss/avg: 0.4386, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3450, iterations: 3450, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 417ms, time_since_start: 09m 019ms, eta: 05m 49s 574ms\n",
            "\u001b[32m2022-12-12T09:28:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, train/hateful_memes/cross_entropy: 0.1809, train/hateful_memes/cross_entropy/avg: 0.4347, train/total_loss: 0.1809, train/total_loss/avg: 0.4347, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3500, iterations: 3500, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 408ms, time_since_start: 09m 06s 427ms, eta: 05m 42s 214ms\n",
            "\u001b[32m2022-12-12T09:28:53 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:28:53 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:28:56 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:28:56 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:28:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:28:59 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:29:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:29:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/6000, val/hateful_memes/cross_entropy: 1.1860, val/total_loss: 1.1860, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.4157, val/hateful_memes/roc_auc: 0.6271, num_updates: 3500, epoch: 7, iterations: 3500, max_updates: 6000, val_time: 09s 343ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.648426\n",
            "\u001b[32m2022-12-12T09:29:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3550/6000, train/hateful_memes/cross_entropy: 0.1809, train/hateful_memes/cross_entropy/avg: 0.4319, train/total_loss: 0.1809, train/total_loss/avg: 0.4319, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3550, iterations: 3550, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 746ms, time_since_start: 09m 22s 522ms, eta: 05m 53s 045ms\n",
            "\u001b[32m2022-12-12T09:29:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/6000, train/hateful_memes/cross_entropy: 0.1809, train/hateful_memes/cross_entropy/avg: 0.4288, train/total_loss: 0.1809, train/total_loss/avg: 0.4288, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3600, iterations: 3600, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 447ms, time_since_start: 09m 28s 969ms, eta: 05m 30s 507ms\n",
            "\u001b[32m2022-12-12T09:29:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3650/6000, train/hateful_memes/cross_entropy: 0.1788, train/hateful_memes/cross_entropy/avg: 0.4231, train/total_loss: 0.1788, train/total_loss/avg: 0.4231, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3650, iterations: 3650, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 405ms, time_since_start: 09m 35s 374ms, eta: 05m 21s 525ms\n",
            "\u001b[32m2022-12-12T09:29:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/6000, train/hateful_memes/cross_entropy: 0.1788, train/hateful_memes/cross_entropy/avg: 0.4189, train/total_loss: 0.1788, train/total_loss/avg: 0.4189, max mem: 5632.0, experiment: run, epoch: 7, num_updates: 3700, iterations: 3700, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 382ms, time_since_start: 09m 41s 756ms, eta: 05m 13s 537ms\n",
            "\u001b[32m2022-12-12T09:29:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3750/6000, train/hateful_memes/cross_entropy: 0.1788, train/hateful_memes/cross_entropy/avg: 0.4164, train/total_loss: 0.1788, train/total_loss/avg: 0.4164, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 3750, iterations: 3750, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 280ms, time_since_start: 09m 48s 037ms, eta: 05m 01s 829ms\n",
            "\u001b[32m2022-12-12T09:29:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/6000, train/hateful_memes/cross_entropy: 0.1715, train/hateful_memes/cross_entropy/avg: 0.4118, train/total_loss: 0.1715, train/total_loss/avg: 0.4118, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 3800, iterations: 3800, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 425ms, time_since_start: 09m 54s 462ms, eta: 05m 01s 944ms\n",
            "\u001b[32m2022-12-12T09:29:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3850/6000, train/hateful_memes/cross_entropy: 0.1389, train/hateful_memes/cross_entropy/avg: 0.4069, train/total_loss: 0.1389, train/total_loss/avg: 0.4069, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 3850, iterations: 3850, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 446ms, time_since_start: 10m 909ms, eta: 04m 56s 063ms\n",
            "\u001b[32m2022-12-12T09:29:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/6000, train/hateful_memes/cross_entropy: 0.1389, train/hateful_memes/cross_entropy/avg: 0.4018, train/total_loss: 0.1389, train/total_loss/avg: 0.4018, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 3900, iterations: 3900, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 386ms, time_since_start: 10m 07s 295ms, eta: 04m 46s 465ms\n",
            "\u001b[32m2022-12-12T09:30:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3950/6000, train/hateful_memes/cross_entropy: 0.1389, train/hateful_memes/cross_entropy/avg: 0.3985, train/total_loss: 0.1389, train/total_loss/avg: 0.3985, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 3950, iterations: 3950, max_updates: 6000, lr: 0.00003, ups: 8.33, time: 06s 376ms, time_since_start: 10m 13s 671ms, eta: 04m 39s 202ms\n",
            "\u001b[32m2022-12-12T09:30:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-12T09:30:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:30:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:30:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:30:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, train/hateful_memes/cross_entropy: 0.1389, train/hateful_memes/cross_entropy/avg: 0.3947, train/total_loss: 0.1389, train/total_loss/avg: 0.3947, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 4000, iterations: 4000, max_updates: 6000, lr: 0.00003, ups: 3.85, time: 13s 115ms, time_since_start: 10m 26s 787ms, eta: 09m 20s 303ms\n",
            "\u001b[32m2022-12-12T09:30:14 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:30:14 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:30:16 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:30:16 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:30:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:30:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:30:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:30:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/6000, val/hateful_memes/cross_entropy: 1.3664, val/total_loss: 1.3664, val/hateful_memes/accuracy: 0.6241, val/hateful_memes/binary_f1: 0.4781, val/hateful_memes/roc_auc: 0.6429, num_updates: 4000, epoch: 8, iterations: 4000, max_updates: 6000, val_time: 10s 635ms, best_update: 2500, best_iteration: 2500, best_val/hateful_memes/roc_auc: 0.648426\n",
            "\u001b[32m2022-12-12T09:30:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4050/6000, train/hateful_memes/cross_entropy: 0.1389, train/hateful_memes/cross_entropy/avg: 0.3935, train/total_loss: 0.1389, train/total_loss/avg: 0.3935, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 4050, iterations: 4050, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 641ms, time_since_start: 10m 44s 066ms, eta: 04m 36s 647ms\n",
            "\u001b[32m2022-12-12T09:30:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/6000, train/hateful_memes/cross_entropy: 0.1389, train/hateful_memes/cross_entropy/avg: 0.3914, train/total_loss: 0.1389, train/total_loss/avg: 0.3914, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 4100, iterations: 4100, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 394ms, time_since_start: 10m 50s 460ms, eta: 04m 19s 495ms\n",
            "\u001b[32m2022-12-12T09:30:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4150/6000, train/hateful_memes/cross_entropy: 0.1091, train/hateful_memes/cross_entropy/avg: 0.3874, train/total_loss: 0.1091, train/total_loss/avg: 0.3874, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 4150, iterations: 4150, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 376ms, time_since_start: 10m 56s 837ms, eta: 04m 11s 993ms\n",
            "\u001b[32m2022-12-12T09:30:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/6000, train/hateful_memes/cross_entropy: 0.1091, train/hateful_memes/cross_entropy/avg: 0.3834, train/total_loss: 0.1091, train/total_loss/avg: 0.3834, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 4200, iterations: 4200, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 313ms, time_since_start: 11m 03s 150ms, eta: 04m 02s 748ms\n",
            "\u001b[32m2022-12-12T09:30:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4250/6000, train/hateful_memes/cross_entropy: 0.1091, train/hateful_memes/cross_entropy/avg: 0.3804, train/total_loss: 0.1091, train/total_loss/avg: 0.3804, max mem: 5632.0, experiment: run, epoch: 8, num_updates: 4250, iterations: 4250, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 310ms, time_since_start: 11m 09s 461ms, eta: 03m 55s 873ms\n",
            "\u001b[32m2022-12-12T09:31:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/6000, train/hateful_memes/cross_entropy: 0.1043, train/hateful_memes/cross_entropy/avg: 0.3766, train/total_loss: 0.1043, train/total_loss/avg: 0.3766, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4300, iterations: 4300, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 284ms, time_since_start: 11m 15s 745ms, eta: 03m 48s 187ms\n",
            "\u001b[32m2022-12-12T09:31:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4350/6000, train/hateful_memes/cross_entropy: 0.1043, train/hateful_memes/cross_entropy/avg: 0.3724, train/total_loss: 0.1043, train/total_loss/avg: 0.3724, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4350, iterations: 4350, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 347ms, time_since_start: 11m 22s 093ms, eta: 03m 43s 727ms\n",
            "\u001b[32m2022-12-12T09:31:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/6000, train/hateful_memes/cross_entropy: 0.1043, train/hateful_memes/cross_entropy/avg: 0.3706, train/total_loss: 0.1043, train/total_loss/avg: 0.3706, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4400, iterations: 4400, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 352ms, time_since_start: 11m 28s 445ms, eta: 03m 37s 098ms\n",
            "\u001b[32m2022-12-12T09:31:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4450/6000, train/hateful_memes/cross_entropy: 0.1091, train/hateful_memes/cross_entropy/avg: 0.3682, train/total_loss: 0.1091, train/total_loss/avg: 0.3682, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4450, iterations: 4450, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 374ms, time_since_start: 11m 34s 819ms, eta: 03m 31s 037ms\n",
            "\u001b[32m2022-12-12T09:31:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, train/hateful_memes/cross_entropy: 0.0999, train/hateful_memes/cross_entropy/avg: 0.3643, train/total_loss: 0.0999, train/total_loss/avg: 0.3643, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4500, iterations: 4500, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 343ms, time_since_start: 11m 41s 162ms, eta: 03m 23s 233ms\n",
            "\u001b[32m2022-12-12T09:31:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:31:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:31:31 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:31:31 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:31:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:31:33 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-12-12T09:31:37 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:31:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:31:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, val/hateful_memes/cross_entropy: 1.8765, val/total_loss: 1.8765, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.4543, val/hateful_memes/roc_auc: 0.6546, num_updates: 4500, epoch: 9, iterations: 4500, max_updates: 6000, val_time: 13s 157ms, best_update: 4500, best_iteration: 4500, best_val/hateful_memes/roc_auc: 0.654629\n",
            "\u001b[32m2022-12-12T09:31:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4550/6000, train/hateful_memes/cross_entropy: 0.0637, train/hateful_memes/cross_entropy/avg: 0.3603, train/total_loss: 0.0637, train/total_loss/avg: 0.3603, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4550, iterations: 4550, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 669ms, time_since_start: 12m 994ms, eta: 03m 26s 572ms\n",
            "\u001b[32m2022-12-12T09:31:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/6000, train/hateful_memes/cross_entropy: 0.0637, train/hateful_memes/cross_entropy/avg: 0.3573, train/total_loss: 0.0637, train/total_loss/avg: 0.3573, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4600, iterations: 4600, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 318ms, time_since_start: 12m 07s 312ms, eta: 03m 08s 950ms\n",
            "\u001b[32m2022-12-12T09:32:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4650/6000, train/hateful_memes/cross_entropy: 0.0637, train/hateful_memes/cross_entropy/avg: 0.3537, train/total_loss: 0.0637, train/total_loss/avg: 0.3537, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4650, iterations: 4650, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 369ms, time_since_start: 12m 13s 682ms, eta: 03m 03s 672ms\n",
            "\u001b[32m2022-12-12T09:32:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/6000, train/hateful_memes/cross_entropy: 0.0590, train/hateful_memes/cross_entropy/avg: 0.3502, train/total_loss: 0.0590, train/total_loss/avg: 0.3502, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4700, iterations: 4700, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 418ms, time_since_start: 12m 20s 100ms, eta: 02m 58s 216ms\n",
            "\u001b[32m2022-12-12T09:32:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4750/6000, train/hateful_memes/cross_entropy: 0.0590, train/hateful_memes/cross_entropy/avg: 0.3474, train/total_loss: 0.0590, train/total_loss/avg: 0.3474, max mem: 5632.0, experiment: run, epoch: 9, num_updates: 4750, iterations: 4750, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 449ms, time_since_start: 12m 26s 550ms, eta: 02m 52s 201ms\n",
            "\u001b[32m2022-12-12T09:32:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/6000, train/hateful_memes/cross_entropy: 0.0520, train/hateful_memes/cross_entropy/avg: 0.3438, train/total_loss: 0.0520, train/total_loss/avg: 0.3438, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 4800, iterations: 4800, max_updates: 6000, lr: 0.00002, ups: 8.33, time: 06s 298ms, time_since_start: 12m 32s 848ms, eta: 02m 41s 451ms\n",
            "\u001b[32m2022-12-12T09:32:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4850/6000, train/hateful_memes/cross_entropy: 0.0520, train/hateful_memes/cross_entropy/avg: 0.3403, train/total_loss: 0.0520, train/total_loss/avg: 0.3403, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 4850, iterations: 4850, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 532ms, time_since_start: 12m 39s 381ms, eta: 02m 40s 468ms\n",
            "\u001b[32m2022-12-12T09:32:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/6000, train/hateful_memes/cross_entropy: 0.0520, train/hateful_memes/cross_entropy/avg: 0.3372, train/total_loss: 0.0520, train/total_loss/avg: 0.3372, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 4900, iterations: 4900, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 355ms, time_since_start: 12m 45s 736ms, eta: 02m 29s 324ms\n",
            "\u001b[32m2022-12-12T09:32:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4950/6000, train/hateful_memes/cross_entropy: 0.0492, train/hateful_memes/cross_entropy/avg: 0.3342, train/total_loss: 0.0492, train/total_loss/avg: 0.3342, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 4950, iterations: 4950, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 512ms, time_since_start: 12m 52s 249ms, eta: 02m 26s 070ms\n",
            "\u001b[32m2022-12-12T09:32:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-12T09:32:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:32:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:32:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:32:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, train/hateful_memes/cross_entropy: 0.0426, train/hateful_memes/cross_entropy/avg: 0.3309, train/total_loss: 0.0426, train/total_loss/avg: 0.3309, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 5000, iterations: 5000, max_updates: 6000, lr: 0.00001, ups: 3.33, time: 15s 328ms, time_since_start: 13m 07s 578ms, eta: 05m 27s 420ms\n",
            "\u001b[32m2022-12-12T09:32:54 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:32:54 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:32:57 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:32:57 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:32:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:33:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:33:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:33:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/6000, val/hateful_memes/cross_entropy: 2.2867, val/total_loss: 2.2867, val/hateful_memes/accuracy: 0.6593, val/hateful_memes/binary_f1: 0.4390, val/hateful_memes/roc_auc: 0.6516, num_updates: 5000, epoch: 10, iterations: 5000, max_updates: 6000, val_time: 10s 090ms, best_update: 4500, best_iteration: 4500, best_val/hateful_memes/roc_auc: 0.654629\n",
            "\u001b[32m2022-12-12T09:33:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5050/6000, train/hateful_memes/cross_entropy: 0.0426, train/hateful_memes/cross_entropy/avg: 0.3280, train/total_loss: 0.0426, train/total_loss/avg: 0.3280, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 5050, iterations: 5050, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 749ms, time_since_start: 13m 24s 420ms, eta: 02m 16s 968ms\n",
            "\u001b[32m2022-12-12T09:33:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/6000, train/hateful_memes/cross_entropy: 0.0426, train/hateful_memes/cross_entropy/avg: 0.3255, train/total_loss: 0.0426, train/total_loss/avg: 0.3255, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 5100, iterations: 5100, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 354ms, time_since_start: 13m 30s 775ms, eta: 02m 02s 161ms\n",
            "\u001b[32m2022-12-12T09:33:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5150/6000, train/hateful_memes/cross_entropy: 0.0384, train/hateful_memes/cross_entropy/avg: 0.3224, train/total_loss: 0.0384, train/total_loss/avg: 0.3224, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 5150, iterations: 5150, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 423ms, time_since_start: 13m 37s 198ms, eta: 01m 56s 626ms\n",
            "\u001b[32m2022-12-12T09:33:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/6000, train/hateful_memes/cross_entropy: 0.0261, train/hateful_memes/cross_entropy/avg: 0.3193, train/total_loss: 0.0261, train/total_loss/avg: 0.3193, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 5200, iterations: 5200, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 358ms, time_since_start: 13m 43s 557ms, eta: 01m 48s 659ms\n",
            "\u001b[32m2022-12-12T09:33:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5250/6000, train/hateful_memes/cross_entropy: 0.0243, train/hateful_memes/cross_entropy/avg: 0.3162, train/total_loss: 0.0243, train/total_loss/avg: 0.3162, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 5250, iterations: 5250, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 593ms, time_since_start: 13m 50s 150ms, eta: 01m 45s 622ms\n",
            "\u001b[32m2022-12-12T09:33:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/6000, train/hateful_memes/cross_entropy: 0.0192, train/hateful_memes/cross_entropy/avg: 0.3133, train/total_loss: 0.0192, train/total_loss/avg: 0.3133, max mem: 5632.0, experiment: run, epoch: 10, num_updates: 5300, iterations: 5300, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 366ms, time_since_start: 13m 56s 517ms, eta: 01m 35s 197ms\n",
            "\u001b[32m2022-12-12T09:33:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5350/6000, train/hateful_memes/cross_entropy: 0.0243, train/hateful_memes/cross_entropy/avg: 0.3106, train/total_loss: 0.0243, train/total_loss/avg: 0.3106, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5350, iterations: 5350, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 510ms, time_since_start: 14m 03s 028ms, eta: 01m 30s 397ms\n",
            "\u001b[32m2022-12-12T09:33:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/6000, train/hateful_memes/cross_entropy: 0.0192, train/hateful_memes/cross_entropy/avg: 0.3078, train/total_loss: 0.0192, train/total_loss/avg: 0.3078, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5400, iterations: 5400, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 295ms, time_since_start: 14m 09s 324ms, eta: 01m 20s 683ms\n",
            "\u001b[32m2022-12-12T09:34:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5450/6000, train/hateful_memes/cross_entropy: 0.0192, train/hateful_memes/cross_entropy/avg: 0.3053, train/total_loss: 0.0192, train/total_loss/avg: 0.3053, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5450, iterations: 5450, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 498ms, time_since_start: 14m 15s 822ms, eta: 01m 16s 340ms\n",
            "\u001b[32m2022-12-12T09:34:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, train/hateful_memes/cross_entropy: 0.0060, train/hateful_memes/cross_entropy/avg: 0.3025, train/total_loss: 0.0060, train/total_loss/avg: 0.3025, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5500, iterations: 5500, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 294ms, time_since_start: 14m 22s 116ms, eta: 01m 07s 220ms\n",
            "\u001b[32m2022-12-12T09:34:09 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:34:09 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:34:12 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:34:12 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:34:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:34:14 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:34:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:34:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/6000, val/hateful_memes/cross_entropy: 2.5969, val/total_loss: 2.5969, val/hateful_memes/accuracy: 0.6593, val/hateful_memes/binary_f1: 0.4321, val/hateful_memes/roc_auc: 0.6541, num_updates: 5500, epoch: 11, iterations: 5500, max_updates: 6000, val_time: 12s 205ms, best_update: 4500, best_iteration: 4500, best_val/hateful_memes/roc_auc: 0.654629\n",
            "\u001b[32m2022-12-12T09:34:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5550/6000, train/hateful_memes/cross_entropy: 0.0243, train/hateful_memes/cross_entropy/avg: 0.3022, train/total_loss: 0.0243, train/total_loss/avg: 0.3022, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5550, iterations: 5550, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 757ms, time_since_start: 14m 41s 084ms, eta: 01m 04s 953ms\n",
            "\u001b[32m2022-12-12T09:34:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/6000, train/hateful_memes/cross_entropy: 0.0243, train/hateful_memes/cross_entropy/avg: 0.2999, train/total_loss: 0.0243, train/total_loss/avg: 0.2999, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5600, iterations: 5600, max_updates: 6000, lr: 0.00001, ups: 8.33, time: 06s 333ms, time_since_start: 14m 47s 417ms, eta: 54s 113ms\n",
            "\u001b[32m2022-12-12T09:34:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5650/6000, train/hateful_memes/cross_entropy: 0.0060, train/hateful_memes/cross_entropy/avg: 0.2972, train/total_loss: 0.0060, train/total_loss/avg: 0.2972, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5650, iterations: 5650, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 549ms, time_since_start: 14m 53s 967ms, eta: 48s 962ms\n",
            "\u001b[32m2022-12-12T09:34:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/6000, train/hateful_memes/cross_entropy: 0.0046, train/hateful_memes/cross_entropy/avg: 0.2946, train/total_loss: 0.0046, train/total_loss/avg: 0.2946, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5700, iterations: 5700, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 302ms, time_since_start: 15m 269ms, eta: 40s 386ms\n",
            "\u001b[32m2022-12-12T09:34:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5750/6000, train/hateful_memes/cross_entropy: 0.0027, train/hateful_memes/cross_entropy/avg: 0.2920, train/total_loss: 0.0027, train/total_loss/avg: 0.2920, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5750, iterations: 5750, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 526ms, time_since_start: 15m 06s 795ms, eta: 34s 850ms\n",
            "\u001b[32m2022-12-12T09:35:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/6000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.2895, train/total_loss: 0.0007, train/total_loss/avg: 0.2895, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5800, iterations: 5800, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 293ms, time_since_start: 15m 13s 089ms, eta: 26s 887ms\n",
            "\u001b[32m2022-12-12T09:35:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5850/6000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.2870, train/total_loss: 0.0007, train/total_loss/avg: 0.2870, max mem: 5632.0, experiment: run, epoch: 11, num_updates: 5850, iterations: 5850, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 367ms, time_since_start: 15m 19s 457ms, eta: 20s 402ms\n",
            "\u001b[32m2022-12-12T09:35:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/6000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.2846, train/total_loss: 0.0007, train/total_loss/avg: 0.2846, max mem: 5632.0, experiment: run, epoch: 12, num_updates: 5900, iterations: 5900, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 417ms, time_since_start: 15m 25s 875ms, eta: 13s 708ms\n",
            "\u001b[32m2022-12-12T09:35:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5950/6000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.2822, train/total_loss: 0.0007, train/total_loss/avg: 0.2822, max mem: 5632.0, experiment: run, epoch: 12, num_updates: 5950, iterations: 5950, max_updates: 6000, lr: 0., ups: 8.33, time: 06s 527ms, time_since_start: 15m 32s 403ms, eta: 06s 971ms\n",
            "\u001b[32m2022-12-12T09:35:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-12-12T09:35:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:35:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:35:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:35:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.2799, train/total_loss: 0.0005, train/total_loss/avg: 0.2799, max mem: 5632.0, experiment: run, epoch: 12, num_updates: 6000, iterations: 6000, max_updates: 6000, lr: 0., ups: 3.57, time: 14s 215ms, time_since_start: 15m 46s 618ms, eta: 0ms\n",
            "\u001b[32m2022-12-12T09:35:33 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-12-12T09:35:33 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2022-12-12T09:35:36 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 34\n",
            "\u001b[32m2022-12-12T09:35:36 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:35:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2022-12-12T09:35:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-12-12T09:35:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-12-12T09:35:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/6000, val/hateful_memes/cross_entropy: 2.5808, val/total_loss: 2.5808, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.4308, val/hateful_memes/roc_auc: 0.6542, num_updates: 6000, epoch: 12, iterations: 6000, max_updates: 6000, val_time: 11s 633ms, best_update: 4500, best_iteration: 4500, best_val/hateful_memes/roc_auc: 0.654629\n",
            "\u001b[32m2022-12-12T09:35:45 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2022-12-12T09:35:45 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2022-12-12T09:35:45 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2022-12-12T09:35:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-12-12T09:35:46 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 4500\n",
            "\u001b[32m2022-12-12T09:35:46 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 4500\n",
            "\u001b[32m2022-12-12T09:35:46 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 9\n",
            "\u001b[32m2022-12-12T09:35:47 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-12-12T09:35:47 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 125/125 [00:12<00:00,  9.91it/s]\n",
            "\u001b[32m2022-12-12T09:35:59 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 125\n",
            "\u001b[32m2022-12-12T09:35:59 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-12-12T09:36:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/6000, test/hateful_memes/cross_entropy: 1.7632, test/total_loss: 1.7632, test/hateful_memes/accuracy: 0.6985, test/hateful_memes/binary_f1: 0.4937, test/hateful_memes/roc_auc: 0.6956\n",
            "\u001b[32m2022-12-12T09:36:00 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 16m 12s 755ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg6wtkCmz-8Y"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}