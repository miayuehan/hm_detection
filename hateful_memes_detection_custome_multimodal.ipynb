{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc9r6o2kP61oa+wJT5UZfu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jrjf_Y8RHio"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXZloXzlZi9z",
        "outputId": "154776d4-6ed2-40ce-c634-dff41b0f746c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AigB6fHDZAiV",
        "outputId": "7b20d7f1-934a-486b-b67b-478e991f41a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas_path in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.8/dist-packages (1.8.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.8/dist-packages (6.1.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from pandas_path) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas_path) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas_path) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas_path) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas_path) (1.15.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2022.11.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (21.3)\n",
            "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.4.2)\n",
            "Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2.5.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.6)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas_path pytorch-lightning transformers spacy ftfy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3QqMKzbVetD",
        "outputId": "447a9448-f2bd-455d-e62e-844bee9267b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (0.0.53)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sacremoses) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacremoses) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOgKinBlaErz",
        "outputId": "ab4947d9-2a03-46c3-be05-15f458e45428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas-path in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from pandas-path) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas-path) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas-path) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas-path) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-path) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas-path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3CXSbcxcLxf",
        "outputId": "ca3fdc79-2b5a-4499-f29c-dc0ced39f27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.3.0\n",
            "aeppl==0.0.33\n",
            "aesara==2.7.9\n",
            "aiohttp==3.8.3\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.12\n",
            "albumentations==1.2.1\n",
            "altair==4.2.0\n",
            "appdirs==1.4.4\n",
            "arviz==0.12.1\n",
            "astor==0.8.1\n",
            "astropy==4.3.1\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.2\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.1\n",
            "attrs==22.1.0\n",
            "audioread==3.0.0\n",
            "autograd==1.5\n",
            "Babel==2.11.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==5.0.1\n",
            "blis==0.7.9\n",
            "bokeh==2.3.3\n",
            "branca==0.6.0\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.11\n",
            "cachetools==5.2.0\n",
            "catalogue==2.0.8\n",
            "certifi==2022.9.24\n",
            "cffi==1.15.1\n",
            "cftime==1.6.2\n",
            "chardet==3.0.4\n",
            "charset-normalizer==2.1.1\n",
            "click==7.1.2\n",
            "clikit==0.6.2\n",
            "cloudpickle==1.5.0\n",
            "cmake==3.22.6\n",
            "cmdstanpy==1.0.8\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "confection==0.0.3\n",
            "cons==0.4.5\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.4.0\n",
            "crashtest==0.3.1\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda11x==11.0.0\n",
            "cvxopt==1.3.0\n",
            "cvxpy==1.2.2\n",
            "cycler==0.11.0\n",
            "cymem==2.0.7\n",
            "Cython==0.29.32\n",
            "daft==0.0.4\n",
            "dask==2022.2.1\n",
            "datascience==0.17.5\n",
            "db-dtypes==1.0.4\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.6\n",
            "distributed==2022.2.1\n",
            "dlib==19.24.0\n",
            "dm-tree==0.1.7\n",
            "dnspython==2.2.1\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.334\n",
            "easydict==1.10\n",
            "ecos==2.0.10\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl\n",
            "entrypoints==0.4\n",
            "ephem==4.1.3\n",
            "et-xmlfile==1.1.0\n",
            "etils==0.9.0\n",
            "etuples==0.3.8\n",
            "fa2==0.3.5\n",
            "fastai==2.7.10\n",
            "fastcore==1.5.27\n",
            "fastdownload==0.0.7\n",
            "fastdtw==0.3.4\n",
            "fastjsonschema==2.16.2\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.8.0\n",
            "firebase-admin==5.3.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.12.1.post1\n",
            "frozenlist==1.3.3\n",
            "fsspec==2022.11.0\n",
            "ftfy==6.1.1\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==4.4.0\n",
            "gensim==3.6.0\n",
            "geographiclib==1.52\n",
            "geopy==1.17.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==2.8.2\n",
            "google-api-python-client==1.12.11\n",
            "google-auth==2.15.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-cloud-bigquery==3.3.6\n",
            "google-cloud-bigquery-storage==2.16.2\n",
            "google-cloud-core==2.3.2\n",
            "google-cloud-datastore==2.9.0\n",
            "google-cloud-firestore==2.7.2\n",
            "google-cloud-language==2.6.1\n",
            "google-cloud-storage==2.5.0\n",
            "google-cloud-translate==3.8.4\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
            "google-crc32c==1.5.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.4.0\n",
            "googleapis-common-protos==1.57.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==2.0.1\n",
            "grpcio==1.51.1\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.2.4\n",
            "holidays==0.17.2\n",
            "holoviews==1.14.9\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httpstan==4.6.1\n",
            "huggingface-hub==0.11.1\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "idna==2.10\n",
            "imageio==2.9.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.8.1\n",
            "imblearn==0.0\n",
            "imgaug==0.4.0\n",
            "importlib-metadata==4.13.0\n",
            "importlib-resources==5.10.0\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "intel-openmp==2022.2.1\n",
            "intervaltree==2.1.0\n",
            "ipykernel==5.3.4\n",
            "ipython==7.9.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==1.1.0\n",
            "jax==0.3.25\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.25+cuda11.cudnn805-cp38-cp38-manylinux2014_x86_64.whl\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.2.0\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==4.3.3\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-core==5.1.0\n",
            "jupyterlab-widgets==3.0.3\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.7\n",
            "keras==2.9.0\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.4.4\n",
            "korean-lunar-calendar==0.3.1\n",
            "langcodes==3.3.0\n",
            "libclang==14.0.6\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "lightning-utilities==0.4.2\n",
            "llvmlite==0.39.1\n",
            "lmdb==0.99\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.5\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.9.1\n",
            "Markdown==3.4.1\n",
            "MarkupSafe==2.0.1\n",
            "marshmallow==3.19.0\n",
            "matplotlib==3.2.2\n",
            "matplotlib-venn==0.11.7\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.1\n",
            "mistune==0.8.4\n",
            "mizani==0.7.3\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==9.0.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.4\n",
            "multidict==6.0.3\n",
            "multipledispatch==0.6.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.9\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.7.0\n",
            "netCDF4==1.6.2\n",
            "networkx==2.8.8\n",
            "nibabel==3.0.2\n",
            "nltk==3.7\n",
            "notebook==5.7.16\n",
            "numba==0.56.4\n",
            "numexpr==2.8.4\n",
            "numpy==1.21.6\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.6.0.66\n",
            "opencv-python==4.6.0.66\n",
            "opencv-python-headless==4.6.0.66\n",
            "openpyxl==3.0.10\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==21.3\n",
            "palettable==3.3.0\n",
            "pandas==1.3.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.17.9\n",
            "pandas-path==0.3.0\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.5.0\n",
            "panel==0.12.1\n",
            "param==1.12.2\n",
            "parso==0.8.3\n",
            "partd==1.3.0\n",
            "pastel==0.2.1\n",
            "pathlib==1.0.1\n",
            "pathy==0.10.0\n",
            "patsy==0.5.3\n",
            "pep517==0.13.0\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==6.2.0\n",
            "platformdirs==2.5.4\n",
            "plotly==5.5.0\n",
            "plotnine==0.8.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.6.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.8\n",
            "prettytable==3.5.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.15.0\n",
            "promise==2.3\n",
            "prompt-toolkit==2.0.10\n",
            "prophet==1.1.1\n",
            "proto-plus==1.22.1\n",
            "protobuf==3.19.6\n",
            "psutil==5.4.8\n",
            "psycopg2==2.9.5\n",
            "ptyprocess==0.7.0\n",
            "py==1.11.0\n",
            "pyarrow==9.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.6\n",
            "pycparser==2.21\n",
            "pyct==0.4.8\n",
            "pydantic==1.10.2\n",
            "pydata-google-auth==1.4.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0.1\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pylev==1.4.0\n",
            "pymc==4.1.4\n",
            "PyMeeus==0.5.11\n",
            "pymongo==4.3.3\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.6\n",
            "pyparsing==3.0.9\n",
            "pyrsistent==0.19.2\n",
            "pysimdjson==3.2.0\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==3.3.0\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==7.0.0\n",
            "python-utils==3.4.5\n",
            "pytorch-lightning==1.8.4\n",
            "pytz==2022.6\n",
            "pyviz-comms==2.2.1\n",
            "PyWavelets==1.4.1\n",
            "PyYAML==6.0\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.5.post2\n",
            "qudida==0.0.4\n",
            "regex==2022.6.2\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.1\n",
            "resampy==0.4.2\n",
            "rpy2==3.5.5\n",
            "rsa==4.9\n",
            "sacremoses==0.0.53\n",
            "scikit-image==0.18.3\n",
            "scikit-learn==1.0.2\n",
            "scipy==1.7.3\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==3.2.2\n",
            "seaborn==0.11.2\n",
            "Send2Trash==1.8.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.8.5.post1\n",
            "six==1.15.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.2.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.11.0\n",
            "spacy==3.4.3\n",
            "spacy-legacy==3.0.10\n",
            "spacy-loggers==1.0.3\n",
            "Sphinx==1.8.6\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.44\n",
            "sqlparse==0.4.3\n",
            "srsly==2.4.5\n",
            "statsmodels==0.12.2\n",
            "sympy==1.7.1\n",
            "tables==3.7.0\n",
            "tabulate==0.8.10\n",
            "tblib==1.7.0\n",
            "tenacity==8.1.0\n",
            "tensorboard==2.9.1\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorboardX==2.5.1\n",
            "tensorflow==2.9.2\n",
            "tensorflow-datasets==4.6.0\n",
            "tensorflow-estimator==2.9.0\n",
            "tensorflow-gcs-config==2.9.1\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-io-gcs-filesystem==0.28.0\n",
            "tensorflow-metadata==1.11.0\n",
            "tensorflow-probability==0.17.0\n",
            "termcolor==2.1.1\n",
            "terminado==0.13.3\n",
            "testpath==0.6.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "thinc==8.1.5\n",
            "threadpoolctl==3.1.0\n",
            "tifffile==2022.10.10\n",
            "tokenizers==0.13.2\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch @ https://download.pytorch.org/whl/cu116/torch-1.13.0%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu116/torchaudio-0.13.0%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
            "torchmetrics==0.11.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.14.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu116/torchvision-0.14.0%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
            "tornado==6.0.4\n",
            "tqdm==4.64.1\n",
            "traitlets==5.6.0\n",
            "transformers==4.25.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typer==0.7.0\n",
            "typing-extensions==4.4.0\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.10.1\n",
            "wcwidth==0.2.5\n",
            "webargs==8.2.0\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.6.1\n",
            "wordcloud==1.8.2.2\n",
            "wrapt==1.14.1\n",
            "xarray==0.20.2\n",
            "xarray-einstats==0.3.0\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.2.0\n",
            "xlwt==1.3.0\n",
            "yarl==1.8.2\n",
            "yellowbrick==1.5\n",
            "zict==2.2.0\n",
            "zipp==3.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0lRzdFCZRhc"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "import tarfile\n",
        "import tempfile\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "import pandas_path  # Path style access for pandas\n",
        "import pytorch_lightning as pl\n",
        "import torch                    \n",
        "import torchvision\n",
        "from pandas_path import path\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbsCCkhcYCb0"
      },
      "source": [
        "**check gpu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoBnQs2gZTxv",
        "outputId": "a12fcb76-09ca-4acd-e6ea-913a5dc09f01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTHQqGnfMM4K",
        "outputId": "0fb7416f-0416-43f5-8e3b-3075106f56e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-65870b45-81ce-c2c0-8c7f-a4ad4da428bb)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vL8_uJwXxeS",
        "outputId": "2cf794c9-233b-4ad9-fe45-6380ef3533f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  9 07:48:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    31W /  70W |   7124MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKXJffNoYE0b"
      },
      "source": [
        "**check memory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuhRl54CX_R3",
        "outputId": "d018d1c1-0762-4fdc-9f2d-1cbf769e638f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgBzec7sbmJv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for the purposes of this post, we'll filter\n",
        "# much of the lovely logging info from our LightningModule\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger().setLevel(logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJA4Y6_6Zq7y",
        "outputId": "3dc5a1cd-7c40-41cc-d5ba-d38cd75b5d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DL7643/finalProject/hateful_memes\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/DL7643/finalProject/hateful_memes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RS70p3OQ3Tw",
        "outputId": "1c7c31e3-4b2f-48a3-fa13-0da5a413c73c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mhateful_memes\u001b[0m/     \u001b[01;34mimage_unimodal_outputs\u001b[0m/   \u001b[01;34mtext_unimodal_outputs\u001b[0m/\n",
            "hateful_memes.zip  \u001b[01;34mmodel-outputs\u001b[0m/\n",
            "\u001b[01;34mhm_example_mmf\u001b[0m/    \u001b[01;34mmulti_unimodals_outputs\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKaTi8FXbqSd",
        "outputId": "d4154b24-defe-40c8-abbf-ea382243f35f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DL7643/finalProject/hateful_memes/hateful_memes\n"
          ]
        }
      ],
      "source": [
        "data_dir = Path(\"/content/drive/MyDrive/DL7643/finalProject/hateful_memes/hateful_memes\")\n",
        "print(data_dir)\n",
        "\n",
        "train_path = data_dir / \"train.jsonl\"\n",
        "dev_path = data_dir / \"dev_seen.jsonl\"\n",
        "dev_unseen_path = data_dir / \"dev_unseen.jsonl\"\n",
        "test_path = data_dir / \"test_seen.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdCJYT7Hcu97",
        "outputId": "a2cc980c-9b18-4c37-ec8d-8514ba567e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DL7643/finalProject/hateful_memes/hateful_memes/dev_seen.jsonl\n"
          ]
        }
      ],
      "source": [
        "print(dev_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEdmt-lfRO7w"
      },
      "source": [
        "### **Build & Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUZ6i3rmcg12"
      },
      "outputs": [],
      "source": [
        "class HMDataset(torch.utils.data.Dataset):\n",
        "    # Data set preprocess\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_path,\n",
        "        image_path,\n",
        "        image_transform,\n",
        "        text_transform,\n",
        "        text_seq_max_length=100,\n",
        "        enforce_balance=False,\n",
        "        random_seed=0\n",
        "    ):\n",
        "\n",
        "        self.df = pd.read_json(\n",
        "            data_path, lines=True\n",
        "        )\n",
        "        self.dev_limit = dev_limit\n",
        "        if enforce_balance:\n",
        "            neg = self.df[\n",
        "                self.df.label.eq(0)\n",
        "            ]\n",
        "            pos = self.df[\n",
        "                self.df.label.eq(1)\n",
        "            ]\n",
        "            self.df = pd.concat(\n",
        "                [\n",
        "                    neg.sample(\n",
        "                        pos.shape[0], \n",
        "                        random_seed=random_seed\n",
        "                    ), \n",
        "                    pos\n",
        "                ]\n",
        "            )\n",
        "        self.df = self.df.reset_index(\n",
        "            drop=True\n",
        "        )\n",
        "        self.df.img = self.df.apply(\n",
        "            lambda row: (image_path / row.img), axis=1\n",
        "        )\n",
        "\n",
        "        if not self.df.img.path.exists().all():\n",
        "            raise FileNotFoundError\n",
        "        if not self.df.img.path.is_file().all():\n",
        "            raise TypeError\n",
        "            \n",
        "        self.image_transform = image_transform\n",
        "        self.text_transform = text_transform\n",
        "        self.text_seq_max_length = text_seq_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RlVIrescpz0"
      },
      "outputs": [],
      "source": [
        "class ModelConcat(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        loss_fn,\n",
        "        language_model,\n",
        "        image_model,\n",
        "        text_embedding_dimension,\n",
        "        image_embedding_dimension,\n",
        "        fusion_size,\n",
        "        dropout_p,\n",
        "        text_seq_max_length=30,\n",
        "    ):\n",
        "        super(ModelConcat, self).__init__()\n",
        "        self.language_model = language_model\n",
        "        self.image_model = image_model\n",
        "        inputs_size = self.language_model.config.hidden_size + image_embedding_dimension\n",
        "        self.fusion_layer = torch.nn.Linear(\n",
        "            in_features=inputs_size, \n",
        "            out_features=fusion_size\n",
        "        )\n",
        "        self.fc_layer = torch.nn.Linear(\n",
        "            in_features=fusion_size, \n",
        "            out_features=num_classes\n",
        "        )\n",
        "        self.loss_fn = loss_fn\n",
        "        self.dropout = torch.nn.Dropout(dropout_p)\n",
        "        \n",
        "    def forward(self, text, image, label=None):\n",
        "        lm_outputs = self.language_model(**text)\n",
        "        last_hidden_state = lm_outputs[0]\n",
        "        text_outputs = torch.squeeze(last_hidden_state[:,0,:])\n",
        "        text_embeddings = torch.nn.functional.tanh(\n",
        "            text_outputs\n",
        "        )\n",
        "        image_embeddings = torch.nn.functional.relu(\n",
        "            self.image_model(image)\n",
        "        )\n",
        "        concat_embeddings = torch.cat(\n",
        "            [text_embeddings, image_embeddings], dim=1\n",
        "        )\n",
        "        fuse_output = self.dropout(\n",
        "            torch.nn.functional.relu(\n",
        "            self.fusion_layer(concat_embeddings)\n",
        "            )\n",
        "        )\n",
        "        logits = self.fc_layer(fuse_output)\n",
        "        prediction = torch.nn.functional.softmax(logits)\n",
        "        loss = (\n",
        "            self.loss_fn(prediction, label) \n",
        "            if label is not None else label\n",
        "        )\n",
        "        return (prediction, loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAM3g-WsctDE"
      },
      "outputs": [],
      "source": [
        "class HMModel(pl.LightningModule):\n",
        "    def __init__(self, hyperparameters):\n",
        "        for data_key in [\"train_path\", \"dev_path\", \"image_path\",]:\n",
        "            if data_key not in hyperparameters.keys():\n",
        "                raise KeyError(\n",
        "                    f\"{data_key} is a required hyperparameters in this model\"\n",
        "                )\n",
        "        \n",
        "        super(HMModel, self).__init__()\n",
        "        self.hyperparameters = hyperparameters\n",
        "        \n",
        "        self.embedding_dim = self.hyperparameters.get(\"embedding_dim\", 128)\n",
        "        self.language_model_type = self.hyperparameters.get(\n",
        "            \"language_model_type\", \"bert-base-cased\"\n",
        "        )\n",
        "        self.image_model_type = self.hyperparameters.get(\n",
        "            \"image_model_type\", \"resnet152\"\n",
        "        )\n",
        "        self.image_model = self.fetch_image_model(self.image_model_type)\n",
        "        self.text_seq_max_length = self.hyperparameters.get(\n",
        "            \"text_seq_max_length\", 100\n",
        "        )\n",
        "        self.text_embedding_dimension = self.hyperparameters.get(\n",
        "            \"text_embedding_dimension\", 128\n",
        "        )\n",
        "        self.image_embedding_dimension = self.hyperparameters.get(\n",
        "            \"image_embedding_dimension\", self.text_embedding_dimension\n",
        "        )\n",
        "        self.output_path = Path(\n",
        "            self.hyperparameters.get(\"output_path\", \"model_output\")\n",
        "        )\n",
        "        self.output_path.mkdir(exist_ok=True)\n",
        "\n",
        "        self.text_transform = self.transform_text()\n",
        "        self.image_transform = self.transform_image()\n",
        "        self.training_dataset = self.create_dateset(\"train_path\")\n",
        "        self.dev_dataset = self.create_dateset(\"dev_path\")\n",
        "        \n",
        "        self.model = self.create_model()\n",
        "        self.trainer_parameters = self.fetch_trainer_parameters()\n",
        "    \n",
        "    def forward(self, text, image, label=None):\n",
        "        return self.model(text, image, label)\n",
        "\n",
        "    def seed(self, seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    def transform_text(self):\n",
        "        language_transform = AutoTokenizer.from_pretrained(self.language_model_type)\n",
        "        language_transform.add_special_tokens({ \"pad_token\": \"0\" })\n",
        "        return language_transform\n",
        "    \n",
        "    def transform_image(self):\n",
        "        image_dim = self.hyperparameters.get(\"image_dim\", 224)\n",
        "        image_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize(\n",
        "                    size=(image_dim, image_dim)\n",
        "                ),        \n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize(\n",
        "                    mean=(0.485, 0.456, 0.406), \n",
        "                    std=(0.229, 0.224, 0.225)\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        return image_transform\n",
        "\n",
        "    def create_dateset(self, dataset_key):\n",
        "        return HMDataset(\n",
        "            data_path=self.hyperparameters.get(dataset_key, dataset_key),\n",
        "            image_path=self.hyperparameters.get(\"image_path\"),\n",
        "            image_transform=self.image_transform,\n",
        "            text_transform=self.text_transform,\n",
        "            text_seq_max_length=self.text_seq_max_length,\n",
        "            enforce_balance=True if \"train\" in str(dataset_key) else False\n",
        "        )\n",
        "\n",
        "    def fetch_image_model(self, model_name):\n",
        "        image_model_map = {\n",
        "            \"alexnet\" : torchvision.models.alexnet,\n",
        "            \"densenet161\" : torchvision.models.densenet161,\n",
        "            \"resnet152\" : torchvision.models.resnet152,\n",
        "            \"resnext101_32x8d\" : torchvision.models.resnext101_32x8d,\n",
        "            \"shufflenet_v2_x2_0\" : torchvision.models.shufflenet_v2_x2_0,\n",
        "            \"vgg19_bn\" : torchvision.models.vgg19_bn,\n",
        "            \"wide_resnet50_2\" : torchvision.models.wide_resnet50_2,\n",
        "            \"wide_resnet101_2\" : torchvision.models.wide_resnet101_2,\n",
        "        }\n",
        "        return image_model_map.get(model_name)\n",
        "    \n",
        "    def create_model(self):\n",
        "        language_model = AutoModel.from_pretrained(self.language_model_type)\n",
        "        image_model = self.image_model(\n",
        "            pretrained=True\n",
        "        )\n",
        "        image_model.fc = torch.nn.Linear(\n",
        "                in_features=2048,\n",
        "                out_features=self.image_embedding_dimension\n",
        "        )\n",
        "\n",
        "        return ModelConcat(\n",
        "            num_classes=self.hyperparameters.get(\"num_classes\", 2),\n",
        "            loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "            language_model=language_model,\n",
        "            image_model=image_model,\n",
        "            text_embedding_dimension=self.text_embedding_dimension,\n",
        "            image_embedding_dimension=self.image_embedding_dimension,\n",
        "            fusion_size=self.hyperparameters.get(\n",
        "                \"fusion_size\", 512\n",
        "            ),\n",
        "            dropout_p=self.hyperparameters.get(\"dropout_p\", 0.1),\n",
        "            text_seq_max_length=self.text_seq_max_length\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        predictions, loss = self.forward(\n",
        "            text=batch[\"text\"], \n",
        "            image=batch[\"image\"], \n",
        "            label=batch[\"label\"]\n",
        "        )\n",
        "        \n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        predictions, loss = self.eval().forward(\n",
        "            text=batch[\"text\"], \n",
        "            image=batch[\"image\"], \n",
        "            label=batch[\"label\"]\n",
        "        )\n",
        "        \n",
        "        return {\"batch_val_loss\": loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack(\n",
        "            tuple(\n",
        "                output[\"batch_val_loss\"] \n",
        "                for output in outputs\n",
        "            )\n",
        "        ).mean()\n",
        "        self.log(\"avg_val_loss\", avg_loss)\n",
        "        \n",
        "        return {\n",
        "            \"val_loss\": avg_loss,\n",
        "            \"progress_bar\":{\"avg_val_loss\": avg_loss}\n",
        "        }\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizers = [\n",
        "            torch.optim.AdamW(\n",
        "                self.model.parameters(), \n",
        "                lr=self.hyperparameters.get(\"lr\", 0.001)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        scheduler = {\n",
        "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizers[0]\n",
        "            ),\n",
        "            'reduce_on_plateau': True,\n",
        "            'monitor': 'avg_val_loss'\n",
        "        }\n",
        "\n",
        "        schedulers = [ scheduler ]\n",
        "        return optimizers, schedulers\n",
        "    \n",
        "    def train_dataloader(self):        \n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.training_dataset, \n",
        "            shuffle=True, \n",
        "            batch_size=self.hyperparameters.get(\"batch_size\", 5), \n",
        "            num_workers=self.hyperparameters.get(\"num_workers\", 20)\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.dev_dataset, \n",
        "            shuffle=False, \n",
        "            batch_size=self.hyperparameters.get(\"batch_size\", 5), \n",
        "            num_workers=self.hyperparameters.get(\"num_workers\", 20)\n",
        "        )\n",
        "    \n",
        "    def fit(self):\n",
        "        self.seed(self.hyperparameters.get(\"random_seed\", 101))\n",
        "        self.trainer = pl.Trainer(**self.trainer_parameters)\n",
        "        self.trainer.fit(self)\n",
        "    \n",
        "    def fetch_trainer_parameters(self):\n",
        "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "            dirpath=self.output_path,\n",
        "            monitor=self.hyperparameters.get(\n",
        "                \"checkpoint_monitor\", \"avg_val_loss\"\n",
        "            ),\n",
        "            mode=self.hyperparameters.get(\n",
        "                \"checkpoint_monitor_mode\", \"min\"\n",
        "            ),\n",
        "            verbose=self.hyperparameters.get(\"verbose\", True)\n",
        "        )\n",
        "\n",
        "        early_stop_callback = pl.callbacks.EarlyStopping(\n",
        "            monitor=self.hyperparameters.get(\n",
        "                \"early_stop_monitor\", \"avg_val_loss\"\n",
        "            ),\n",
        "            min_delta=self.hyperparameters.get(\n",
        "                \"early_stop_min_delta\", 0.001\n",
        "            ),\n",
        "            patience=self.hyperparameters.get(\n",
        "                \"early_stop_patience\", 3\n",
        "            ),\n",
        "            verbose=self.hyperparameters.get(\"verbose\", True),\n",
        "        )\n",
        "\n",
        "        trainer_parameters = {\n",
        "            \"enable_checkpointing\": True,\n",
        "            \"callbacks\": [checkpoint_callback, early_stop_callback],\n",
        "            \"default_root_dir\": self.output_path,\n",
        "            \"accumulate_grad_batches\": self.hyperparameters.get(\n",
        "                \"accumulate_grad_batches\", 1\n",
        "            ),\n",
        "            \"auto_select_gpus\": self.hyperparameters.get(\"auto_select_gpus\", False),\n",
        "            \"devices\": self.hyperparameters.get(\"devices\", 1),\n",
        "            \"accelerator\": self.hyperparameters.get(\"accelerator\", \"cpu\"),\n",
        "            \"max_epochs\": self.hyperparameters.get(\"max_epochs\", 100),\n",
        "            \"gradient_clip_val\": self.hyperparameters.get(\n",
        "                \"gradient_clip_value\", 1\n",
        "            )\n",
        "        }\n",
        "        return trainer_parameters\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_accuracy(self, test_path):\n",
        "        testing_data = self.create_dateset(test_path)\n",
        "        data_frame = pd.DataFrame(\n",
        "            index=testing_data.df.id,\n",
        "            columns=[\"proba\", \"label\", \"target\"]\n",
        "        )\n",
        "        test_dataloader = torch.utils.data.DataLoader(\n",
        "            testing_data, \n",
        "            shuffle=False, \n",
        "            batch_size=self.hyperparameters.get(\"batch_size\", 4), \n",
        "            num_workers=self.hyperparameters.get(\"num_workers\", 16))\n",
        "        for batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
        "            predictions, _ = self.model.eval().to(\"cpu\")(\n",
        "                batch[\"text\"], batch[\"image\"]\n",
        "            )\n",
        "            data_frame.loc[batch[\"id\"], \"proba\"] = predictions[:, 1]\n",
        "            data_frame.loc[batch[\"id\"], \"label\"] = predictions.argmax(dim=1)\n",
        "            data_frame.loc[batch[\"id\"], \"target\"] = batch[\"label\"]\n",
        "        data_frame.proba = data_frame.proba.astype(float)        \n",
        "        data_frame.label = data_frame.label.astype(int)\n",
        "        data_frame.target = data_frame.target.astype(int)\n",
        "        return data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2ZFp3x6cxZW"
      },
      "outputs": [],
      "source": [
        "def gen_accuracy(language_model_type, image_model_type):\n",
        "    print(language_model_type, image_model_type)\n",
        "    hyperparameters = {\n",
        "        # Required hyperparameters\n",
        "        \"train_path\": train_path,\n",
        "        \"dev_path\": dev_path,\n",
        "        \"image_path\": data_dir,\n",
        "        \n",
        "        # Optional hyperparameters\n",
        "        \"embedding_dim\": 150,\n",
        "        \"language_model_type\": language_model_type,\n",
        "        \"image_model_type\": image_model_type,\n",
        "        \"text_seq_max_length\": 32,\n",
        "        \"text_embedding_dimension\": 300,\n",
        "        \"image_embedding_dimension\": 300,\n",
        "        \"fusion_size\": 256,\n",
        "        \"output_path\": \"model_output\",\n",
        "        \"dev_limit\": None,\n",
        "        \"lr\": 0.00005,\n",
        "        \"max_epochs\": 10,\n",
        "        \"devices\": 1,\n",
        "        \"accelerator\": \"gpu\",\n",
        "        # \"auto_select_gpus\": True,\n",
        "        # \"n_gpu\": 100,\n",
        "        \"batch_size\": 4,\n",
        "        # allows us to \"simulate\" having larger batches \n",
        "        \"accumulate_grad_batches\": 16,\n",
        "        \"early_stop_patience\": 5,\n",
        "    }\n",
        "    hateful_memes_model = HMModel(hyperparameters=hyperparameters)\n",
        "    hateful_memes_model.fit()\n",
        "    \n",
        "    checkpoints = glob(os.path.join(\"model_output\", \"*.ckpt\"))    \n",
        "    print(checkpoints)\n",
        "    hateful_memes_model_best = HMModel.load_from_checkpoint(\n",
        "        checkpoints[-1],\n",
        "        hyperparameters=hyperparameters\n",
        "    )\n",
        "    accuracy_eval = hateful_memes_model_best.eval_accuracy(\n",
        "        dev_unseen_path\n",
        "    )\n",
        "    acc = accuracy_eval[\"target\"] == accuracy_eval[\"label\"]\n",
        "    accuracy = acc[acc == True].count()/acc.count()\n",
        "    auc_roc = roc_auc_score(accuracy_eval[\"label\"], accuracy_eval[\"target\"])\n",
        "    f1 = f1_score(accuracy_eval[\"label\"], accuracy_eval[\"target\"])\n",
        "\n",
        "    return accuracy_eval, accuracy, auc_roc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f0123f9df9294c71b2c2854129afb930",
            "a916e4283d4a4929b970b936c5a913dc",
            "a018cc1ad80e42439f22cf2b96b230b3",
            "4c061b30dcce4cc1bc8acc96c4d8c5a7",
            "536c483b8c3046a4a17f31408186c5e9",
            "5840675297c04bf19745403bd1abda5a",
            "17bfa3801cba47b3829a95a371e06104",
            "1e12748a43264b56ad2afae89ec45e2f",
            "ead4238679d64bd9bade68dc7bfcd7b6",
            "08919b9bbc4849f9a570d15962f52b0d",
            "1d592d6b2b2f4bcb95d7198f01ad1c49",
            "2c8eb553ab9545edbf99c41d3e18a0ae",
            "f3b1a96989f4416c82578c453574d6cf",
            "d5a2e33e807448d7a627f49f304e5536",
            "562d6a6cec1841fb9f109a09098c1dff",
            "0e484227e51847c4b48f9ccbf876a3c9",
            "00ff514ae6814a378c9566645adf6748",
            "def5171e797e4fa9b536927065596e00",
            "d7f56e915bd146b1b7de54983068daee",
            "0c7c09a274da4e689e192e8eee3e1677",
            "17e24102050144b69aad9bc7b32195e0",
            "97c2a382a46f44b3a8e42345c0fb4321",
            "75f6f601246c4bfe98ed3bcb4202eb03",
            "417f318eb3694553b7dfae24f7293ba1",
            "dd940fcfd4504b7e919cd5423df911d4",
            "f289395b8be8484fa5676e3b1ae98886",
            "123eaaf2deb4446c9bd5152dea4de319",
            "b5440071aaed4a418f10f3b102a032e9",
            "65d5f92d4b884a6082d7c76afd939e05",
            "68faaf184d9742379fa895a2d1436f47",
            "80f2964693614280967605d7ce48a402",
            "5181ac26a9494ec3a8fae8275a627bbc",
            "b8557753ffa44a328ea6afd061b71f86",
            "13d7d76ba02649eea06b87cc7e13e2fb",
            "22af582e53604c0197c4e55877828042",
            "acc76552d1d44bf9a148420611797323",
            "37ede65e07a3480aac0d7602d95188e0",
            "d23317de7b644d1a8c7996893259eb38",
            "b8891e3ce22c4c25852de559ded11929",
            "361404b5366543999bf6f6558cd32871",
            "a9617716c41949ebb8a787b8068efb25",
            "7280db3c05f84cb49d8c47197b28a5a6",
            "df140570de194c0f82daf9d105c91b5a",
            "64ceb605b8814c6e9445e8a99541cda9",
            "a9aae00dc3bb406eb4a039b83675b490",
            "0eb80f42310c4edcacef59f24f63950a",
            "7665a42c372043d99a456f742ea8e7ee",
            "2fd7b9460a30431195a4733b0703098a",
            "31404e0c62474208a898121580a1e455",
            "263de19e09084dff8d5aae807a036924",
            "7f8f21c79fcc4a1b9db633210b5bec76",
            "c53577e44f474efe984e3bd5f21a0188",
            "6bd8649a66bc43f99ce21d42aee7b751",
            "81a82a0bfe4a4681aee306bf9dc23650",
            "98cf49f1c7964c38b41c5ef667f27967",
            "3c76dee992474bd7bbaf56d10be52cf7",
            "0f7cc21652d0400ab37244e8d6fb282a",
            "907ae3cf62594e43bac5ce7644f96740",
            "1bb61df668c34970b93eb513d7e3d397",
            "a0f1391921f0431796865f4c90f9e1c2",
            "948407c1e73742bd99d40376f087f769",
            "f7e389ff9c264b318b6b0b5ea5b1a8b6",
            "1bb1b63c4113472291f9ad7cf95d0a97",
            "19310459032a482fb3427d4c83aa5949",
            "ae23ced17fbe46e989861e9d1482bd64",
            "5334e93de4774c49bafff69ec9e3d8ce",
            "1f7dde1abd8b45fea2137a1637ec1c10",
            "777ae614e1984e5eba4ab23259b4ad44",
            "1cec5f9d85c14b49933ed9b90925d9df",
            "d1ba42ddb26343a2a1ad156910e79a8f",
            "955b0a7f67e4462c844b2f944e68bd6a",
            "02277fc70ad74eee80ca554aad3cb0d6",
            "ae0a401657c34d7bafb6c924a559fb90",
            "cdbbb9bbb20d44739e3c9989bb26e528",
            "f6b7ddfe0b194cb4847ddd23fe305613",
            "13039781239946fd96faf2496da536b9",
            "48582daa7ebb4a63b2168d357a385ba7",
            "83a5862884d34d4083b85bd5b5adb7d5",
            "76bead8dd85c4926aa5a62b249373d50",
            "dca5873197ce4e46951cb45bc915a7c8",
            "8ca415d44a3a4a129e2c28c295a113aa",
            "2c0c20f5e7fd40d4a50ddeab3339e234",
            "e3fb8293c58845f3b0dd1b77ec6d9603",
            "c24d9fa5ca7d44879c8c8371f1ba0862",
            "ec7d370fbf024b689998a38f14fd9932",
            "72e38c2e1f9f4672a7fcee522660cf31",
            "31eb91c65ae74c6bac70ab586a983892",
            "940bbdf7ff54421a88361cbb744377d9",
            "3868ff1a2ef54350ba416587a26099b7",
            "9779c5d6cd924c31bd7a2ee881fa6ab0",
            "56c63222ea2946edb4a50c7699c9b30b",
            "236979029bf2482f8f7d406d763138f6",
            "b3c03e493a964a229af3d84a2b1927ce",
            "2e27f3137a3d4197971e8a182fc86730",
            "6cbdc2a9524a4c51a812377ff6ebc1ab",
            "c2724da9374147d6aed8d80993299d28",
            "349a72542bcb44e9bbfc679f988dfb34",
            "b87ecaf3bdf243799974a94b34f385d8",
            "e668ebc685bf43c48c12f971c32aab8b",
            "37da314f7b424978aaff7cb28c573bf6",
            "f34c60f5599d41dead3e0905b8db1c32",
            "7afc07448c094876bec4b8c8fe2d435e",
            "b5320d35401541a391882e9e1ad5eb4d",
            "83b1ae099cc0474b99915ed7774778f1",
            "e6e8230a694249ce8ee02e31f6c17ace",
            "31a4c23d44dc4b4fa3c69891f855313c",
            "31bc8e55f89843b3bc01499b935086b5",
            "04ca29ee08ef426e9cc152e97bf2ab9c",
            "89d369dfbc134930aa03bbe44092d1d1",
            "b95c1c7b3da949e78ba5df277da1a4b3",
            "52b0e7f840454e4893fc49ec88937b3f",
            "38c08bf58bd54d71a9041954bdf6fda9",
            "87b38991322149ef85140f4c4d7d9cdb",
            "931e8b7dd9b54f7d92cb2170936dae28",
            "ebccf8c8df9d4ef2bd67267ad8fbe09a",
            "9a2df960ebbd457e91e4d00ea53100e2",
            "aac4689bb8d244a590d6f968d11aabd4",
            "b7821bee92784d72a75f533c62d4adc0",
            "fe61b6cdd17d4c43a37711195064813d",
            "c78ece4a4b864784ad9da1dad54d7b81",
            "f2ad00c5524443faac44fe7cd062871a",
            "70fcf96d3c044219921f62a7d7d229a4",
            "bddd63e8773146b797ea47952eeab829",
            "9f6e9c79487b4eb8b732c3b7c2f578ae",
            "2e4cd96433914ace9dee768b062e2a6a",
            "d56eefe8523245988501424323ce64fd",
            "c6c1f6ce54aa498ba2eb8e86d3e92d3d",
            "f1fd755be71f479bb18cba5204fff97c",
            "58cf050e5f4b45188cc82a3dfb45ad2b",
            "d6dc7cb6f7684fb48f4623a48c3bf6a7",
            "bd41f8ab807c45d3a5d56d2b8893c349",
            "fb5f69cb57e14a1b9ef51ba63199a134",
            "3b67055096ea489bb1dbe724835107b6",
            "09db30cb99be45308fe054088f13f36c",
            "ff9c7f365d6042e49d651257d14ee8b7",
            "10d0289887c84ea1b282306b5bfdf7be",
            "4a386f8c8e27406390ffee0696d67bbf",
            "fa5204b723f849bf881b7d0e68662041",
            "1996c0bafab64d918cdc9ac10734e3aa",
            "a0eae0503c794a8fb8d794360023eba2",
            "2c0ed5081a6144e2a9405b57b8604f6f",
            "15d20df1ce3f4d73a4ed2ea9d0085396",
            "a269c948bc1f439192740c26e10c8bd9",
            "76c5844c939d47fdb1247325341bb624",
            "603fefaa1bf347929e1936d933ce20ae",
            "ae5330172d7040af9198ac3c9f66a53d",
            "14ee70e650284d9aad7f1bbb2188cace",
            "a26b85ba71e7410f9cc295c49fa3cd4c",
            "f35276a5954d40908e9fd0e098d9a4b4",
            "42aa1fa6ded54238840f09ddf08af1f4",
            "d1391b69b11044a2a2cc3b0200686ccf",
            "b5f0a5014ee54a0fa3cf76357f1e9aa5",
            "e73436031dcd482d9db85c5979b1c63b",
            "2ed5ed862caa4bc98971225fcc257b45",
            "ba3a99ce853b4167b0ef512132f4b11d",
            "b907ed1cd69a406ca609c883edddbe1d",
            "a02f7ca070f6430aa394fb74655254a9",
            "e316d1fb17a84b34b6b968a028cc33fd",
            "da9439683aea4637a02c5cc8d5e594ee",
            "8aa1c1449a78489db9ba7578229008f1",
            "b988e538f2184a358ce401f5b2820efc",
            "8255b46bb7cc4507b8880422959db99c",
            "184c788951da4062ab3bf71a1ab4dd9f",
            "dad8943b0cf84da0be32386fa44b0e0f",
            "81cf73988d7249f5839cc053b9df26d1",
            "edf2ee75d9764b94a8e0824faa9bb587",
            "934bd56c50744ddcbe67db6ab35c8ac1",
            "ed5a656345954cdfad6ad5a13e2d5819",
            "d2ea1ce60e3e4070af24e1b96ee4b0d6",
            "8b17627aad244e8885499d9ab8d159d9",
            "d60c07322bf147748a4752d21a95e508",
            "732ff1c800f448b2ac16757fd041a80d",
            "8fa80b6fb0eb4223ad68bea690b8d9ab",
            "d9daa27b161b46f58daf7e83e1e659e2",
            "9db4119e4b744707b8b8c1933e82efff",
            "3d59fe30179d439c9ee51cd872402536",
            "1ec5523308194e1bbe60d506053bfafa",
            "7f72a3346a3c4dd6a83e203b8ad13ea4",
            "d2a9f848b06c43f08a9a664a13cbe1f3",
            "2730114d87b041adb63270a150d23285",
            "1e83cca1d2b4418ab155f19485b680ef",
            "cc0ea0b632254598914d096baa5bc3ef",
            "a3d16fba95694906836728ec53c3ead9",
            "29716123fed84fca86e5a815e3176a0f",
            "a4880042ac174efcbfd248f0f3c8b5eb",
            "4003c831b6204b219f5bbab8ed62e784",
            "31782d8efe1446ff9bab2e6d32bd48df",
            "b19e6c9a3cda496fb27305f6bbb052f3",
            "c2dede7f467b4d91b943cffb6b351f03",
            "9c1ee8f7b1eb43cd94e50f04fa003ef5",
            "620d2e9d3e0347b89ff96349ace9db81",
            "e5a25661c14f44ca9c3925a296d95f56",
            "4860a620b1934945ba221d840f1d123e",
            "a47765dcf3124c41a41fc14b8020d1f8",
            "7ef1e47902db4c4f8bf9f577e8c5ddc5",
            "5345707c329c4919aca732f137eac298",
            "27abf831af204a65a8db437d7b07dd2c",
            "c5853325d4ce469891553a97a5070a03",
            "3b65efefb1634749b9f388b3b1f0e1b7",
            "0283041ab1e44e75aeee9785066e919e",
            "2278fedf1c6448009b40c910920904f6",
            "74e97035774749d39280e213fa47149d",
            "8da82c6bd9184014be2233a6823cb659",
            "072b1d34ddd3488bb55492f8bd7a92c4",
            "125ba9a42b724a5994b4cf20d34e6ddf",
            "2529eb66236746099186bf5f733b91f7",
            "6bbdb4496cf24fc5953de9a8396ffba3",
            "3c1a68295efe4c9a9b5263fdc6b786e8",
            "4bf4ceed66904eedb223546166b4dae8",
            "b149a66f253c4074a37df90e7e91ac8f",
            "d96bd5778f1b45f58147ec31df924ea1",
            "176d3fb58d444cada70efd43fbb22b64",
            "23505a08588643dbaea5427f09c1407c",
            "36af08d6b3e249dd83228e80c2e553ba",
            "090227f6b891470a93cb4642b6d3e1cf",
            "425b040bcc3149a5a6fccf72daa797f6",
            "c525819ea1734840ae1f4e4ce6251aa9",
            "230ff57c757b4025984386d221749a59",
            "eb346047619540cd81393e1ae9bdcf6f",
            "243c71f490754080b890646e6aa47b86",
            "6498cce989484dfca53ffd8fc044b64f",
            "a806f9ab637549448f1030fe94d5b577",
            "382eacdb6c7a45e29f9e83baec28db52",
            "c1a3c4e6679444bfb5a806d037c04879",
            "d210703ca9f0449eaafdd073d7180aaf",
            "bbf71a76031742c88c267df485e44c5e",
            "cbfa9b36de4c4462aa4ee0bb37e276d6",
            "0d98afa7da104cbf9a5e849e2d0984a6",
            "c72182ffb0774ff4b7505473366d215f",
            "ba536402b7db438dabfe97127a32e33b",
            "4c4417d3852147ce9cd6c8e5788c477d",
            "46f71c00ad5e43bda36b9112cc906a48",
            "2748c4c0ba02443582a0c4db87d054ad",
            "9775e98f8bbd4450b96dde859905585b",
            "8b66c16905a2445a82de1a6461ee7e89",
            "cf0329dd90e243b1aea9a3a0af11d3d4",
            "013b995c30a345e189def7e935c47bef",
            "8c18192a6142476e83ca621e0fae2ed3",
            "b581f3489d8140488445e4d622fd2f91",
            "69d7ea6569ba4cb4a52d16f1453e7545",
            "a54d0aa13b244275aff70596ba3a7d5a",
            "8ee4681318ca419d96d15d82b517814e",
            "af84f925cb2c4e24af4b90241111d64f",
            "bdcd34c288b447eaaa88c0b87243cbfd",
            "ea4868e170f84dee850d2b25172ca4d3",
            "4c855ac42cd648da96b38ba146269f4e",
            "bc3f5f8feda144f4b9b8529a4bd44f77",
            "8e7543c25cf04824ae5306f11269f548",
            "ccd1c2cbf3634daa8400211b5dadcae0",
            "17997ade48764c50be92beaeb7adf382",
            "b1bbd1520f0040e0a59c77894933e53b",
            "d187f75734fb4ee3bd8bb25213c6027a",
            "4c0e8a49d597490aaff7c0ef90378eed",
            "e982f50319c347fe95dc32634a76c758",
            "1c51323ec44249c5b6b48d9e7bf34691",
            "9b3df5a283dc4fc4882c5fcd049c9247",
            "5b9e6f635719496fb8c5021479e1661b",
            "d79b56bdd1c54375916fbb7ba7449643",
            "d8a62957ed0f4e97ba69dfa756e26977",
            "b46e73f0a3d34f179e2c5604b1859d71",
            "65016ed796d343858e9078d61a0d4086",
            "09879bbe612a410b9989848ad26cb5b2",
            "2ec03c2449084f2b91dbd151413fd73d",
            "a3b4f8dee96841e88e30eef1912312c7",
            "747394688132494ea45eb1138a76ac89",
            "59fb399804b04802ab66cad8bd1719c7",
            "0d4074571d5344fc837d0df190181f97",
            "50d6107485c0481e823ba720eed3c125",
            "1ce17abc0b364ab79acb2eb4fef12953",
            "45fb523ed0d24df9bb4c20872d3cd243",
            "5d2b004eeb9a4d179550a40231581f29",
            "154453690e734d249bb68713dfb0c969",
            "ba5c6cd421f74edea6eb99f32860c0d2",
            "25e9518d18874654aa5ba22c3f1e9f74",
            "5c3837d85a994bc7be8bd574cc8d0ab8",
            "000de9a9504e4e219b7b8b1182c0c388",
            "124471c4adc94f4097632b08f3d2df3a",
            "2776e03890ed4a98b69ccd5c37605504",
            "15fd94ee7a414affb9cfc17f363fd19a",
            "f7571461b23c4d87adc385588af0bf26",
            "b802f5c71664432f80ae9f5046b10894",
            "61d4763d6cec45ea878233dc45c8f6bc",
            "e0a27180f7bd4215893f70714a03cbf7",
            "d75885607b394c88856bc091f9e7afea",
            "06baa701495f4d6b95b447d1c3766e9c",
            "3fca7e54138140e5b60ae2dddbe074b1",
            "3c4d2ab4c798466080a67fb40e35796b",
            "81b7701a884740aa8fdf9886229a529f",
            "c48f8271911d4abd89d633d7c70bcb17",
            "aef2252499774b35b652c1339677e80e",
            "688be9c7600b482fbc3af8e3c9a5a7f1",
            "cbc2f32da8ff498d945244971c937523",
            "81704cf6f3614714bbb0ac51fa5a8288",
            "f22ffb84ac2b43c2a91f33e1aeeb0902",
            "053f94d34be34e72851284eb131e21ee",
            "0167e70a98394186a00b311379c79e63",
            "01dafedba44f468da4f5400a2818f7d7",
            "87dd3c85b167447abaa6b8313b4b778b",
            "977ef11e71434b089deb08fbe692402f",
            "39539d5572bf46fcaab3e785efce9349",
            "0904383edd4e44ba90f3328b4c18b707"
          ]
        },
        "id": "MilLroyWc2oA",
        "outputId": "069b19d1-424f-4dd5-8bc3-2340f4c9106e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distilbert-base-uncased densenet161\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 97.5 M\n",
            "--------------------------------------------------\n",
            "97.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "97.5 M    Total params\n",
            "390.185   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0123f9df9294c71b2c2854129afb930",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c8eb553ab9545edbf99c41d3e18a0ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75f6f601246c4bfe98ed3bcb4202eb03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.704\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.70426 (best 0.70426), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v11.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13d7d76ba02649eea06b87cc7e13e2fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.021 >= min_delta = 0.001. New best score: 0.683\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' reached 0.68332 (best 0.68332), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=1-step=190-v9.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9aae00dc3bb406eb4a039b83675b490",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c76dee992474bd7bbaf56d10be52cf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' reached 0.68325 (best 0.68325), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=3-step=380-v1.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f7cc21652d0400ab37244e8d6fb282a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.683. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 475: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:03<08:20,  3.74s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:04<04:02,  1.82s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:04<02:39,  1.21s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:05<01:59,  1.10it/s]\u001b[A\n",
            "  4%|▎         | 5/135 [00:05<01:38,  1.32it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:06<01:24,  1.53it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:06<01:15,  1.69it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:06<01:09,  1.84it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:07<01:05,  1.93it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:07<01:02,  1.99it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:08<01:00,  2.05it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:08<00:58,  2.09it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:09<00:57,  2.14it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:09<00:56,  2.13it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:10<00:55,  2.15it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:10<00:55,  2.15it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:11<00:55,  2.15it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:11<00:54,  2.15it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:12<00:54,  2.13it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:12<00:54,  2.12it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:13<00:53,  2.13it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:13<00:52,  2.16it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:13<00:51,  2.17it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:14<00:51,  2.17it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:14<00:50,  2.18it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:15<00:49,  2.19it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:15<00:49,  2.19it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:16<00:48,  2.19it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:16<00:48,  2.17it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:17<00:48,  2.18it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:17<00:47,  2.18it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:18<00:47,  2.16it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:18<00:47,  2.15it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:18<00:46,  2.16it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:19<00:46,  2.16it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:19<00:46,  2.15it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:20<00:45,  2.15it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:20<00:44,  2.16it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:21<00:44,  2.16it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:21<00:44,  2.16it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:22<00:43,  2.16it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:22<00:43,  2.16it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:23<00:42,  2.15it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:23<00:42,  2.16it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:24<00:41,  2.17it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:24<00:40,  2.17it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:25<00:40,  2.17it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:25<00:39,  2.18it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:25<00:39,  2.16it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:26<00:40,  2.11it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:26<00:39,  2.12it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:27<00:39,  2.10it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:27<00:38,  2.14it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:28<00:37,  2.15it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:28<00:37,  2.16it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:29<00:36,  2.14it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:29<00:36,  2.16it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:30<00:35,  2.16it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:30<00:35,  2.13it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:31<00:35,  2.11it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:31<00:34,  2.13it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:32<00:34,  2.13it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:32<00:33,  2.15it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:32<00:33,  2.14it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:33<00:32,  2.13it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:33<00:32,  2.14it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:34<00:31,  2.13it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:34<00:31,  2.14it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:35<00:30,  2.15it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:35<00:29,  2.17it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:36<00:30,  2.12it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:36<00:29,  2.11it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:37<00:29,  2.11it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:37<00:28,  2.12it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:38<00:28,  2.14it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:38<00:27,  2.14it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:39<00:26,  2.15it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:39<00:26,  2.13it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:39<00:25,  2.16it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:40<00:25,  2.15it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:40<00:24,  2.16it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:41<00:24,  2.15it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:41<00:24,  2.14it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:42<00:23,  2.15it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:42<00:23,  2.16it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:43<00:22,  2.17it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:43<00:22,  2.17it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:44<00:21,  2.18it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:44<00:21,  2.15it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:45<00:20,  2.17it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:45<00:20,  2.17it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:45<00:19,  2.17it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:46<00:19,  2.17it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:46<00:18,  2.16it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:47<00:18,  2.13it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:47<00:18,  2.14it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:48<00:17,  2.15it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [00:48<00:17,  2.16it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [00:49<00:16,  2.18it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [00:49<00:16,  2.16it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [00:50<00:15,  2.18it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [00:50<00:15,  2.19it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [00:51<00:14,  2.17it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [00:51<00:14,  2.14it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [00:52<00:13,  2.17it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [00:52<00:13,  2.19it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [00:52<00:12,  2.22it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [00:53<00:12,  2.16it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [00:53<00:12,  2.13it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [00:54<00:11,  2.12it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [00:54<00:11,  2.13it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [00:55<00:10,  2.11it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [00:55<00:10,  2.11it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [00:56<00:09,  2.11it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [00:56<00:09,  2.11it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [00:57<00:08,  2.13it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [00:57<00:08,  2.14it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [00:58<00:08,  2.08it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [00:58<00:07,  2.11it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [00:59<00:07,  2.11it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [00:59<00:06,  2.11it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:00<00:06,  2.08it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:00<00:05,  2.09it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:00<00:05,  2.10it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:01<00:04,  2.09it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:01<00:04,  2.04it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:02<00:03,  2.06it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:02<00:03,  2.04it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:03<00:02,  2.03it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:03<00:02,  2.04it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:04<00:01,  2.06it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:04<00:01,  2.03it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:05<00:00,  2.06it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:05<00:00,  2.05it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:06<00:00,  2.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: distilbert-base-uncased & densenet161, \n",
            " accuracy: 0.6018518518518519, \n",
            " auc_roc: 0.5735261744375468, \n",
            " f1 score: 0.46384039900249374\n",
            "distilbert-base-uncased vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 212 M \n",
            "--------------------------------------------------\n",
            "212 M     Trainable params\n",
            "0         Non-trainable params\n",
            "212 M     Total params\n",
            "850.174   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "907ae3cf62594e43bac5ce7644f96740",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb61df668c34970b93eb513d7e3d397",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0f1391921f0431796865f4c90f9e1c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.715\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.71484 (best 0.71484), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v11.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "948407c1e73742bd99d40376f087f769",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.022 >= min_delta = 0.001. New best score: 0.693\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' reached 0.69292 (best 0.69292), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=1-step=190-v9.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7e389ff9c264b318b6b0b5ea5b1a8b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb1b63c4113472291f9ad7cf95d0a97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19310459032a482fb3427d4c83aa5949",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.693. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 475: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:05<11:21,  5.08s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:05<05:21,  2.42s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:06<03:27,  1.57s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:06<02:33,  1.17s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:07<02:03,  1.05it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:07<01:44,  1.24it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:08<01:32,  1.38it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:08<01:26,  1.47it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:09<01:21,  1.54it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:10<01:17,  1.62it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:10<01:14,  1.67it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:11<01:12,  1.70it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:11<01:10,  1.74it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:12<01:08,  1.77it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:12<01:07,  1.78it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:13<01:06,  1.79it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:13<01:05,  1.79it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:14<01:05,  1.79it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:15<01:05,  1.78it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:15<01:04,  1.78it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:16<01:04,  1.77it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:16<01:02,  1.79it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:17<01:03,  1.76it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:17<01:03,  1.75it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:18<01:02,  1.75it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:19<01:02,  1.75it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:19<01:01,  1.77it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:20<00:59,  1.79it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:20<00:59,  1.79it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:21<00:58,  1.79it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:21<00:59,  1.75it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:22<00:58,  1.75it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:23<00:57,  1.76it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:23<00:56,  1.79it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:24<00:55,  1.79it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:24<00:55,  1.79it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:25<00:54,  1.79it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:25<00:54,  1.79it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:26<00:53,  1.80it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:26<00:53,  1.78it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:27<00:52,  1.79it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:28<00:52,  1.79it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:28<00:51,  1.79it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:29<00:50,  1.81it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:29<00:49,  1.82it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:30<00:49,  1.80it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:30<00:49,  1.79it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:31<00:48,  1.79it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:31<00:47,  1.81it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:32<00:47,  1.80it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:33<00:46,  1.80it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:33<00:46,  1.79it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:34<00:45,  1.81it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:34<00:45,  1.80it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:35<00:44,  1.78it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:35<00:44,  1.78it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:36<00:43,  1.79it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:36<00:43,  1.79it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:37<00:42,  1.79it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:38<00:42,  1.78it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:38<00:41,  1.78it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:39<00:41,  1.78it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:39<00:40,  1.79it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:40<00:39,  1.80it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:40<00:39,  1.77it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:41<00:39,  1.73it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:42<00:39,  1.72it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:42<00:39,  1.69it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:43<00:38,  1.70it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:43<00:37,  1.72it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:44<00:37,  1.70it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:45<00:36,  1.71it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:45<00:35,  1.73it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:46<00:35,  1.71it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:46<00:34,  1.72it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:47<00:34,  1.72it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:47<00:34,  1.70it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:48<00:34,  1.64it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:49<00:34,  1.63it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:49<00:33,  1.66it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:50<00:32,  1.65it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:51<00:32,  1.65it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:51<00:31,  1.65it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:52<00:30,  1.66it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:52<00:29,  1.67it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:53<00:30,  1.62it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:54<00:28,  1.66it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:54<00:28,  1.63it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:55<00:27,  1.65it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:55<00:27,  1.65it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:56<00:26,  1.67it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:57<00:25,  1.68it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:57<00:25,  1.68it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:58<00:24,  1.67it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:58<00:23,  1.68it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:59<00:23,  1.68it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:00<00:22,  1.69it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:00<00:22,  1.66it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:01<00:21,  1.66it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:01<00:21,  1.65it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:02<00:20,  1.65it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:03<00:20,  1.65it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:03<00:19,  1.67it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:04<00:18,  1.69it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:04<00:17,  1.70it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:05<00:16,  1.72it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:05<00:16,  1.70it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:06<00:15,  1.71it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:07<00:15,  1.69it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:07<00:14,  1.72it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:08<00:14,  1.70it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:08<00:13,  1.72it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:09<00:12,  1.75it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:09<00:11,  1.77it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:10<00:11,  1.80it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:11<00:10,  1.81it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:11<00:10,  1.75it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:12<00:09,  1.76it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:12<00:09,  1.78it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:13<00:08,  1.78it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:13<00:07,  1.78it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:14<00:07,  1.78it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:15<00:06,  1.81it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:15<00:06,  1.82it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:16<00:05,  1.83it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:16<00:04,  1.83it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:17<00:04,  1.82it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:17<00:03,  1.82it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:18<00:03,  1.78it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:18<00:02,  1.80it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:19<00:02,  1.83it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:19<00:01,  1.84it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:20<00:01,  1.85it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:21<00:00,  1.86it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:22<00:00,  1.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: distilbert-base-uncased & vgg19_bn, \n",
            " accuracy: 0.5962962962962963, \n",
            " auc_roc: 0.5544423684040977, \n",
            " f1 score: 0.40437158469945356\n",
            "bert-base-uncased densenet161\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 140 M \n",
            "--------------------------------------------------\n",
            "140 M     Trainable params\n",
            "0         Non-trainable params\n",
            "140 M     Total params\n",
            "562.662   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae23ced17fbe46e989861e9d1482bd64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5334e93de4774c49bafff69ec9e3d8ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f7dde1abd8b45fea2137a1637ec1c10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.672\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.67181 (best 0.67181), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v11.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "777ae614e1984e5eba4ab23259b4ad44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cec5f9d85c14b49933ed9b90925d9df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1ba42ddb26343a2a1ad156910e79a8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.672. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:04<10:24,  4.66s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:05<05:04,  2.29s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:05<03:20,  1.52s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:06<02:30,  1.15s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:07<02:03,  1.05it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:07<01:47,  1.20it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:08<01:36,  1.33it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:08<01:28,  1.43it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:09<01:24,  1.49it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:10<01:20,  1.55it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:10<01:19,  1.57it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:11<01:17,  1.58it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:11<01:16,  1.60it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:12<01:14,  1.63it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:13<01:13,  1.63it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:13<01:12,  1.65it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:14<01:11,  1.64it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:14<01:11,  1.65it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:15<01:11,  1.63it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:16<01:10,  1.64it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:16<01:08,  1.66it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:17<01:07,  1.67it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:17<01:06,  1.68it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:18<01:05,  1.68it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:19<01:05,  1.68it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:19<01:04,  1.68it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:20<01:04,  1.68it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:20<01:03,  1.69it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:21<01:02,  1.69it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:22<01:01,  1.70it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:22<01:01,  1.68it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:23<01:01,  1.68it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:23<01:00,  1.67it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:24<01:00,  1.68it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:25<00:59,  1.68it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:25<00:59,  1.67it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:26<00:58,  1.67it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:26<00:57,  1.68it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:27<00:57,  1.67it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:28<00:56,  1.67it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:28<00:56,  1.66it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:29<00:57,  1.62it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:29<00:57,  1.61it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:30<00:56,  1.61it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:31<00:55,  1.64it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:31<00:54,  1.65it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:32<00:52,  1.66it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:32<00:52,  1.67it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:33<00:51,  1.66it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:34<00:51,  1.66it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:34<00:50,  1.67it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:35<00:50,  1.66it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:35<00:49,  1.66it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:36<00:48,  1.67it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:37<00:47,  1.67it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:37<00:47,  1.66it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:38<00:46,  1.67it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:38<00:46,  1.67it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:39<00:45,  1.66it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:40<00:45,  1.66it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:40<00:44,  1.65it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:41<00:44,  1.64it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:41<00:43,  1.65it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:42<00:43,  1.63it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:43<00:42,  1.63it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:43<00:42,  1.61it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:44<00:42,  1.61it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:45<00:41,  1.62it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:45<00:40,  1.64it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:46<00:39,  1.65it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:46<00:38,  1.66it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:47<00:37,  1.67it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:48<00:37,  1.66it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:48<00:36,  1.65it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:49<00:36,  1.63it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:49<00:36,  1.63it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:50<00:35,  1.65it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:51<00:34,  1.66it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:51<00:33,  1.66it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:52<00:33,  1.67it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:52<00:32,  1.67it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:53<00:32,  1.65it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:54<00:31,  1.63it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:54<00:31,  1.63it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:55<00:30,  1.65it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:55<00:29,  1.64it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:56<00:29,  1.65it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:57<00:28,  1.65it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:57<00:27,  1.66it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:58<00:27,  1.66it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:58<00:26,  1.64it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:59<00:26,  1.60it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:00<00:26,  1.59it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:00<00:25,  1.58it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:01<00:24,  1.61it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:02<00:24,  1.62it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:02<00:23,  1.63it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:03<00:22,  1.63it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:03<00:22,  1.64it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:04<00:21,  1.63it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:05<00:20,  1.64it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:05<00:20,  1.64it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:06<00:19,  1.65it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:06<00:18,  1.68it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:07<00:17,  1.69it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:08<00:17,  1.69it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:08<00:16,  1.71it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:09<00:15,  1.72it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:09<00:15,  1.73it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:10<00:14,  1.73it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:11<00:13,  1.72it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:11<00:13,  1.69it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:12<00:13,  1.68it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:12<00:12,  1.71it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:13<00:11,  1.70it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:13<00:11,  1.71it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:14<00:10,  1.70it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:15<00:09,  1.72it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:15<00:09,  1.73it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:16<00:08,  1.71it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:16<00:08,  1.72it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:17<00:07,  1.72it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:18<00:06,  1.72it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:18<00:06,  1.73it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:19<00:05,  1.73it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:19<00:05,  1.73it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:20<00:04,  1.72it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:20<00:04,  1.73it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:21<00:03,  1.74it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:22<00:02,  1.75it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:22<00:02,  1.69it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:23<00:01,  1.68it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:23<00:01,  1.67it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:24<00:00,  1.65it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:25<00:00,  1.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: bert-base-uncased & densenet161, \n",
            " accuracy: 0.6222222222222222, \n",
            " auc_roc: 0.5762811557973678, \n",
            " f1 score: 0.3892215568862275\n",
            "bert-base-uncased vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 255 M \n",
            "--------------------------------------------------\n",
            "255 M     Trainable params\n",
            "0         Non-trainable params\n",
            "255 M     Total params\n",
            "1,022.651 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "955b0a7f67e4462c844b2f944e68bd6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02277fc70ad74eee80ca554aad3cb0d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae0a401657c34d7bafb6c924a559fb90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.685\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.68452 (best 0.68452), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v12.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdbbb9bbb20d44739e3c9989bb26e528",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6b7ddfe0b194cb4847ddd23fe305613",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13039781239946fd96faf2496da536b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.685. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:06<13:30,  6.05s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:06<06:17,  2.84s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:07<03:59,  1.81s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:07<02:53,  1.33s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:08<02:17,  1.06s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:08<01:55,  1.12it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:09<01:41,  1.26it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:10<01:31,  1.38it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:10<01:25,  1.47it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:11<01:23,  1.50it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:11<01:21,  1.52it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:12<01:20,  1.53it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:13<01:17,  1.58it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:13<01:14,  1.61it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:14<01:12,  1.65it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:14<01:11,  1.67it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:15<01:10,  1.68it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:16<01:09,  1.69it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:16<01:09,  1.68it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:17<01:08,  1.69it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:17<01:07,  1.69it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:18<01:05,  1.71it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:19<01:05,  1.71it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:19<01:04,  1.71it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:20<01:03,  1.72it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:20<01:03,  1.72it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:21<01:02,  1.73it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:21<01:01,  1.73it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:22<01:01,  1.72it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:23<01:00,  1.72it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:23<01:01,  1.70it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:24<01:01,  1.68it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:24<01:01,  1.65it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:25<01:01,  1.65it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:26<01:01,  1.63it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:26<01:00,  1.63it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:27<01:00,  1.62it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:28<00:59,  1.63it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:28<00:59,  1.60it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:29<01:00,  1.58it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:29<00:59,  1.57it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:30<00:58,  1.58it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:31<00:58,  1.58it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:31<00:57,  1.59it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:32<00:56,  1.58it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:33<00:56,  1.58it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:33<00:54,  1.61it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:34<00:54,  1.60it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:34<00:52,  1.63it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:35<00:52,  1.61it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:36<00:52,  1.60it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:36<00:52,  1.58it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:37<00:51,  1.59it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:38<00:51,  1.58it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:38<00:50,  1.60it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:39<00:49,  1.59it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:40<00:48,  1.60it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:40<00:48,  1.58it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:41<00:48,  1.55it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:42<00:48,  1.53it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:42<00:48,  1.51it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:43<00:47,  1.53it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:43<00:46,  1.55it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:44<00:45,  1.56it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:45<00:44,  1.56it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:45<00:43,  1.57it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:46<00:42,  1.59it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:47<00:43,  1.53it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:47<00:42,  1.54it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:48<00:41,  1.56it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:49<00:40,  1.58it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:49<00:39,  1.60it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:50<00:38,  1.60it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:50<00:37,  1.61it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:51<00:36,  1.64it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:52<00:36,  1.62it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:52<00:35,  1.65it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:53<00:34,  1.67it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:53<00:33,  1.68it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:54<00:32,  1.69it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:55<00:31,  1.69it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:55<00:31,  1.69it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:56<00:30,  1.68it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:56<00:30,  1.68it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:57<00:29,  1.69it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:57<00:29,  1.68it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:58<00:28,  1.69it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:59<00:27,  1.69it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:59<00:27,  1.66it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [01:00<00:27,  1.67it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:00<00:26,  1.67it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:01<00:25,  1.68it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:02<00:24,  1.69it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:02<00:24,  1.68it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:03<00:23,  1.68it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:03<00:23,  1.67it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:04<00:22,  1.66it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:05<00:22,  1.66it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:05<00:21,  1.67it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:06<00:20,  1.68it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:06<00:20,  1.69it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:07<00:19,  1.71it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:08<00:18,  1.71it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:08<00:17,  1.73it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:09<00:17,  1.75it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:09<00:16,  1.75it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:10<00:15,  1.77it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:10<00:15,  1.77it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:11<00:14,  1.76it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:12<00:14,  1.72it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:12<00:14,  1.69it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:13<00:13,  1.67it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:13<00:13,  1.69it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:14<00:12,  1.71it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:15<00:11,  1.74it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:15<00:10,  1.75it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:16<00:10,  1.77it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:16<00:09,  1.77it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:17<00:09,  1.76it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:17<00:08,  1.78it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:18<00:07,  1.78it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:18<00:07,  1.79it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:19<00:06,  1.79it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:20<00:06,  1.79it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:20<00:05,  1.79it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:21<00:05,  1.79it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:21<00:04,  1.79it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:22<00:03,  1.78it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:22<00:03,  1.78it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:23<00:02,  1.78it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:23<00:02,  1.79it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:24<00:01,  1.79it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:25<00:01,  1.79it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:25<00:00,  1.80it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:27<00:00,  1.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: bert-base-uncased & vgg19_bn, \n",
            " accuracy: 0.6277777777777778, \n",
            " auc_roc: 0.5871968279579121, \n",
            " f1 score: 0.4240687679083094\n",
            "roberta-base densenet161\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 155 M \n",
            "--------------------------------------------------\n",
            "155 M     Trainable params\n",
            "0         Non-trainable params\n",
            "155 M     Total params\n",
            "623.316   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48582daa7ebb4a63b2168d357a385ba7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83a5862884d34d4083b85bd5b5adb7d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76bead8dd85c4926aa5a62b249373d50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.723\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.72330 (best 0.72330), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v13.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dca5873197ce4e46951cb45bc915a7c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.025 >= min_delta = 0.001. New best score: 0.699\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' reached 0.69850 (best 0.69850), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=1-step=190-v10.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ca415d44a3a4a129e2c28c295a113aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0c20f5e7fd40d4a50ddeab3339e234",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.005 >= min_delta = 0.001. New best score: 0.694\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' reached 0.69373 (best 0.69373), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=3-step=380-v2.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3c03e493a964a229af3d84a2b1927ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.007 >= min_delta = 0.001. New best score: 0.687\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 475: 'avg_val_loss' reached 0.68650 (best 0.68650), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=4-step=475-v3.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e27f3137a3d4197971e8a182fc86730",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 570: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cbdc2a9524a4c51a812377ff6ebc1ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 665: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2724da9374147d6aed8d80993299d28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.687. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 760: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:04<10:15,  4.59s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:05<04:52,  2.20s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:05<03:10,  1.44s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:06<02:21,  1.08s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:06<01:54,  1.14it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:07<01:37,  1.32it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:07<01:27,  1.47it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:08<01:19,  1.60it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:08<01:15,  1.67it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:09<01:12,  1.73it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:09<01:09,  1.78it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:10<01:07,  1.82it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:10<01:06,  1.84it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:11<01:04,  1.88it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:11<01:03,  1.89it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:12<01:02,  1.90it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:12<01:02,  1.89it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:13<01:01,  1.90it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:14<01:01,  1.89it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:14<01:00,  1.89it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:15<01:00,  1.90it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:15<00:59,  1.91it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:16<00:58,  1.92it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:16<00:57,  1.92it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:17<00:57,  1.91it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:17<00:56,  1.91it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:18<00:56,  1.92it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:18<00:55,  1.92it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:19<00:55,  1.89it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:19<00:54,  1.91it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:20<00:54,  1.91it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:20<00:53,  1.91it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:21<00:54,  1.89it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:21<00:53,  1.90it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:22<00:52,  1.89it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:22<00:52,  1.89it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:23<00:51,  1.89it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:24<00:51,  1.89it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:24<00:51,  1.88it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:25<00:50,  1.86it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:25<00:50,  1.87it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:26<00:49,  1.87it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:26<00:49,  1.87it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:27<00:48,  1.86it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:27<00:47,  1.88it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:28<00:47,  1.89it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:28<00:46,  1.89it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:29<00:45,  1.90it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:29<00:45,  1.91it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:30<00:44,  1.92it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:30<00:44,  1.91it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:31<00:43,  1.89it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:31<00:43,  1.90it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:32<00:42,  1.91it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:33<00:42,  1.88it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:33<00:42,  1.87it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:34<00:41,  1.88it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:34<00:40,  1.88it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:35<00:40,  1.88it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:35<00:39,  1.89it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:36<00:39,  1.89it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:36<00:38,  1.89it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:37<00:37,  1.90it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:37<00:37,  1.89it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:38<00:36,  1.90it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:38<00:36,  1.90it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:39<00:35,  1.90it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:39<00:35,  1.90it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:40<00:34,  1.89it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:40<00:34,  1.90it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:41<00:33,  1.88it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:42<00:33,  1.89it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:42<00:32,  1.88it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:43<00:32,  1.89it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:43<00:31,  1.90it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:44<00:30,  1.91it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:44<00:30,  1.91it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:45<00:30,  1.89it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:45<00:29,  1.89it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:46<00:29,  1.89it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:46<00:28,  1.91it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:47<00:27,  1.91it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:47<00:27,  1.90it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:48<00:27,  1.88it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:48<00:26,  1.87it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:49<00:26,  1.88it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:49<00:25,  1.89it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:50<00:24,  1.90it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:51<00:24,  1.88it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:51<00:24,  1.83it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:52<00:24,  1.83it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:52<00:23,  1.83it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:53<00:22,  1.85it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:53<00:22,  1.85it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:54<00:21,  1.87it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:54<00:20,  1.86it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:55<00:20,  1.86it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [00:55<00:20,  1.85it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [00:56<00:19,  1.87it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [00:56<00:18,  1.87it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [00:57<00:18,  1.89it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [00:58<00:17,  1.88it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [00:58<00:17,  1.88it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [00:59<00:16,  1.91it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [00:59<00:15,  1.93it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:00<00:14,  1.94it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:00<00:14,  1.98it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:01<00:13,  1.99it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:01<00:12,  2.01it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:02<00:12,  2.00it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:02<00:12,  2.00it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:03<00:11,  1.99it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:03<00:11,  1.99it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:04<00:10,  2.00it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:04<00:09,  2.00it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:05<00:09,  1.99it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:05<00:09,  1.99it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:06<00:08,  1.97it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:06<00:08,  1.99it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:07<00:07,  1.99it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:07<00:07,  2.00it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:08<00:06,  1.99it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:08<00:06,  1.99it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:09<00:05,  1.99it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:09<00:05,  1.99it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:10<00:04,  1.99it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:10<00:04,  2.00it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:11<00:03,  2.01it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:11<00:03,  1.99it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:12<00:02,  1.96it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:12<00:02,  1.94it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:13<00:01,  1.94it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:13<00:01,  1.95it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:14<00:00,  1.95it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:15<00:00,  1.79it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: roberta-base & densenet161, \n",
            " accuracy: 0.6222222222222222, \n",
            " auc_roc: 0.5918796992481203, \n",
            " f1 score: 0.47692307692307695\n",
            "roberta-base vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 270 M \n",
            "--------------------------------------------------\n",
            "270 M     Trainable params\n",
            "0         Non-trainable params\n",
            "270 M     Total params\n",
            "1,083.305 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "349a72542bcb44e9bbfc679f988dfb34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b87ecaf3bdf243799974a94b34f385d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e668ebc685bf43c48c12f971c32aab8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.696\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.69625 (best 0.69625), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v13.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37da314f7b424978aaff7cb28c573bf6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f34c60f5599d41dead3e0905b8db1c32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38c08bf58bd54d71a9041954bdf6fda9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.696. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:06<14:14,  6.38s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:07<06:47,  3.06s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:07<04:23,  1.99s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:08<03:13,  1.48s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:09<02:35,  1.19s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:09<02:11,  1.02s/it]\u001b[A\n",
            "  5%|▌         | 7/135 [00:10<01:56,  1.10it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:11<01:46,  1.19it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:11<01:39,  1.26it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:12<01:34,  1.32it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:13<01:31,  1.36it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:14<01:29,  1.37it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:14<01:27,  1.39it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:15<01:26,  1.41it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:16<01:25,  1.40it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:16<01:24,  1.41it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:17<01:23,  1.42it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:18<01:22,  1.42it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:18<01:21,  1.42it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:19<01:19,  1.45it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:20<01:16,  1.48it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:20<01:14,  1.51it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:21<01:14,  1.51it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:22<01:14,  1.48it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:22<01:15,  1.47it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:23<01:14,  1.46it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:24<01:12,  1.48it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:24<01:11,  1.50it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:25<01:09,  1.52it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:26<01:08,  1.54it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:26<01:07,  1.54it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:27<01:06,  1.56it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:28<01:05,  1.55it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:28<01:05,  1.54it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:29<01:04,  1.54it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:30<01:03,  1.55it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:30<01:02,  1.56it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:31<01:01,  1.58it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:31<01:01,  1.56it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:32<01:00,  1.56it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:33<01:00,  1.55it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:33<01:00,  1.54it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:34<00:59,  1.54it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:35<00:59,  1.54it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:35<00:58,  1.54it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:36<00:57,  1.54it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:37<00:57,  1.54it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:37<00:56,  1.54it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:38<00:56,  1.53it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:39<00:56,  1.51it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:39<00:54,  1.53it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:40<00:54,  1.52it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:41<00:53,  1.53it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:41<00:52,  1.54it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:42<00:52,  1.52it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:43<00:52,  1.52it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:43<00:51,  1.52it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:44<00:50,  1.51it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:45<00:49,  1.53it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:45<00:49,  1.51it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:46<00:48,  1.52it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:47<00:47,  1.52it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:47<00:47,  1.51it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:48<00:46,  1.52it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:49<00:46,  1.52it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:49<00:44,  1.53it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:50<00:44,  1.53it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:50<00:43,  1.53it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:51<00:43,  1.52it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:52<00:43,  1.48it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:53<00:44,  1.45it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:53<00:42,  1.48it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:54<00:41,  1.49it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:55<00:40,  1.50it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:55<00:39,  1.51it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:56<00:39,  1.50it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:56<00:38,  1.52it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:57<00:37,  1.51it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:58<00:36,  1.52it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:58<00:36,  1.53it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:59<00:35,  1.52it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [01:00<00:34,  1.53it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [01:00<00:34,  1.52it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [01:01<00:33,  1.52it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [01:02<00:32,  1.53it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [01:02<00:32,  1.52it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [01:03<00:31,  1.53it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [01:04<00:30,  1.52it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [01:04<00:29,  1.54it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [01:05<00:29,  1.54it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:06<00:28,  1.52it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:06<00:28,  1.53it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:07<00:27,  1.53it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:08<00:26,  1.53it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:08<00:26,  1.52it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:09<00:25,  1.51it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:10<00:25,  1.51it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:10<00:24,  1.51it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:11<00:23,  1.52it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:12<00:23,  1.50it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:12<00:22,  1.51it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:13<00:21,  1.50it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:14<00:21,  1.51it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:14<00:20,  1.54it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:15<00:19,  1.55it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:15<00:18,  1.56it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:16<00:17,  1.57it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:17<00:17,  1.57it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:17<00:16,  1.58it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:18<00:15,  1.57it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:19<00:15,  1.56it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:19<00:14,  1.58it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:20<00:13,  1.59it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:21<00:13,  1.59it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:21<00:12,  1.60it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:22<00:11,  1.60it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:22<00:11,  1.56it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:23<00:11,  1.54it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:24<00:10,  1.52it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:24<00:09,  1.54it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:25<00:09,  1.55it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:26<00:08,  1.56it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:26<00:07,  1.57it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:27<00:07,  1.56it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:28<00:06,  1.58it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:28<00:05,  1.59it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:29<00:05,  1.60it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:29<00:04,  1.60it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:30<00:03,  1.60it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:31<00:03,  1.61it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:31<00:02,  1.61it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:32<00:01,  1.60it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:33<00:01,  1.60it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:33<00:00,  1.59it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:35<00:00,  1.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: roberta-base & vgg19_bn, \n",
            " accuracy: 0.6148148148148148, \n",
            " auc_roc: 0.553490990990991, \n",
            " f1 score: 0.29729729729729726\n",
            "distilroberta-base densenet161\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 113 M \n",
            "--------------------------------------------------\n",
            "113 M     Trainable params\n",
            "0         Non-trainable params\n",
            "113 M     Total params\n",
            "453.207   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87b38991322149ef85140f4c4d7d9cdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "931e8b7dd9b54f7d92cb2170936dae28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebccf8c8df9d4ef2bd67267ad8fbe09a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.685\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.68466 (best 0.68466), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v14.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a2df960ebbd457e91e4d00ea53100e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.009 >= min_delta = 0.001. New best score: 0.676\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' reached 0.67616 (best 0.67616), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=1-step=190-v10.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aac4689bb8d244a590d6f968d11aabd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7821bee92784d72a75f533c62d4adc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe61b6cdd17d4c43a37711195064813d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.676. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 475: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:04<09:46,  4.38s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:04<04:37,  2.09s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:05<02:58,  1.36s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:05<02:11,  1.01s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:06<01:45,  1.23it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:06<01:28,  1.45it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:07<01:19,  1.62it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:07<01:12,  1.76it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:08<01:07,  1.86it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:08<01:04,  1.95it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:09<01:01,  2.01it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:09<01:00,  2.02it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:10<00:59,  2.04it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:10<00:58,  2.08it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:10<00:57,  2.11it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:11<01:04,  1.86it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:12<01:09,  1.70it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:13<01:12,  1.62it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:13<01:13,  1.58it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:14<01:13,  1.56it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:14<01:10,  1.62it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:15<01:10,  1.60it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:16<01:07,  1.67it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:16<01:02,  1.77it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:17<00:58,  1.87it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:17<00:56,  1.94it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:17<00:53,  2.02it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:18<00:52,  2.05it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:18<00:51,  2.07it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:19<00:50,  2.09it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:19<00:49,  2.12it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:20<00:48,  2.14it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:20<00:48,  2.12it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:21<00:47,  2.14it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:21<00:46,  2.14it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:22<00:46,  2.14it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:22<00:45,  2.14it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:23<00:45,  2.13it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:23<00:46,  2.07it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:24<00:45,  2.08it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:24<00:44,  2.11it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:25<00:43,  2.12it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:25<00:43,  2.12it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:25<00:42,  2.13it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:26<00:41,  2.15it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:26<00:41,  2.13it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:27<00:41,  2.13it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:27<00:40,  2.13it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:28<00:40,  2.14it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:28<00:40,  2.11it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:29<00:39,  2.12it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:29<00:38,  2.13it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:30<00:38,  2.13it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:30<00:38,  2.12it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:31<00:38,  2.10it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:31<00:37,  2.08it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:32<00:36,  2.12it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:32<00:36,  2.12it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:33<00:36,  2.11it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:33<00:35,  2.12it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:33<00:34,  2.14it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:34<00:34,  2.14it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:34<00:33,  2.12it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:35<00:33,  2.11it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:35<00:33,  2.12it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:36<00:32,  2.13it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:36<00:31,  2.13it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:37<00:31,  2.15it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:37<00:30,  2.16it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:38<00:30,  2.16it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:38<00:30,  2.13it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:39<00:29,  2.12it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:39<00:29,  2.12it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:40<00:29,  2.10it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:40<00:28,  2.11it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:41<00:27,  2.11it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:41<00:27,  2.09it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:41<00:27,  2.11it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:42<00:26,  2.12it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:42<00:25,  2.13it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:43<00:25,  2.12it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:43<00:24,  2.13it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:44<00:24,  2.13it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:44<00:24,  2.11it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:45<00:23,  2.12it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:45<00:22,  2.13it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:46<00:23,  2.09it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:46<00:22,  2.05it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:47<00:22,  2.03it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:47<00:22,  2.04it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:48<00:21,  2.02it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:48<00:21,  2.05it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:49<00:20,  2.02it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:49<00:20,  2.01it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:50<00:19,  2.02it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:50<00:19,  2.04it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:51<00:18,  2.04it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [00:51<00:18,  2.04it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [00:52<00:17,  2.02it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [00:52<00:17,  1.99it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [00:53<00:16,  2.00it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [00:53<00:16,  2.02it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [00:54<00:16,  1.97it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [00:54<00:15,  1.97it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [00:55<00:15,  1.96it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [00:55<00:14,  1.99it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [00:56<00:13,  2.03it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [00:56<00:13,  2.06it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [00:57<00:12,  2.08it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [00:57<00:11,  2.10it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [00:58<00:11,  2.11it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [00:58<00:10,  2.13it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [00:58<00:10,  2.15it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [00:59<00:09,  2.12it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [00:59<00:09,  2.09it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:00<00:09,  2.08it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:00<00:08,  2.11it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:01<00:07,  2.13it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:01<00:07,  2.10it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:02<00:07,  2.07it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:02<00:06,  2.06it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:03<00:06,  2.06it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:03<00:05,  2.05it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:04<00:05,  2.09it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:04<00:04,  2.09it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:05<00:04,  2.11it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:05<00:03,  2.13it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:06<00:03,  2.14it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:06<00:02,  2.13it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:07<00:02,  2.14it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:07<00:01,  2.12it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:08<00:01,  2.14it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:08<00:00,  2.13it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:08<00:00,  2.11it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:10<00:00,  1.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: distilroberta-base & densenet161, \n",
            " accuracy: 0.5925925925925926, \n",
            " auc_roc: 0.5632352941176471, \n",
            " f1 score: 0.45\n",
            "distilroberta-base vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 228 M \n",
            "--------------------------------------------------\n",
            "228 M     Trainable params\n",
            "0         Non-trainable params\n",
            "228 M     Total params\n",
            "913.196   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c78ece4a4b864784ad9da1dad54d7b81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2ad00c5524443faac44fe7cd062871a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70fcf96d3c044219921f62a7d7d229a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.677\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.67656 (best 0.67656), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v14.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bddd63e8773146b797ea47952eeab829",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f6e9c79487b4eb8b732c3b7c2f578ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e4cd96433914ace9dee768b062e2a6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.677. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:05<12:32,  5.62s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:06<05:51,  2.65s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:06<03:44,  1.70s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:07<02:45,  1.26s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:07<02:13,  1.02s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:08<01:53,  1.14it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:09<01:40,  1.27it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:09<01:30,  1.40it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:10<01:24,  1.50it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:10<01:19,  1.57it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:11<01:15,  1.64it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:11<01:12,  1.69it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:12<01:10,  1.73it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:13<01:09,  1.75it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:13<01:07,  1.77it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:14<01:07,  1.78it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:14<01:07,  1.75it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:15<01:06,  1.75it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:15<01:06,  1.75it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:16<01:05,  1.77it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:17<01:04,  1.76it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:17<01:03,  1.77it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:18<01:03,  1.76it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:18<01:02,  1.77it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:19<01:01,  1.78it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:19<01:01,  1.78it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:20<01:00,  1.79it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:20<00:59,  1.79it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:21<00:59,  1.78it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:22<00:58,  1.79it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:22<00:58,  1.79it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:23<00:57,  1.80it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:23<00:56,  1.80it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:24<00:56,  1.79it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:24<00:55,  1.79it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:25<00:55,  1.79it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:25<00:54,  1.79it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:26<00:54,  1.80it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:27<00:53,  1.78it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:27<00:53,  1.77it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:28<00:53,  1.77it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:28<00:52,  1.76it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:29<00:52,  1.77it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:29<00:51,  1.77it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:30<00:50,  1.77it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:31<00:50,  1.78it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:31<00:49,  1.78it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:32<00:48,  1.79it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:32<00:47,  1.80it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:33<00:47,  1.78it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:33<00:46,  1.79it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:34<00:47,  1.77it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:34<00:45,  1.78it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:35<00:45,  1.78it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:36<00:45,  1.77it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:36<00:44,  1.77it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:37<00:43,  1.79it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:37<00:44,  1.73it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:38<00:44,  1.69it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:39<00:43,  1.71it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:39<00:42,  1.73it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:40<00:41,  1.75it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:40<00:40,  1.76it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:41<00:40,  1.75it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:41<00:40,  1.74it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:42<00:39,  1.76it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:42<00:38,  1.76it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:43<00:37,  1.77it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:44<00:37,  1.78it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:44<00:36,  1.78it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:45<00:36,  1.78it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:45<00:35,  1.77it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:46<00:35,  1.77it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:46<00:34,  1.77it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:47<00:33,  1.77it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:48<00:33,  1.75it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:48<00:32,  1.77it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:49<00:32,  1.77it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:49<00:31,  1.77it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:50<00:31,  1.77it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:50<00:30,  1.78it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:51<00:29,  1.78it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:52<00:29,  1.76it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:52<00:28,  1.77it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:53<00:28,  1.76it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:53<00:27,  1.76it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:54<00:27,  1.77it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:54<00:26,  1.76it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:55<00:26,  1.77it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:55<00:25,  1.77it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:56<00:24,  1.79it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:57<00:24,  1.78it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:57<00:23,  1.77it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:58<00:23,  1.77it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:58<00:22,  1.77it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:59<00:22,  1.76it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:59<00:21,  1.75it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:00<00:20,  1.76it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:01<00:20,  1.76it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:01<00:19,  1.76it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:02<00:19,  1.77it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:02<00:18,  1.79it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:03<00:18,  1.78it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:03<00:17,  1.80it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:04<00:16,  1.82it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:04<00:15,  1.82it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:05<00:15,  1.81it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:06<00:14,  1.80it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:06<00:14,  1.82it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:07<00:13,  1.83it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:07<00:13,  1.83it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:08<00:12,  1.84it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:08<00:11,  1.85it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:09<00:11,  1.86it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:09<00:10,  1.87it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:10<00:10,  1.86it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:10<00:09,  1.88it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:11<00:09,  1.87it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:11<00:08,  1.88it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:12<00:07,  1.88it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:13<00:07,  1.86it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:13<00:07,  1.86it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:14<00:06,  1.85it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:14<00:05,  1.86it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:15<00:05,  1.86it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:15<00:04,  1.86it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:16<00:04,  1.86it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:16<00:03,  1.86it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:17<00:03,  1.86it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:17<00:02,  1.86it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:18<00:02,  1.86it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:18<00:01,  1.87it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:19<00:01,  1.88it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:19<00:00,  1.88it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:21<00:00,  1.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: distilroberta-base & vgg19_bn, \n",
            " accuracy: 0.6092592592592593, \n",
            " auc_roc: 0.572641878669276, \n",
            " f1 score: 0.43733333333333335\n",
            "gpt2 densenet161\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d56eefe8523245988501424323ce64fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6c1f6ce54aa498ba2eb8e86d3e92d3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1fd755be71f479bb18cba5204fff97c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58cf050e5f4b45188cc82a3dfb45ad2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6dc7cb6f7684fb48f4623a48c3bf6a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 155 M \n",
            "--------------------------------------------------\n",
            "155 M     Trainable params\n",
            "0         Non-trainable params\n",
            "155 M     Total params\n",
            "622.493   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd41f8ab807c45d3a5d56d2b8893c349",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb5f69cb57e14a1b9ef51ba63199a134",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b67055096ea489bb1dbe724835107b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.707\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.70685 (best 0.70685), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v15.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09db30cb99be45308fe054088f13f36c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff9c7f365d6042e49d651257d14ee8b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10d0289887c84ea1b282306b5bfdf7be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.707. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:05<11:19,  5.07s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:05<05:22,  2.43s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:06<03:29,  1.59s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:06<02:35,  1.19s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:07<02:04,  1.05it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:07<01:45,  1.22it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:08<01:34,  1.36it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:09<01:26,  1.46it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:09<01:23,  1.52it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:10<01:19,  1.57it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:10<01:16,  1.63it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:11<01:13,  1.68it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:11<01:10,  1.74it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:12<01:08,  1.77it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:12<01:06,  1.80it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:13<01:06,  1.79it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:14<01:06,  1.76it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:14<01:06,  1.77it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:15<01:05,  1.76it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:15<01:05,  1.76it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:16<01:03,  1.79it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:16<01:01,  1.82it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:17<01:01,  1.82it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:17<01:00,  1.82it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:18<01:00,  1.83it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:19<01:05,  1.65it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:20<01:11,  1.51it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:20<01:14,  1.44it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:21<01:16,  1.39it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:22<01:17,  1.35it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:23<01:23,  1.25it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:24<01:19,  1.29it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:24<01:12,  1.40it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:25<01:06,  1.51it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:25<01:02,  1.59it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:26<00:59,  1.67it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:26<00:57,  1.70it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:27<00:55,  1.73it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:27<00:55,  1.74it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:28<00:53,  1.76it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:29<00:52,  1.80it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:29<00:51,  1.82it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:30<00:49,  1.85it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:30<00:48,  1.86it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:31<00:47,  1.89it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:31<00:46,  1.90it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:32<00:46,  1.91it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:32<00:45,  1.91it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:33<00:44,  1.92it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:33<00:44,  1.91it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:34<00:44,  1.90it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:34<00:43,  1.90it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:35<00:42,  1.92it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:35<00:42,  1.92it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:36<00:41,  1.92it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:36<00:41,  1.90it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:37<00:40,  1.91it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:37<00:40,  1.89it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:38<00:40,  1.89it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:38<00:39,  1.89it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:39<00:39,  1.89it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:40<00:39,  1.83it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:40<00:39,  1.84it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:41<00:38,  1.85it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:41<00:37,  1.86it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:42<00:36,  1.87it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:42<00:36,  1.88it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:43<00:35,  1.88it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:43<00:35,  1.87it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:44<00:34,  1.88it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:44<00:33,  1.89it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:45<00:33,  1.88it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:45<00:33,  1.84it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:46<00:33,  1.83it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:47<00:32,  1.82it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:47<00:32,  1.83it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:48<00:31,  1.84it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:48<00:30,  1.84it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:49<00:30,  1.86it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:49<00:29,  1.87it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:50<00:28,  1.88it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:50<00:28,  1.88it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:51<00:28,  1.86it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:51<00:27,  1.85it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:52<00:27,  1.85it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:53<00:26,  1.85it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:53<00:25,  1.86it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:54<00:25,  1.86it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:54<00:24,  1.86it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:55<00:24,  1.86it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:55<00:23,  1.88it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:56<00:23,  1.86it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:56<00:22,  1.86it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:57<00:21,  1.87it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:57<00:21,  1.88it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:58<00:21,  1.86it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:58<00:20,  1.86it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [00:59<00:19,  1.87it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [00:59<00:19,  1.87it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:00<00:18,  1.88it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:01<00:17,  1.89it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:01<00:17,  1.90it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:02<00:16,  1.91it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:02<00:16,  1.93it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:03<00:15,  1.95it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:03<00:14,  1.97it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:04<00:14,  1.96it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:04<00:13,  1.96it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:05<00:13,  1.98it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:05<00:12,  1.98it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:06<00:12,  1.99it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:06<00:11,  1.99it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:07<00:10,  2.00it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:07<00:10,  1.99it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:08<00:10,  1.99it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:08<00:09,  1.99it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:09<00:09,  1.98it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:09<00:08,  1.99it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:10<00:08,  1.93it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:10<00:07,  1.91it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:11<00:07,  1.93it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:11<00:06,  1.93it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:12<00:06,  1.96it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:12<00:05,  1.97it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:13<00:05,  1.98it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:13<00:04,  1.99it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:14<00:04,  1.99it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:14<00:03,  2.00it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:15<00:03,  2.00it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:15<00:02,  2.00it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:16<00:02,  1.99it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:16<00:01,  1.98it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:17<00:01,  2.00it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:17<00:00,  2.00it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:19<00:00,  1.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: gpt2 & densenet161, \n",
            " accuracy: 0.5925925925925926, \n",
            " auc_roc: 0.5231481481481481, \n",
            " f1 score: 0.2857142857142857\n",
            "gpt2 vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 270 M \n",
            "--------------------------------------------------\n",
            "270 M     Trainable params\n",
            "0         Non-trainable params\n",
            "270 M     Total params\n",
            "1,082.482 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a386f8c8e27406390ffee0696d67bbf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa5204b723f849bf881b7d0e68662041",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1996c0bafab64d918cdc9ac10734e3aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.713\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.71273 (best 0.71273), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v16.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0eae0503c794a8fb8d794360023eba2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0ed5081a6144e2a9405b57b8604f6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15d20df1ce3f4d73a4ed2ea9d0085396",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.713. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:06<14:44,  6.60s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:07<06:51,  3.09s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:07<04:17,  1.95s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:08<03:06,  1.42s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:09<02:26,  1.13s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:09<02:02,  1.05it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:10<01:47,  1.19it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:10<01:37,  1.30it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:11<01:32,  1.37it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:12<01:26,  1.45it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:12<01:22,  1.50it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:13<01:20,  1.54it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:13<01:18,  1.56it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:14<01:17,  1.55it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:15<01:17,  1.54it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:15<01:16,  1.55it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:16<01:14,  1.58it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:17<01:14,  1.58it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:17<01:12,  1.60it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:18<01:11,  1.61it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:18<01:10,  1.63it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:19<01:09,  1.63it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:20<01:08,  1.64it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:20<01:07,  1.65it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:21<01:06,  1.65it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:22<01:06,  1.65it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:22<01:05,  1.65it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:23<01:04,  1.66it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:23<01:04,  1.65it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:24<01:03,  1.66it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:25<01:03,  1.65it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:25<01:02,  1.65it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:26<01:02,  1.64it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:26<01:01,  1.63it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:27<01:01,  1.64it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:28<01:00,  1.64it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:28<00:59,  1.64it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:29<00:58,  1.65it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:29<00:59,  1.61it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:30<00:59,  1.58it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:31<00:58,  1.60it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:31<00:57,  1.61it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:32<00:56,  1.62it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:33<00:55,  1.63it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:33<00:54,  1.64it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:34<00:54,  1.64it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:34<00:53,  1.64it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:35<00:52,  1.66it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:36<00:52,  1.65it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:36<00:51,  1.64it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:37<00:50,  1.65it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:37<00:51,  1.62it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:38<00:50,  1.63it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:39<00:49,  1.62it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:39<00:48,  1.63it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:40<00:48,  1.63it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:40<00:47,  1.64it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:41<00:46,  1.64it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:42<00:46,  1.64it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:42<00:45,  1.64it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:43<00:45,  1.62it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:44<00:44,  1.63it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:44<00:44,  1.63it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:45<00:44,  1.59it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:45<00:44,  1.57it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:46<00:44,  1.56it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:47<00:43,  1.57it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:47<00:41,  1.60it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:48<00:41,  1.61it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:49<00:39,  1.63it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:49<00:38,  1.64it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:50<00:38,  1.63it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:50<00:37,  1.64it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:51<00:37,  1.64it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:52<00:36,  1.64it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:52<00:36,  1.64it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:53<00:35,  1.64it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:53<00:35,  1.62it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:54<00:34,  1.63it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:55<00:33,  1.62it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:55<00:33,  1.63it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:56<00:32,  1.62it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:57<00:33,  1.58it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:57<00:32,  1.58it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:58<00:31,  1.60it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:58<00:30,  1.60it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:59<00:29,  1.61it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [01:00<00:29,  1.61it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [01:00<00:28,  1.61it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [01:01<00:27,  1.63it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:01<00:26,  1.65it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:02<00:26,  1.64it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:03<00:25,  1.64it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:03<00:25,  1.59it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:04<00:25,  1.56it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:05<00:24,  1.57it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:05<00:24,  1.58it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:06<00:23,  1.59it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:07<00:22,  1.61it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:07<00:21,  1.63it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:08<00:20,  1.63it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:08<00:20,  1.62it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:09<00:19,  1.64it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:10<00:18,  1.66it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:10<00:17,  1.68it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:11<00:17,  1.69it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:11<00:16,  1.71it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:12<00:15,  1.71it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:12<00:15,  1.70it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:13<00:15,  1.66it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:14<00:14,  1.65it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:14<00:14,  1.64it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:15<00:13,  1.59it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:16<00:13,  1.54it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:16<00:13,  1.53it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:17<00:12,  1.55it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:18<00:11,  1.58it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:18<00:10,  1.59it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:19<00:10,  1.58it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:19<00:09,  1.60it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:20<00:09,  1.49it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:21<00:08,  1.54it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:21<00:07,  1.57it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:22<00:07,  1.56it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:23<00:06,  1.57it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:23<00:05,  1.60it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:24<00:04,  1.61it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:25<00:04,  1.60it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:25<00:03,  1.57it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:26<00:03,  1.58it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:27<00:02,  1.56it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:27<00:01,  1.58it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:28<00:01,  1.58it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:28<00:00,  1.59it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:30<00:00,  1.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: gpt2 & vgg19_bn, \n",
            " accuracy: 0.5962962962962963, \n",
            " auc_roc: 0.532122559920929, \n",
            " f1 score: 0.3057324840764331\n",
            "distilgpt2 densenet161\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a269c948bc1f439192740c26e10c8bd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76c5844c939d47fdb1247325341bb624",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "603fefaa1bf347929e1936d933ce20ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae5330172d7040af9198ac3c9f66a53d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14ee70e650284d9aad7f1bbb2188cace",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 113 M \n",
            "--------------------------------------------------\n",
            "113 M     Trainable params\n",
            "0         Non-trainable params\n",
            "113 M     Total params\n",
            "452.384   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a26b85ba71e7410f9cc295c49fa3cd4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f35276a5954d40908e9fd0e098d9a4b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42aa1fa6ded54238840f09ddf08af1f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.708\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.70781 (best 0.70781), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v17.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1391b69b11044a2a2cc3b0200686ccf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5f0a5014ee54a0fa3cf76357f1e9aa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e73436031dcd482d9db85c5979b1c63b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.708. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:04<10:42,  4.79s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:05<04:59,  2.25s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:05<03:10,  1.44s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:06<02:19,  1.06s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:06<01:50,  1.18it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:07<01:32,  1.40it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:07<01:21,  1.57it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:08<01:13,  1.72it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:08<01:09,  1.82it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:09<01:05,  1.91it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:09<01:03,  1.94it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:10<01:03,  1.94it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:10<01:02,  1.96it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:11<01:01,  1.96it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:11<01:04,  1.87it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:12<01:02,  1.91it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:12<01:00,  1.96it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:13<00:58,  1.99it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:13<00:57,  2.02it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:14<00:56,  2.05it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:14<00:54,  2.08it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:14<00:53,  2.10it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:15<00:53,  2.11it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:15<00:52,  2.12it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:16<00:51,  2.12it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:16<00:51,  2.12it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:17<00:50,  2.13it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:17<00:49,  2.15it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:18<00:49,  2.15it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:18<00:50,  2.10it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:19<00:49,  2.09it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:19<00:49,  2.10it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:20<00:48,  2.09it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:20<00:48,  2.09it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:21<00:47,  2.10it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:21<00:46,  2.11it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:22<00:46,  2.11it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:22<00:46,  2.11it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:23<00:45,  2.10it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:23<00:45,  2.09it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:23<00:44,  2.12it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:24<00:44,  2.09it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:24<00:43,  2.11it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:25<00:42,  2.12it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:25<00:42,  2.12it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:26<00:42,  2.12it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:26<00:41,  2.12it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:27<00:41,  2.11it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:27<00:40,  2.11it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:28<00:40,  2.10it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:28<00:40,  2.09it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:29<00:39,  2.11it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:29<00:38,  2.13it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:30<00:38,  2.11it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:30<00:38,  2.10it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:31<00:37,  2.10it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:31<00:36,  2.11it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:32<00:36,  2.11it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:32<00:36,  2.09it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:32<00:35,  2.10it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:33<00:35,  2.10it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:33<00:34,  2.10it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:34<00:34,  2.10it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:34<00:33,  2.10it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:35<00:33,  2.11it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:35<00:32,  2.12it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:36<00:32,  2.10it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:36<00:32,  2.07it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:37<00:31,  2.09it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:37<00:31,  2.09it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:38<00:30,  2.11it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:38<00:29,  2.12it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:39<00:29,  2.10it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:39<00:29,  2.06it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:40<00:29,  2.04it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:40<00:29,  2.00it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:41<00:28,  2.01it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:41<00:28,  2.02it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:42<00:27,  2.03it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:42<00:26,  2.06it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:43<00:25,  2.09it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:43<00:25,  2.10it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:44<00:24,  2.10it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:44<00:24,  2.08it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:45<00:24,  2.03it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:45<00:23,  2.05it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:46<00:23,  2.08it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:46<00:22,  2.08it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:46<00:22,  2.08it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:47<00:21,  2.10it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:47<00:20,  2.11it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:48<00:20,  2.12it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:48<00:19,  2.11it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:49<00:19,  2.10it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:49<00:18,  2.11it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:50<00:18,  2.11it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:50<00:18,  2.10it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [00:51<00:17,  2.11it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [00:51<00:16,  2.12it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [00:52<00:16,  2.10it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [00:52<00:16,  2.11it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [00:53<00:15,  2.10it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [00:53<00:15,  2.10it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [00:54<00:14,  2.11it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [00:54<00:13,  2.15it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [00:54<00:13,  2.17it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [00:55<00:12,  2.17it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [00:55<00:12,  2.18it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [00:56<00:12,  2.16it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [00:56<00:11,  2.08it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [00:57<00:11,  2.08it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [00:57<00:10,  2.10it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [00:58<00:10,  2.09it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [00:58<00:10,  2.08it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [00:59<00:09,  2.06it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [00:59<00:09,  2.06it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:00<00:08,  2.05it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:00<00:08,  2.06it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:01<00:07,  2.07it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:01<00:07,  2.08it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:02<00:06,  2.07it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:02<00:06,  2.06it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:03<00:05,  2.05it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:03<00:05,  2.07it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:04<00:04,  2.06it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:04<00:04,  2.07it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:05<00:03,  2.07it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:05<00:03,  2.04it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:06<00:02,  2.01it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:06<00:02,  2.05it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:07<00:01,  2.04it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:07<00:01,  2.03it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:08<00:00,  2.05it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:08<00:00,  2.06it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:09<00:00,  1.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: distilgpt2 & densenet161, \n",
            " accuracy: 0.6037037037037037, \n",
            " auc_roc: 0.5299175382139983, \n",
            " f1 score: 0.2569444444444445\n",
            "distilgpt2 vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 228 M \n",
            "--------------------------------------------------\n",
            "228 M     Trainable params\n",
            "0         Non-trainable params\n",
            "228 M     Total params\n",
            "912.373   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ed5ed862caa4bc98971225fcc257b45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba3a99ce853b4167b0ef512132f4b11d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b907ed1cd69a406ca609c883edddbe1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.705\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.70473 (best 0.70473), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v18.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a02f7ca070f6430aa394fb74655254a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e316d1fb17a84b34b6b968a028cc33fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da9439683aea4637a02c5cc8d5e594ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.705. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt', 'model-outputs/epoch=0-step=95-v18.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:05<13:05,  5.86s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:06<06:10,  2.79s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:07<03:57,  1.80s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:07<02:54,  1.34s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:08<02:20,  1.08s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:08<01:58,  1.09it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:09<01:44,  1.23it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:10<01:36,  1.32it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:10<01:33,  1.34it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:11<01:30,  1.39it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:12<01:25,  1.44it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:12<01:22,  1.49it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:13<01:19,  1.53it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:14<01:18,  1.55it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:14<01:16,  1.57it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:15<01:16,  1.56it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:16<01:15,  1.55it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:16<01:14,  1.56it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:17<01:13,  1.57it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:17<01:13,  1.56it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:18<01:12,  1.56it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:19<01:11,  1.58it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:19<01:10,  1.60it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:20<01:09,  1.59it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:21<01:08,  1.60it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:21<01:07,  1.61it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:22<01:07,  1.60it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:22<01:06,  1.61it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:23<01:04,  1.64it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:24<01:03,  1.65it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:24<01:02,  1.67it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:25<01:01,  1.68it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:25<01:00,  1.67it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:26<01:00,  1.68it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:27<00:59,  1.69it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:27<00:58,  1.69it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:28<00:58,  1.68it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:28<00:57,  1.70it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:29<00:56,  1.69it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:29<00:56,  1.69it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:30<00:55,  1.69it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:31<00:55,  1.68it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:31<00:54,  1.68it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:32<00:53,  1.69it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:32<00:52,  1.70it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:33<00:52,  1.70it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:34<00:51,  1.71it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:34<00:50,  1.71it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:35<00:50,  1.72it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:35<00:49,  1.70it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:36<00:49,  1.71it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:37<00:48,  1.71it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:37<00:48,  1.70it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:38<00:47,  1.70it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:38<00:47,  1.68it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:39<00:47,  1.68it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:40<00:46,  1.67it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:40<00:45,  1.68it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:41<00:45,  1.66it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:41<00:46,  1.63it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:42<00:45,  1.64it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:43<00:44,  1.65it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:43<00:43,  1.66it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:44<00:42,  1.66it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:44<00:42,  1.66it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:45<00:41,  1.67it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:46<00:40,  1.67it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:46<00:40,  1.66it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:47<00:39,  1.67it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:47<00:38,  1.68it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:48<00:37,  1.69it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:49<00:37,  1.69it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:49<00:36,  1.69it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:50<00:35,  1.70it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:50<00:35,  1.70it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:51<00:34,  1.70it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:51<00:34,  1.70it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:52<00:33,  1.70it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:53<00:33,  1.70it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:53<00:32,  1.69it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:54<00:32,  1.68it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:54<00:31,  1.68it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:55<00:31,  1.67it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:56<00:30,  1.67it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:56<00:29,  1.67it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:57<00:29,  1.68it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:57<00:28,  1.69it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:58<00:27,  1.69it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:59<00:27,  1.70it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:59<00:26,  1.71it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:00<00:25,  1.71it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:00<00:25,  1.71it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:01<00:24,  1.69it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:02<00:24,  1.68it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:02<00:23,  1.68it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:03<00:23,  1.68it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:03<00:22,  1.69it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:04<00:22,  1.68it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:05<00:21,  1.68it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:05<00:20,  1.68it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:06<00:20,  1.70it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:06<00:19,  1.70it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:07<00:18,  1.69it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:07<00:18,  1.70it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:08<00:17,  1.72it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:09<00:16,  1.73it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:09<00:16,  1.74it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:10<00:15,  1.74it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:10<00:14,  1.74it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:11<00:14,  1.74it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:11<00:14,  1.69it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:12<00:13,  1.67it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:13<00:13,  1.69it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:13<00:12,  1.70it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:14<00:11,  1.72it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:14<00:10,  1.73it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:15<00:10,  1.73it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:16<00:09,  1.74it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:16<00:09,  1.75it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:17<00:08,  1.74it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:17<00:08,  1.73it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:18<00:07,  1.74it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:18<00:06,  1.74it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:19<00:06,  1.74it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:20<00:05,  1.75it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:20<00:05,  1.74it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:21<00:04,  1.74it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:21<00:04,  1.75it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:22<00:03,  1.74it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:22<00:02,  1.74it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:23<00:02,  1.74it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:24<00:01,  1.74it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:24<00:01,  1.73it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:25<00:00,  1.74it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:26<00:00,  1.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: distilgpt2 & vgg19_bn, \n",
            " accuracy: 0.6092592592592593, \n",
            " auc_roc: 0.5462346918063105, \n",
            " f1 score: 0.29900332225913623\n",
            "albert-base-v2 densenet161\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aa1c1449a78489db9ba7578229008f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b988e538f2184a358ce401f5b2820efc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8255b46bb7cc4507b8880422959db99c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "184c788951da4062ab3bf71a1ab4dd9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 42.9 M\n",
            "--------------------------------------------------\n",
            "42.9 M    Trainable params\n",
            "0         Non-trainable params\n",
            "42.9 M    Total params\n",
            "171.468   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dad8943b0cf84da0be32386fa44b0e0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81cf73988d7249f5839cc053b9df26d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edf2ee75d9764b94a8e0824faa9bb587",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.711\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.71073 (best 0.71073), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v19.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "934bd56c50744ddcbe67db6ab35c8ac1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' reached 0.71034 (best 0.71034), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=1-step=190-v11.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed5a656345954cdfad6ad5a13e2d5819",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.018 >= min_delta = 0.001. New best score: 0.693\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' reached 0.69267 (best 0.69267), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=2-step=285-v1.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2ea1ce60e3e4070af24e1b96ee4b0d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b17627aad244e8885499d9ab8d159d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 475: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d60c07322bf147748a4752d21a95e508",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.693. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 570: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt', 'model-outputs/epoch=0-step=95-v18.ckpt', 'model-outputs/epoch=2-step=285-v1.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:04<09:58,  4.47s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:05<04:46,  2.15s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:05<03:07,  1.42s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:06<02:19,  1.07s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:06<01:53,  1.14it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:07<01:37,  1.32it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:07<01:26,  1.47it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:08<01:20,  1.58it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:08<01:15,  1.67it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:09<01:12,  1.73it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:09<01:09,  1.78it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:10<01:07,  1.81it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:10<01:06,  1.84it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:11<01:05,  1.85it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:11<01:04,  1.87it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:12<01:03,  1.88it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:12<01:02,  1.88it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:13<01:02,  1.87it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:14<01:02,  1.85it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:14<01:01,  1.86it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:15<01:01,  1.86it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:15<01:00,  1.87it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:16<00:59,  1.87it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:16<00:58,  1.88it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:17<00:58,  1.89it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:17<00:57,  1.89it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:18<00:57,  1.89it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:18<00:56,  1.90it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:19<00:55,  1.90it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:19<00:55,  1.89it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:20<00:54,  1.89it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:20<00:54,  1.90it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:21<00:55,  1.85it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:21<00:54,  1.87it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:22<00:53,  1.86it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:23<00:52,  1.88it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:23<00:52,  1.87it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:24<00:51,  1.89it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:24<00:51,  1.86it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:25<00:50,  1.86it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:25<00:50,  1.87it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:26<00:50,  1.85it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:26<00:49,  1.86it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:27<00:48,  1.86it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:27<00:48,  1.86it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:28<00:47,  1.87it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:28<00:47,  1.86it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:29<00:46,  1.87it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:30<00:45,  1.89it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:30<00:45,  1.89it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:31<00:45,  1.84it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:31<00:45,  1.81it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:32<00:45,  1.81it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:32<00:44,  1.83it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:33<00:43,  1.84it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:33<00:42,  1.85it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:34<00:41,  1.87it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:34<00:41,  1.85it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:35<00:40,  1.86it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:36<00:40,  1.85it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:36<00:39,  1.86it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:37<00:39,  1.85it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:37<00:39,  1.82it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:38<00:39,  1.81it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:38<00:38,  1.82it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:39<00:37,  1.84it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:39<00:36,  1.86it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:40<00:36,  1.85it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:40<00:35,  1.86it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:41<00:35,  1.85it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:41<00:34,  1.86it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:42<00:34,  1.85it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:43<00:33,  1.86it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:43<00:32,  1.87it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:44<00:32,  1.86it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:44<00:31,  1.86it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:45<00:30,  1.88it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:45<00:30,  1.88it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:46<00:29,  1.89it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:46<00:29,  1.88it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:47<00:28,  1.88it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:47<00:28,  1.89it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:48<00:27,  1.86it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:48<00:27,  1.86it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:49<00:26,  1.85it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:49<00:26,  1.87it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:50<00:25,  1.87it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:51<00:25,  1.87it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:51<00:24,  1.88it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:52<00:23,  1.88it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:52<00:23,  1.88it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:53<00:22,  1.88it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:53<00:22,  1.87it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:54<00:22,  1.85it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:54<00:21,  1.84it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:55<00:21,  1.82it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:55<00:20,  1.85it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [00:56<00:19,  1.85it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [00:56<00:19,  1.87it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [00:57<00:18,  1.87it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [00:58<00:18,  1.88it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [00:58<00:17,  1.88it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [00:59<00:17,  1.88it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [00:59<00:16,  1.89it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:00<00:15,  1.91it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:00<00:15,  1.92it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:01<00:14,  1.94it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:01<00:14,  1.91it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:02<00:13,  1.88it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:02<00:13,  1.85it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:03<00:12,  1.85it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:03<00:12,  1.86it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:04<00:11,  1.90it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:04<00:10,  1.91it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:05<00:10,  1.94it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:05<00:09,  1.96it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:06<00:09,  1.97it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:06<00:08,  1.97it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:07<00:08,  1.97it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:07<00:07,  1.97it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:08<00:07,  1.97it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:08<00:06,  1.96it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:09<00:06,  1.98it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:09<00:05,  1.98it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:10<00:05,  1.99it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:10<00:04,  1.97it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:11<00:04,  1.95it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:11<00:03,  1.96it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:12<00:03,  1.98it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:12<00:02,  1.98it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:13<00:02,  1.99it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:13<00:01,  1.98it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:14<00:01,  1.99it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:14<00:00,  1.97it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:16<00:00,  1.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: albert-base-v2 & densenet161, \n",
            " accuracy: 0.5833333333333334, \n",
            " auc_roc: 0.5413635715304521, \n",
            " f1 score: 0.39353099730458224\n",
            "albert-base-v2 vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 157 M \n",
            "--------------------------------------------------\n",
            "157 M     Trainable params\n",
            "0         Non-trainable params\n",
            "157 M     Total params\n",
            "631.457   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "732ff1c800f448b2ac16757fd041a80d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fa80b6fb0eb4223ad68bea690b8d9ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9daa27b161b46f58daf7e83e1e659e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.697\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.69743 (best 0.69743), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v19.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9db4119e4b744707b8b8c1933e82efff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d59fe30179d439c9ee51cd872402536",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ec5523308194e1bbe60d506053bfafa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.697. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt', 'model-outputs/epoch=0-step=95-v18.ckpt', 'model-outputs/epoch=2-step=285-v1.ckpt', 'model-outputs/epoch=0-step=95-v19.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:04<11:05,  4.96s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:05<05:18,  2.40s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:06<03:28,  1.58s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:06<02:37,  1.20s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:07<02:08,  1.01it/s]\u001b[A\n",
            "  4%|▍         | 6/135 [00:07<01:50,  1.17it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:08<01:38,  1.30it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:09<01:42,  1.24it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:10<01:33,  1.35it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:10<01:26,  1.44it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:11<01:23,  1.49it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:11<01:19,  1.54it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:12<01:17,  1.57it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:13<01:16,  1.58it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:13<01:14,  1.61it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:14<01:13,  1.62it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:14<01:12,  1.63it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:15<01:11,  1.63it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:16<01:11,  1.63it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:16<01:12,  1.59it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:17<01:12,  1.57it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:18<01:13,  1.54it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:18<01:12,  1.55it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:19<01:10,  1.58it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:19<01:08,  1.61it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:20<01:07,  1.62it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:21<01:06,  1.64it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:21<01:04,  1.66it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:22<01:04,  1.65it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:22<01:03,  1.66it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:23<01:02,  1.67it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:24<01:01,  1.67it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:24<01:01,  1.67it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:25<01:00,  1.66it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:25<01:00,  1.66it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:26<00:59,  1.67it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:27<00:58,  1.66it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:27<00:57,  1.68it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:28<00:57,  1.66it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:28<00:57,  1.65it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:29<00:56,  1.65it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:30<00:56,  1.65it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:30<00:55,  1.64it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:31<00:55,  1.64it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:32<00:54,  1.65it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:32<00:53,  1.65it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:33<00:53,  1.66it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:33<00:52,  1.65it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:34<00:51,  1.67it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:35<00:51,  1.65it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:35<00:50,  1.66it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:36<00:50,  1.66it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:36<00:49,  1.67it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:37<00:48,  1.66it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:38<00:48,  1.65it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:38<00:47,  1.65it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:39<00:47,  1.66it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:39<00:46,  1.66it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:40<00:45,  1.66it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:41<00:45,  1.67it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:41<00:44,  1.66it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:42<00:43,  1.67it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:42<00:43,  1.66it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:43<00:42,  1.66it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:44<00:42,  1.66it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:44<00:41,  1.66it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:45<00:40,  1.66it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:45<00:40,  1.66it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:46<00:39,  1.66it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:47<00:38,  1.67it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:47<00:38,  1.66it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:48<00:38,  1.63it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:48<00:38,  1.63it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:49<00:37,  1.64it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:50<00:36,  1.65it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:50<00:35,  1.65it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:51<00:34,  1.66it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:51<00:34,  1.65it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:52<00:34,  1.64it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:53<00:33,  1.63it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:53<00:34,  1.58it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:54<00:34,  1.54it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:55<00:33,  1.55it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:55<00:32,  1.58it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:56<00:31,  1.60it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:57<00:30,  1.62it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:57<00:29,  1.63it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:58<00:28,  1.64it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:58<00:27,  1.65it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:59<00:27,  1.65it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:00<00:26,  1.65it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:00<00:25,  1.66it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:01<00:25,  1.65it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:01<00:24,  1.66it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:02<00:24,  1.66it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:03<00:23,  1.65it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:03<00:22,  1.66it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:04<00:22,  1.65it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:04<00:21,  1.66it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:05<00:21,  1.65it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:06<00:20,  1.66it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:06<00:19,  1.66it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:07<00:19,  1.67it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:07<00:18,  1.69it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:08<00:17,  1.71it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:08<00:16,  1.72it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:09<00:16,  1.73it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:10<00:15,  1.73it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:10<00:15,  1.73it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:11<00:14,  1.74it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:11<00:13,  1.75it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:12<00:13,  1.74it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:12<00:12,  1.75it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:13<00:11,  1.75it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:14<00:11,  1.74it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:14<00:10,  1.74it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:15<00:10,  1.75it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:15<00:09,  1.74it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:16<00:09,  1.74it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:16<00:08,  1.75it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:17<00:08,  1.74it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:18<00:07,  1.70it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:18<00:07,  1.66it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:19<00:06,  1.64it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:20<00:06,  1.65it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:20<00:05,  1.68it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:21<00:04,  1.69it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:21<00:04,  1.71it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:22<00:03,  1.73it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:22<00:02,  1.72it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:23<00:02,  1.73it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:24<00:01,  1.73it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:24<00:01,  1.74it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:25<00:00,  1.75it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:26<00:00,  1.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: albert-base-v2 & vgg19_bn, \n",
            " accuracy: 0.5740740740740741, \n",
            " auc_roc: 0.5338320193680551, \n",
            " f1 score: 0.3915343915343915\n",
            "xlm-roberta-base densenet161\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f72a3346a3c4dd6a83e203b8ad13ea4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2a9f848b06c43f08a9a664a13cbe1f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2730114d87b041adb63270a150d23285",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e83cca1d2b4418ab155f19485b680ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 309 M \n",
            "--------------------------------------------------\n",
            "309 M     Trainable params\n",
            "0         Non-trainable params\n",
            "309 M     Total params\n",
            "1,236.908 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc0ea0b632254598914d096baa5bc3ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3d16fba95694906836728ec53c3ead9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29716123fed84fca86e5a815e3176a0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.704\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.70432 (best 0.70432), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v20.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4880042ac174efcbfd248f0f3c8b5eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.015 >= min_delta = 0.001. New best score: 0.690\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' reached 0.68962 (best 0.68962), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=1-step=190-v11.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4003c831b6204b219f5bbab8ed62e784",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31782d8efe1446ff9bab2e6d32bd48df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b19e6c9a3cda496fb27305f6bbb052f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.690. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 475: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt', 'model-outputs/epoch=0-step=95-v18.ckpt', 'model-outputs/epoch=2-step=285-v1.ckpt', 'model-outputs/epoch=0-step=95-v19.ckpt', 'model-outputs/epoch=1-step=190-v11.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:09<21:45,  9.74s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:10<09:50,  4.44s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:11<05:59,  2.72s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:11<04:11,  1.92s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:12<03:12,  1.48s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:13<02:38,  1.23s/it]\u001b[A\n",
            "  5%|▌         | 7/135 [00:13<02:13,  1.04s/it]\u001b[A\n",
            "  6%|▌         | 8/135 [00:14<01:58,  1.07it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:15<01:46,  1.18it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:15<01:37,  1.28it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:16<01:32,  1.34it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:17<01:27,  1.40it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:17<01:24,  1.45it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:18<01:21,  1.48it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:19<01:20,  1.49it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:19<01:18,  1.51it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:20<01:17,  1.52it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:21<01:16,  1.53it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:21<01:15,  1.53it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:22<01:17,  1.49it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:23<01:18,  1.45it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:23<01:17,  1.46it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:24<01:15,  1.49it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:25<01:13,  1.51it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:25<01:13,  1.51it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:26<01:11,  1.52it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:27<01:10,  1.54it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:27<01:09,  1.53it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:28<01:10,  1.51it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:29<01:08,  1.52it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:29<01:08,  1.53it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:30<01:06,  1.54it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:31<01:05,  1.55it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:32<01:16,  1.33it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:33<01:23,  1.20it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:33<01:20,  1.23it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:34<01:14,  1.32it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:35<01:09,  1.40it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:35<01:05,  1.46it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:36<01:03,  1.50it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:36<01:01,  1.54it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:37<00:59,  1.55it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:38<00:58,  1.58it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:38<00:56,  1.61it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:39<00:55,  1.62it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:39<00:55,  1.62it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:40<00:59,  1.47it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:41<00:58,  1.47it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:42<00:56,  1.51it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:42<00:54,  1.55it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:43<00:53,  1.58it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:43<00:51,  1.61it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:44<00:50,  1.62it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:45<00:50,  1.62it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:45<00:49,  1.62it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:46<00:48,  1.62it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:46<00:48,  1.62it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:47<00:47,  1.63it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:48<00:46,  1.62it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:48<00:45,  1.63it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:49<00:45,  1.63it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:50<00:44,  1.63it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:50<00:44,  1.63it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:51<00:44,  1.61it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:51<00:43,  1.61it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:52<00:43,  1.59it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:53<00:43,  1.58it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:53<00:42,  1.56it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:54<00:42,  1.57it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:55<00:41,  1.58it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:55<00:40,  1.60it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:56<00:39,  1.60it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:56<00:38,  1.61it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:57<00:37,  1.61it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:58<00:36,  1.62it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:58<00:36,  1.63it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:59<00:35,  1.63it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [01:00<00:35,  1.62it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [01:00<00:34,  1.62it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [01:01<00:34,  1.62it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [01:01<00:33,  1.63it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [01:02<00:32,  1.63it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [01:03<00:31,  1.63it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [01:03<00:31,  1.63it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [01:04<00:32,  1.56it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [01:05<00:33,  1.45it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [01:05<00:34,  1.41it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [01:06<00:34,  1.35it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [01:07<00:34,  1.33it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [01:08<00:33,  1.35it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:09<00:32,  1.34it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:09<00:30,  1.41it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:10<00:28,  1.46it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:10<00:27,  1.51it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:11<00:26,  1.54it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:12<00:25,  1.55it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:12<00:24,  1.57it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:13<00:23,  1.59it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:13<00:22,  1.60it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:14<00:21,  1.60it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:15<00:21,  1.60it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:15<00:20,  1.61it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:16<00:19,  1.62it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:17<00:18,  1.64it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:17<00:18,  1.66it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:18<00:17,  1.67it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:18<00:16,  1.68it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:19<00:16,  1.69it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:20<00:16,  1.56it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:21<00:17,  1.40it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:21<00:17,  1.36it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:22<00:17,  1.33it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:23<00:16,  1.32it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:24<00:15,  1.33it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:24<00:14,  1.39it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:25<00:12,  1.47it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:25<00:11,  1.53it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:26<00:10,  1.57it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:27<00:09,  1.61it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:27<00:09,  1.64it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:28<00:08,  1.65it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:28<00:07,  1.67it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:29<00:07,  1.67it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:30<00:06,  1.67it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:30<00:05,  1.70it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:31<00:05,  1.71it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:31<00:04,  1.71it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:32<00:04,  1.69it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:33<00:03,  1.66it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:33<00:02,  1.67it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:34<00:02,  1.68it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:34<00:01,  1.69it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:35<00:01,  1.71it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:35<00:00,  1.72it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:37<00:00,  1.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: xlm-roberta-base & densenet161, \n",
            " accuracy: 0.5944444444444444, \n",
            " auc_roc: 0.5725472624077156, \n",
            " f1 score: 0.477326968973747\n",
            "xlm-roberta-base vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 424 M \n",
            "--------------------------------------------------\n",
            "424 M     Trainable params\n",
            "0         Non-trainable params\n",
            "424 M     Total params\n",
            "1,696.897 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b65efefb1634749b9f388b3b1f0e1b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b149a66f253c4074a37df90e7e91ac8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6498cce989484dfca53ffd8fc044b64f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.701\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.70110 (best 0.70110), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v20.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46f71c00ad5e43bda36b9112cc906a48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2748c4c0ba02443582a0c4db87d054ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' reached 0.70087 (best 0.70087), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=2-step=285-v2.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9775e98f8bbd4450b96dde859905585b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.701. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt', 'model-outputs/epoch=0-step=95-v18.ckpt', 'model-outputs/epoch=2-step=285-v1.ckpt', 'model-outputs/epoch=0-step=95-v19.ckpt', 'model-outputs/epoch=1-step=190-v11.ckpt', 'model-outputs/epoch=2-step=285-v2.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:09<21:07,  9.46s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:10<09:38,  4.35s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:11<05:59,  2.72s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:11<04:13,  1.93s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:12<03:13,  1.49s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:13<02:36,  1.21s/it]\u001b[A\n",
            "  5%|▌         | 7/135 [00:13<02:12,  1.04s/it]\u001b[A\n",
            "  6%|▌         | 8/135 [00:14<01:55,  1.10it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:15<01:45,  1.19it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:15<01:37,  1.28it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:16<01:32,  1.33it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:17<01:28,  1.39it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:17<01:25,  1.43it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:18<01:23,  1.46it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:19<01:20,  1.48it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:19<01:19,  1.49it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:20<01:19,  1.48it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:21<01:18,  1.49it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:21<01:20,  1.45it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:22<01:20,  1.43it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:23<01:19,  1.44it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:23<01:17,  1.45it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:24<01:17,  1.45it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:25<01:15,  1.47it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:25<01:14,  1.47it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:26<01:13,  1.48it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:27<01:12,  1.49it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:27<01:11,  1.50it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:28<01:10,  1.50it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:29<01:12,  1.45it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:30<01:26,  1.20it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:31<01:39,  1.03it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:33<01:49,  1.07s/it]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:34<01:54,  1.13s/it]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:35<01:55,  1.15s/it]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:36<01:49,  1.10s/it]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:37<01:35,  1.02it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:37<01:26,  1.12it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:38<01:19,  1.21it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:39<01:13,  1.29it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:39<01:09,  1.35it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:40<01:06,  1.39it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:41<01:04,  1.42it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:41<01:02,  1.44it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:42<01:01,  1.46it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:43<01:00,  1.48it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:43<00:58,  1.49it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:44<00:57,  1.50it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:45<00:56,  1.52it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:45<00:55,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:46<00:55,  1.51it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:47<00:54,  1.52it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:47<00:53,  1.52it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:48<00:53,  1.51it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:49<00:53,  1.50it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:49<00:52,  1.49it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:50<00:51,  1.51it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:51<00:51,  1.51it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:51<00:51,  1.48it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:52<00:52,  1.43it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:53<00:51,  1.44it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:53<00:49,  1.46it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:54<00:49,  1.45it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:55<00:48,  1.47it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:55<00:47,  1.47it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:56<00:46,  1.47it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:57<00:46,  1.48it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:58<00:45,  1.48it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:58<00:44,  1.49it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:59<00:44,  1.46it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [01:00<00:43,  1.46it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [01:00<00:43,  1.46it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [01:01<00:42,  1.46it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [01:02<00:41,  1.47it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [01:02<00:40,  1.48it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [01:03<00:39,  1.49it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [01:04<00:39,  1.48it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [01:04<00:38,  1.47it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [01:05<00:37,  1.47it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [01:06<00:36,  1.49it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [01:06<00:35,  1.50it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [01:07<00:35,  1.50it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [01:08<00:34,  1.49it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [01:08<00:33,  1.50it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [01:09<00:33,  1.50it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [01:10<00:32,  1.49it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [01:10<00:31,  1.51it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [01:11<00:31,  1.51it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [01:12<00:30,  1.50it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [01:12<00:29,  1.50it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:13<00:29,  1.51it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:14<00:28,  1.50it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:14<00:27,  1.51it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:15<00:27,  1.51it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:16<00:26,  1.51it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:16<00:25,  1.50it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:17<00:25,  1.50it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:18<00:24,  1.51it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:18<00:23,  1.52it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:19<00:23,  1.52it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:20<00:22,  1.52it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:20<00:21,  1.51it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:21<00:21,  1.51it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:22<00:20,  1.53it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:22<00:19,  1.52it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:23<00:19,  1.52it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:24<00:18,  1.52it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:24<00:17,  1.53it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:25<00:16,  1.54it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:25<00:16,  1.54it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:26<00:15,  1.55it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:27<00:14,  1.56it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:27<00:14,  1.56it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:28<00:13,  1.56it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:29<00:12,  1.57it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:29<00:12,  1.58it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:30<00:11,  1.58it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:31<00:10,  1.57it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:31<00:10,  1.57it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:32<00:09,  1.57it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:32<00:08,  1.57it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:34<00:09,  1.31it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:34<00:09,  1.33it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:35<00:07,  1.40it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:36<00:07,  1.42it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:36<00:06,  1.45it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:37<00:05,  1.49it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:37<00:04,  1.52it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:38<00:03,  1.53it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:39<00:03,  1.52it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:39<00:02,  1.51it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:40<00:01,  1.53it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:41<00:01,  1.50it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:41<00:00,  1.49it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:43<00:00,  1.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: xlm-roberta-base & vgg19_bn, \n",
            " accuracy: 0.5648148148148148, \n",
            " auc_roc: 0.5391954171512254, \n",
            " f1 score: 0.43099273607748184\n",
            "squeezebert/squeezebert-uncased densenet161\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b66c16905a2445a82de1a6461ee7e89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/500 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf0329dd90e243b1aea9a3a0af11d3d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "013b995c30a345e189def7e935c47bef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c18192a6142476e83ca621e0fae2ed3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/103M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 82.3 M\n",
            "--------------------------------------------------\n",
            "82.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "82.3 M    Total params\n",
            "329.111   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b581f3489d8140488445e4d622fd2f91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69d7ea6569ba4cb4a52d16f1453e7545",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a54d0aa13b244275aff70596ba3a7d5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.703\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.70296 (best 0.70296), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v20.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ee4681318ca419d96d15d82b517814e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved by 0.017 >= min_delta = 0.001. New best score: 0.686\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' reached 0.68593 (best 0.68593), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=1-step=190-v12.ckpt' as top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af84f925cb2c4e24af4b90241111d64f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e982f50319c347fe95dc32634a76c758",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c51323ec44249c5b6b48d9e7bf34691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.686. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 475: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt', 'model-outputs/epoch=0-step=95-v18.ckpt', 'model-outputs/epoch=2-step=285-v1.ckpt', 'model-outputs/epoch=0-step=95-v19.ckpt', 'model-outputs/epoch=1-step=190-v11.ckpt', 'model-outputs/epoch=2-step=285-v2.ckpt', 'model-outputs/epoch=1-step=190-v12.ckpt']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:07<16:39,  7.46s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:07<07:29,  3.38s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:08<04:36,  2.09s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:09<03:14,  1.48s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:09<02:31,  1.16s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:10<02:03,  1.05it/s]\u001b[A\n",
            "  5%|▌         | 7/135 [00:10<01:45,  1.21it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:11<01:32,  1.37it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:11<01:24,  1.49it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:12<01:17,  1.60it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:12<01:12,  1.70it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:13<01:09,  1.76it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:13<01:07,  1.82it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:14<01:05,  1.86it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:14<01:03,  1.89it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:15<01:01,  1.92it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:15<01:01,  1.90it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:16<01:00,  1.93it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:16<00:59,  1.94it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:17<00:58,  1.95it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:18<00:58,  1.95it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:18<00:57,  1.96it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:19<00:56,  1.97it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:19<00:56,  1.98it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:20<00:55,  1.98it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:20<00:54,  2.00it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:21<00:54,  2.00it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:21<00:53,  1.99it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:22<00:53,  1.97it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:22<00:52,  1.99it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:23<00:52,  1.99it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:23<00:51,  1.98it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:24<00:51,  1.99it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:24<00:52,  1.94it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:25<00:51,  1.94it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:25<00:52,  1.88it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:26<00:52,  1.87it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:26<00:51,  1.87it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:27<00:51,  1.86it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:27<00:51,  1.86it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:28<00:53,  1.76it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:29<00:57,  1.61it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:29<00:58,  1.58it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:30<00:55,  1.65it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:30<00:52,  1.71it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:31<00:50,  1.77it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:32<00:49,  1.79it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:32<00:48,  1.81it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:33<00:47,  1.81it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:33<00:46,  1.83it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:34<00:45,  1.84it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:34<00:45,  1.84it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:35<00:44,  1.84it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:35<00:43,  1.85it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:36<00:43,  1.86it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:36<00:42,  1.84it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:37<00:42,  1.83it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:37<00:42,  1.81it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:38<00:41,  1.84it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:39<00:40,  1.83it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:39<00:40,  1.84it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:40<00:40,  1.79it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:40<00:41,  1.74it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:41<00:40,  1.74it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:41<00:40,  1.74it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:42<00:38,  1.78it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:43<00:37,  1.82it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:43<00:36,  1.84it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:44<00:35,  1.84it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:44<00:35,  1.85it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:45<00:34,  1.85it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:45<00:34,  1.85it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:46<00:33,  1.86it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:46<00:32,  1.86it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:47<00:32,  1.87it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:47<00:31,  1.88it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:48<00:30,  1.89it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:48<00:30,  1.87it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:49<00:29,  1.88it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:49<00:29,  1.86it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:50<00:28,  1.87it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:51<00:28,  1.87it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:51<00:27,  1.86it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:52<00:27,  1.87it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:52<00:26,  1.87it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:53<00:26,  1.85it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:53<00:25,  1.86it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:54<00:25,  1.87it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:54<00:24,  1.89it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:55<00:23,  1.91it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [00:55<00:22,  1.92it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [00:56<00:22,  1.92it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [00:56<00:21,  1.92it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [00:57<00:21,  1.93it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [00:57<00:20,  1.94it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [00:58<00:19,  1.95it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [00:58<00:19,  1.95it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [00:59<00:18,  1.96it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [00:59<00:18,  1.97it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:00<00:17,  1.96it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:00<00:17,  1.96it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:01<00:16,  1.95it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:01<00:16,  1.95it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:02<00:15,  1.96it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:02<00:15,  1.98it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:03<00:14,  1.99it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:03<00:14,  2.00it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:04<00:13,  2.00it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:04<00:12,  2.04it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:05<00:12,  2.05it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:05<00:11,  2.05it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:06<00:11,  2.05it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:06<00:10,  2.07it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:07<00:10,  2.03it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:07<00:09,  2.05it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:08<00:09,  2.05it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:08<00:08,  2.06it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:09<00:08,  2.05it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:09<00:07,  2.06it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:10<00:07,  2.02it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:10<00:07,  1.98it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:11<00:06,  1.97it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:11<00:06,  1.96it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:12<00:05,  1.99it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:12<00:04,  2.01it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:13<00:04,  2.01it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:13<00:03,  2.02it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:14<00:03,  2.04it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:14<00:02,  2.05it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:15<00:02,  2.05it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:15<00:01,  2.07it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:16<00:01,  2.08it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:16<00:00,  2.09it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:17<00:00,  2.10it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:18<00:00,  1.72it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " model: squeezebert/squeezebert-uncased & densenet161, \n",
            " accuracy: 0.6, \n",
            " auc_roc: 0.566791586073501, \n",
            " f1 score: 0.44329896907216493\n",
            "squeezebert/squeezebert-uncased vgg19_bn\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                    | Params\n",
            "--------------------------------------------------\n",
            "0 | model | LanguageAndVisionConcat | 197 M \n",
            "--------------------------------------------------\n",
            "197 M     Trainable params\n",
            "0         Non-trainable params\n",
            "197 M     Total params\n",
            "789.100   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b3df5a283dc4fc4882c5fcd049c9247",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b9e6f635719496fb8c5021479e1661b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79b56bdd1c54375916fbb7ba7449643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric avg_val_loss improved. New best score: 0.697\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 95: 'avg_val_loss' reached 0.69701 (best 0.69701), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=0-step=95-v20.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ce17abc0b364ab79acb2eb4fef12953"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 190: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7571461b23c4d87adc385588af0bf26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 285: 'avg_val_loss' was not in top 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "688be9c7600b482fbc3af8e3c9a5a7f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric avg_val_loss did not improve in the last 3 records. Best score: 0.697. Signaling Trainer to stop.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 380: 'avg_val_loss' reached 0.69658 (best 0.69658), saving model to '/content/drive/MyDrive/DL7643/finalProject/hateful_memes/model-outputs/epoch=3-step=380-v2.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['model-outputs/epoch=0-step=95.ckpt', 'model-outputs/epoch=0-step=95-v1.ckpt', 'model-outputs/epoch=0-step=95-v2.ckpt', 'model-outputs/epoch=0-step=95-v3.ckpt', 'model-outputs/epoch=0-step=95-v4.ckpt', 'model-outputs/epoch=0-step=95-v5.ckpt', 'model-outputs/epoch=3-step=380.ckpt', 'model-outputs/epoch=4-step=475.ckpt', 'model-outputs/epoch=1-step=190.ckpt', 'model-outputs/epoch=1-step=190-v1.ckpt', 'model-outputs/epoch=0-step=95-v6.ckpt', 'model-outputs/epoch=2-step=285.ckpt', 'model-outputs/epoch=4-step=475-v1.ckpt', 'model-outputs/epoch=0-step=95-v7.ckpt', 'model-outputs/epoch=1-step=190-v2.ckpt', 'model-outputs/epoch=4-step=475-v2.ckpt', 'model-outputs/epoch=1-step=190-v3.ckpt', 'model-outputs/epoch=0-step=95-v8.ckpt', 'model-outputs/epoch=1-step=190-v4.ckpt', 'model-outputs/epoch=0-step=95-v9.ckpt', 'model-outputs/epoch=1-step=190-v5.ckpt', 'model-outputs/epoch=1-step=190-v6.ckpt', 'model-outputs/epoch=1-step=190-v7.ckpt', 'model-outputs/epoch=0-step=95-v10.ckpt', 'model-outputs/epoch=1-step=190-v8.ckpt', 'model-outputs/epoch=3-step=380-v1.ckpt', 'model-outputs/epoch=1-step=190-v9.ckpt', 'model-outputs/epoch=0-step=95-v11.ckpt', 'model-outputs/epoch=0-step=95-v12.ckpt', 'model-outputs/epoch=4-step=475-v3.ckpt', 'model-outputs/epoch=0-step=95-v13.ckpt', 'model-outputs/epoch=1-step=190-v10.ckpt', 'model-outputs/epoch=0-step=95-v14.ckpt', 'model-outputs/epoch=0-step=95-v15.ckpt', 'model-outputs/epoch=0-step=95-v16.ckpt', 'model-outputs/epoch=0-step=95-v17.ckpt', 'model-outputs/epoch=0-step=95-v18.ckpt', 'model-outputs/epoch=2-step=285-v1.ckpt', 'model-outputs/epoch=0-step=95-v19.ckpt', 'model-outputs/epoch=1-step=190-v11.ckpt', 'model-outputs/epoch=2-step=285-v2.ckpt', 'model-outputs/epoch=1-step=190-v12.ckpt', 'model-outputs/epoch=3-step=380-v2.ckpt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/135 [00:07<17:21,  7.77s/it]\u001b[A\n",
            "  1%|▏         | 2/135 [00:08<07:55,  3.57s/it]\u001b[A\n",
            "  2%|▏         | 3/135 [00:09<04:53,  2.23s/it]\u001b[A\n",
            "  3%|▎         | 4/135 [00:09<03:29,  1.60s/it]\u001b[A\n",
            "  4%|▎         | 5/135 [00:10<02:40,  1.23s/it]\u001b[A\n",
            "  4%|▍         | 6/135 [00:10<02:10,  1.01s/it]\u001b[A\n",
            "  5%|▌         | 7/135 [00:11<01:52,  1.14it/s]\u001b[A\n",
            "  6%|▌         | 8/135 [00:12<01:40,  1.27it/s]\u001b[A\n",
            "  7%|▋         | 9/135 [00:12<01:30,  1.40it/s]\u001b[A\n",
            "  7%|▋         | 10/135 [00:13<01:23,  1.49it/s]\u001b[A\n",
            "  8%|▊         | 11/135 [00:13<01:19,  1.56it/s]\u001b[A\n",
            "  9%|▉         | 12/135 [00:14<01:16,  1.62it/s]\u001b[A\n",
            " 10%|▉         | 13/135 [00:14<01:13,  1.66it/s]\u001b[A\n",
            " 10%|█         | 14/135 [00:15<01:11,  1.70it/s]\u001b[A\n",
            " 11%|█         | 15/135 [00:15<01:09,  1.72it/s]\u001b[A\n",
            " 12%|█▏        | 16/135 [00:16<01:08,  1.74it/s]\u001b[A\n",
            " 13%|█▎        | 17/135 [00:17<01:09,  1.69it/s]\u001b[A\n",
            " 13%|█▎        | 18/135 [00:17<01:08,  1.71it/s]\u001b[A\n",
            " 14%|█▍        | 19/135 [00:18<01:07,  1.72it/s]\u001b[A\n",
            " 15%|█▍        | 20/135 [00:18<01:06,  1.72it/s]\u001b[A\n",
            " 16%|█▌        | 21/135 [00:19<01:05,  1.73it/s]\u001b[A\n",
            " 16%|█▋        | 22/135 [00:20<01:05,  1.72it/s]\u001b[A\n",
            " 17%|█▋        | 23/135 [00:20<01:05,  1.72it/s]\u001b[A\n",
            " 18%|█▊        | 24/135 [00:21<01:04,  1.71it/s]\u001b[A\n",
            " 19%|█▊        | 25/135 [00:21<01:03,  1.74it/s]\u001b[A\n",
            " 19%|█▉        | 26/135 [00:22<01:02,  1.75it/s]\u001b[A\n",
            " 20%|██        | 27/135 [00:22<01:03,  1.71it/s]\u001b[A\n",
            " 21%|██        | 28/135 [00:23<01:04,  1.65it/s]\u001b[A\n",
            " 21%|██▏       | 29/135 [00:24<01:04,  1.63it/s]\u001b[A\n",
            " 22%|██▏       | 30/135 [00:24<01:02,  1.68it/s]\u001b[A\n",
            " 23%|██▎       | 31/135 [00:25<01:01,  1.70it/s]\u001b[A\n",
            " 24%|██▎       | 32/135 [00:25<01:00,  1.72it/s]\u001b[A\n",
            " 24%|██▍       | 33/135 [00:26<01:00,  1.68it/s]\u001b[A\n",
            " 25%|██▌       | 34/135 [00:27<00:59,  1.71it/s]\u001b[A\n",
            " 26%|██▌       | 35/135 [00:27<00:57,  1.73it/s]\u001b[A\n",
            " 27%|██▋       | 36/135 [00:28<00:57,  1.71it/s]\u001b[A\n",
            " 27%|██▋       | 37/135 [00:28<00:56,  1.74it/s]\u001b[A\n",
            " 28%|██▊       | 38/135 [00:29<00:56,  1.73it/s]\u001b[A\n",
            " 29%|██▉       | 39/135 [00:29<00:55,  1.73it/s]\u001b[A\n",
            " 30%|██▉       | 40/135 [00:30<00:54,  1.74it/s]\u001b[A\n",
            " 30%|███       | 41/135 [00:31<00:53,  1.76it/s]\u001b[A\n",
            " 31%|███       | 42/135 [00:31<00:53,  1.74it/s]\u001b[A\n",
            " 32%|███▏      | 43/135 [00:32<00:53,  1.73it/s]\u001b[A\n",
            " 33%|███▎      | 44/135 [00:32<00:52,  1.72it/s]\u001b[A\n",
            " 33%|███▎      | 45/135 [00:33<00:52,  1.73it/s]\u001b[A\n",
            " 34%|███▍      | 46/135 [00:34<00:51,  1.73it/s]\u001b[A\n",
            " 35%|███▍      | 47/135 [00:34<00:50,  1.73it/s]\u001b[A\n",
            " 36%|███▌      | 48/135 [00:35<00:50,  1.73it/s]\u001b[A\n",
            " 36%|███▋      | 49/135 [00:35<00:49,  1.72it/s]\u001b[A\n",
            " 37%|███▋      | 50/135 [00:36<00:48,  1.74it/s]\u001b[A\n",
            " 38%|███▊      | 51/135 [00:36<00:48,  1.73it/s]\u001b[A\n",
            " 39%|███▊      | 52/135 [00:37<00:48,  1.73it/s]\u001b[A\n",
            " 39%|███▉      | 53/135 [00:38<00:47,  1.73it/s]\u001b[A\n",
            " 40%|████      | 54/135 [00:38<00:46,  1.73it/s]\u001b[A\n",
            " 41%|████      | 55/135 [00:39<00:45,  1.74it/s]\u001b[A\n",
            " 41%|████▏     | 56/135 [00:39<00:46,  1.72it/s]\u001b[A\n",
            " 42%|████▏     | 57/135 [00:40<00:44,  1.74it/s]\u001b[A\n",
            " 43%|████▎     | 58/135 [00:40<00:44,  1.73it/s]\u001b[A\n",
            " 44%|████▎     | 59/135 [00:41<00:43,  1.73it/s]\u001b[A\n",
            " 44%|████▍     | 60/135 [00:42<00:43,  1.73it/s]\u001b[A\n",
            " 45%|████▌     | 61/135 [00:42<00:43,  1.69it/s]\u001b[A\n",
            " 46%|████▌     | 62/135 [00:43<00:44,  1.65it/s]\u001b[A\n",
            " 47%|████▋     | 63/135 [00:44<00:44,  1.61it/s]\u001b[A\n",
            " 47%|████▋     | 64/135 [00:44<00:43,  1.65it/s]\u001b[A\n",
            " 48%|████▊     | 65/135 [00:45<00:41,  1.67it/s]\u001b[A\n",
            " 49%|████▉     | 66/135 [00:45<00:40,  1.70it/s]\u001b[A\n",
            " 50%|████▉     | 67/135 [00:46<00:39,  1.72it/s]\u001b[A\n",
            " 50%|█████     | 68/135 [00:46<00:38,  1.73it/s]\u001b[A\n",
            " 51%|█████     | 69/135 [00:47<00:38,  1.72it/s]\u001b[A\n",
            " 52%|█████▏    | 70/135 [00:48<00:37,  1.72it/s]\u001b[A\n",
            " 53%|█████▎    | 71/135 [00:48<00:37,  1.72it/s]\u001b[A\n",
            " 53%|█████▎    | 72/135 [00:49<00:36,  1.72it/s]\u001b[A\n",
            " 54%|█████▍    | 73/135 [00:49<00:35,  1.73it/s]\u001b[A\n",
            " 55%|█████▍    | 74/135 [00:50<00:35,  1.72it/s]\u001b[A\n",
            " 56%|█████▌    | 75/135 [00:50<00:34,  1.72it/s]\u001b[A\n",
            " 56%|█████▋    | 76/135 [00:51<00:34,  1.71it/s]\u001b[A\n",
            " 57%|█████▋    | 77/135 [00:52<00:34,  1.70it/s]\u001b[A\n",
            " 58%|█████▊    | 78/135 [00:52<00:33,  1.71it/s]\u001b[A\n",
            " 59%|█████▊    | 79/135 [00:53<00:33,  1.69it/s]\u001b[A\n",
            " 59%|█████▉    | 80/135 [00:53<00:32,  1.70it/s]\u001b[A\n",
            " 60%|██████    | 81/135 [00:54<00:31,  1.71it/s]\u001b[A\n",
            " 61%|██████    | 82/135 [00:55<00:31,  1.71it/s]\u001b[A\n",
            " 61%|██████▏   | 83/135 [00:55<00:30,  1.71it/s]\u001b[A\n",
            " 62%|██████▏   | 84/135 [00:56<00:29,  1.71it/s]\u001b[A\n",
            " 63%|██████▎   | 85/135 [00:56<00:29,  1.69it/s]\u001b[A\n",
            " 64%|██████▎   | 86/135 [00:57<00:29,  1.67it/s]\u001b[A\n",
            " 64%|██████▍   | 87/135 [00:58<00:29,  1.65it/s]\u001b[A\n",
            " 65%|██████▌   | 88/135 [00:58<00:28,  1.67it/s]\u001b[A\n",
            " 66%|██████▌   | 89/135 [00:59<00:27,  1.69it/s]\u001b[A\n",
            " 67%|██████▋   | 90/135 [00:59<00:26,  1.71it/s]\u001b[A\n",
            " 67%|██████▋   | 91/135 [01:00<00:25,  1.73it/s]\u001b[A\n",
            " 68%|██████▊   | 92/135 [01:00<00:24,  1.74it/s]\u001b[A\n",
            " 69%|██████▉   | 93/135 [01:01<00:24,  1.74it/s]\u001b[A\n",
            " 70%|██████▉   | 94/135 [01:02<00:23,  1.76it/s]\u001b[A\n",
            " 70%|███████   | 95/135 [01:02<00:22,  1.75it/s]\u001b[A\n",
            " 71%|███████   | 96/135 [01:03<00:22,  1.73it/s]\u001b[A\n",
            " 72%|███████▏  | 97/135 [01:03<00:21,  1.73it/s]\u001b[A\n",
            " 73%|███████▎  | 98/135 [01:04<00:21,  1.72it/s]\u001b[A\n",
            " 73%|███████▎  | 99/135 [01:05<00:21,  1.71it/s]\u001b[A\n",
            " 74%|███████▍  | 100/135 [01:05<00:20,  1.71it/s]\u001b[A\n",
            " 75%|███████▍  | 101/135 [01:06<00:19,  1.72it/s]\u001b[A\n",
            " 76%|███████▌  | 102/135 [01:06<00:19,  1.73it/s]\u001b[A\n",
            " 76%|███████▋  | 103/135 [01:07<00:18,  1.74it/s]\u001b[A\n",
            " 77%|███████▋  | 104/135 [01:07<00:17,  1.75it/s]\u001b[A\n",
            " 78%|███████▊  | 105/135 [01:08<00:17,  1.75it/s]\u001b[A\n",
            " 79%|███████▊  | 106/135 [01:09<00:16,  1.75it/s]\u001b[A\n",
            " 79%|███████▉  | 107/135 [01:09<00:15,  1.77it/s]\u001b[A\n",
            " 80%|████████  | 108/135 [01:10<00:15,  1.78it/s]\u001b[A\n",
            " 81%|████████  | 109/135 [01:10<00:14,  1.79it/s]\u001b[A\n",
            " 81%|████████▏ | 110/135 [01:11<00:13,  1.79it/s]\u001b[A\n",
            " 82%|████████▏ | 111/135 [01:11<00:13,  1.78it/s]\u001b[A\n",
            " 83%|████████▎ | 112/135 [01:12<00:12,  1.80it/s]\u001b[A\n",
            " 84%|████████▎ | 113/135 [01:12<00:12,  1.80it/s]\u001b[A\n",
            " 84%|████████▍ | 114/135 [01:13<00:11,  1.80it/s]\u001b[A\n",
            " 85%|████████▌ | 115/135 [01:13<00:11,  1.80it/s]\u001b[A\n",
            " 86%|████████▌ | 116/135 [01:14<00:10,  1.80it/s]\u001b[A\n",
            " 87%|████████▋ | 117/135 [01:15<00:09,  1.82it/s]\u001b[A\n",
            " 87%|████████▋ | 118/135 [01:15<00:09,  1.82it/s]\u001b[A\n",
            " 88%|████████▊ | 119/135 [01:16<00:08,  1.82it/s]\u001b[A\n",
            " 89%|████████▉ | 120/135 [01:16<00:08,  1.81it/s]\u001b[A\n",
            " 90%|████████▉ | 121/135 [01:17<00:07,  1.81it/s]\u001b[A\n",
            " 90%|█████████ | 122/135 [01:17<00:07,  1.81it/s]\u001b[A\n",
            " 91%|█████████ | 123/135 [01:18<00:06,  1.81it/s]\u001b[A\n",
            " 92%|█████████▏| 124/135 [01:18<00:06,  1.81it/s]\u001b[A\n",
            " 93%|█████████▎| 125/135 [01:19<00:05,  1.82it/s]\u001b[A\n",
            " 93%|█████████▎| 126/135 [01:20<00:04,  1.80it/s]\u001b[A\n",
            " 94%|█████████▍| 127/135 [01:20<00:04,  1.81it/s]\u001b[A\n",
            " 95%|█████████▍| 128/135 [01:21<00:03,  1.81it/s]\u001b[A\n",
            " 96%|█████████▌| 129/135 [01:21<00:03,  1.81it/s]\u001b[A\n",
            " 96%|█████████▋| 130/135 [01:22<00:02,  1.81it/s]\u001b[A\n",
            " 97%|█████████▋| 131/135 [01:22<00:02,  1.81it/s]\u001b[A\n",
            " 98%|█████████▊| 132/135 [01:23<00:01,  1.81it/s]\u001b[A\n",
            " 99%|█████████▊| 133/135 [01:23<00:01,  1.75it/s]\u001b[A\n",
            " 99%|█████████▉| 134/135 [01:24<00:00,  1.76it/s]\u001b[A\n",
            "100%|██████████| 135/135 [01:26<00:00,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " model: squeezebert/squeezebert-uncased & vgg19_bn, \n",
            " accuracy: 0.5740740740740741, \n",
            " auc_roc: 0.567534110915493, \n",
            " f1 score: 0.4956140350877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# test 1 with vision_feature_dim: 1000 \n",
        "tests = [       \n",
        "    (\"distilbert-base-uncased\", \"densenet161\"),\n",
        "    (\"distilbert-base-uncased\", \"vgg19_bn\"),\n",
        "    (\"bert-base-uncased\", \"densenet161\"),\n",
        "    (\"bert-base-uncased\", \"vgg19_bn\"),\n",
        "    (\"roberta-base\", \"densenet161\"),\n",
        "    (\"roberta-base\", \"vgg19_bn\"),\n",
        "    (\"distilroberta-base\", \"densenet161\"),\n",
        "    (\"distilroberta-base\", \"vgg19_bn\"),\n",
        "    (\"gpt2\", \"densenet161\"),\n",
        "    (\"gpt2\", \"vgg19_bn\"),\n",
        "    (\"distilgpt2\", \"densenet161\"),\n",
        "    (\"distilgpt2\", \"vgg19_bn\"),\n",
        "    (\"albert-base-v2\", \"densenet161\"),\n",
        "    (\"albert-base-v2\", \"vgg19_bn\"),\n",
        "    (\"xlm-roberta-base\", \"densenet161\"),\n",
        "    (\"xlm-roberta-base\", \"vgg19_bn\"),\n",
        "    (\"squeezebert/squeezebert-uncased\", \"densenet161\"),\n",
        "    (\"squeezebert/squeezebert-uncased\", \"vgg19_bn\"),\n",
        "]\n",
        "\n",
        "# test 2 with vision_feature_dim: 300 \n",
        "# tests = [\n",
        "#     (\"distilbert-base-uncased\", \"resnet152\"),\n",
        "#     (\"distilbert-base-uncased\", \"wide_resnet101_2\"),\n",
        "#     (\"bert-base-uncased\", \"densenet161\"),\n",
        "#     (\"bert-base-uncased\", \"vgg19_bn\"),\n",
        "#     (\"roberta-base\", \"resnet152\"),\n",
        "#     (\"roberta-base\", \"wide_resnet101_2\"),\n",
        "#     (\"distilroberta-base\", \"resnet152\"),\n",
        "#     (\"distilroberta-base\", \"wide_resnet101_2\"),\n",
        "#     (\"gpt2\", \"resnet152\"),\n",
        "#     (\"gpt2\", \"wide_resnet101_2\"),\n",
        "#     (\"distilgpt2\", \"resnet152\"),\n",
        "#     (\"distilgpt2\", \"wide_resnet101_2\"),\n",
        "#     (\"albert-base-v2\", \"resnet152\"),\n",
        "#     (\"albert-base-v2\", \"wide_resnet101_2\"),\n",
        "#     (\"xlm-roberta-base\", \"resnet152\"),\n",
        "#     (\"xlm-roberta-base\", \"wide_resnet101_2\"),\n",
        "#     (\"squeezebert/squeezebert-uncased\", \"resnet152\"),\n",
        "#     (\"squeezebert/squeezebert-uncased\", \"wide_resnet101_2\"),\n",
        "# ]\n",
        "\n",
        "for language_model_name, vision_model_name in tests:\n",
        "    _, accuracy, auc_roc, f1 = get_accuracy_for(language_model_name, vision_model_name)\n",
        "    print(\"\\n model: {} & {}, \\n accuracy: {}, \\n auc_roc: {}, \\n f1 score: {}\".format(language_model_name, vision_model_name, accuracy, auc_roc, f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or9zM9EGJio5"
      },
      "outputs": [],
      "source": []
    }
  ]
}